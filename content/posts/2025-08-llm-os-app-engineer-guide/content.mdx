## 前言：90% 的 LLM 專案為何停在 POC 階段？

根據 Gartner 與 McKinsey 的觀察，超過八成的 LLM 專案停留在概念驗證（POC），從未進入正式生產環境。

原因不在技術不可行，而在於：

- 缺乏穩定性設計（non-deterministic output）
- 成本不可預測（token usage 波動大）
- 無法與現有系統整合（data pipeline, auth, audit log）
- 缺少監控與除錯工具

換句話說：我們擅長「展示能力」，但不擅長「工程建構後交付」。

這門課的目標，是填補這道鴻溝——
讓你從「會用 Token API 的開發者」，轉型為「能交付穩定 LLM OS 應用的系統設計者」。

> 💡 **定位明確**：你不需要理解 Transformer 的數學原理，也不需要會訓練模型。你需要的是把 LLM OS 當作「新時代的 API」，並用工程化的方式打造應用。

---

## 📊 LLM OS 應用工程師 vs 系統工程師

| 面向 | 系統工程師 | **應用工程師** | 
|---|---|---|
| **關注重點** | 底層架構、模型優化 | 產品體驗、業務價值 |
| **核心技能** | RAG 原理、向量資料庫、模型部署 | Prompt 版本管理、UX 設計、成本控制 |
| **工作內容** | 建構 LLM 基礎設施 | 開發 Bot、Copilot、Agent |
| **市場需求** | 每家公司 1-2 位 | **每家公司 5-10 位** |
| **學習曲線** | 陡峭（6-12 個月） | **適中（2-3 個月）** |

---

## 🎯 學習目標與能力出口

完成這個課程後，你將能夠：

### ✅ 核心能力
- 把一個 LLM OS 應用從**設計 → API → UX → 上線**
- 處理 **80% 的產品問題**（不穩定、成本高、體驗差）
- 具備**產品思維**，知道何時該用/不該用 LLM

### 🚀 可開發的應用類型
1. 對話與互動應用
- 智慧客服：處理複雜詢問、多輪對話、情緒管理
- 企業內部 Copilot：幫助員工快速查詢文件、操作系統
- 多語翻譯與文化轉換助手 <br />

👉 用到的模組：System Prompt、上下文管理、Function Calling

2. 文件與知識應用
- 文件助手：摘要、問答、比對、法規檢索
- 研究助理：文獻搜尋、比較、生成研究筆記
- 會議/合約助理：自動生成摘要、風險提示、重點標註 <br />

👉 用到的模組：RAG、進階 Context Engineering、Plan→Solve→Verify

3. 數據與分析應用
- 報告生成器：輸入數據，自動產出決策報告
- 財務分析助手：KPI 分析、異常檢測、決策建議
- 行銷數據助理：從 GA/CRM 撈數據 → 分析 → 生成 insights <br />

👉 用到的模組：Function Calling、Chain-of-Thought、成本工程

4. 開發者工具
- Coding Copilot：程式碼生成、解釋、重構建議
- 測試案例生成器：根據需求自動產出測試案例
- Pipeline Debugger：輔助排查數據流程或 API 連動問題 <br />

👉 用到的模組：LLM 選型、進階 Prompt 工程、自檢 / 自一致性

5. 商務與生產力
- 銷售助理：自動生成銷售話術、郵件回覆
- 專案助理：追蹤進度、生成週報、風險預警
- 行銷內容工廠：自動產生廣告文案、標題、社群貼文 <br />

👉 用到的模組：成本工程、上下文管理、可觀測性

6. Agent 與自動化
- Workflow Agent：自動完成多步驟任務（如搜尋 → 分析 → 報告）
- 多 Agent 協作：分工完成複雜專案
- 系統自動化：串接 ERP / CRM / 工單系統，減少人工流程 <br />

👉 用到的模組：Agent 架構、ReAct、工具路由、進階 RAG

學完這些模組，您不只是能做一個聊天機器人，而是能：
- 讓 LLM 穩定輸出（可控 / 可驗證）
- 把 LLM 嵌入不同業務流程（文件、數據、客服、開發）
- 設計長期可用的框架（成本、觀測、流程管理） <br />

👉 這就是 LLM OS 應用工程師的核心價值：把 LLM OS 當作「新一代 API」，應用到各種產品與產業場景。

### 📈 職涯發展路徑

<!-- <CareerPathDiagram /> -->

---

## 🏗 完整課程架構（8 週速成）

### 📚 課程設計理念
- **70% 應用實作**：直接動手做產品
- **30% 系統必修**：理解必要的底層概念
- **100% 實戰導向**：每個模組都有實際產出

---

## 📘 模組 1：Prompt for Applications（第 1 週）

### 🎯 學習目標
從「寫 Prompt」升級到「管理 Prompt 資產」

### 📚 核心內容
在這個模組中，我們將深入探討如何將 Prompt Engineering 從一門藝術轉化為一門科學。您將學習如何系統化地管理、優化和測試您的 prompts，確保它們在實際應用中能夠發揮最大效用，並為您的產品或服務帶來可預測、可依賴的成果。

### 1.1 Prompt 版本管理 (Version Control + Feature Flag)
為什麼版本管理至關重要？

想像一下，您正在開發一個依賴大型語言模型 (LLM) 的應用程式，例如客服機器人或內容生成工具。您今天覺得某個 prompt 效果很好，就直接上線了。一週後，為了應對新的需求，您修改了這個 prompt，卻發現效果不如預期，甚至引發了新的問題。這時，如果您沒有一個好的版本管理系統，要回退到上一個穩定版本將會非常困難，甚至可能造成線上服務的中斷。

這就是為什麼我們需要將軟體開發中成熟的版本控制概念引入到 Prompt Engineering 中。

#### 1.1.1 版本控制 (Version Control) - 您的 Prompt 安全網

版本控制不僅僅是為 prompt 加上 v1, v2, v3 的標籤。一個成熟的流程應該包含：

集中式管理：將所有 prompts 存放在一個統一的地方，例如 Git Repo、專門的 Prompt 管理平台，或是資料庫中。這樣可以避免團隊成員使用不同步或過時的 prompts。

明確的命名與註釋：

版本號 (Versioning)：遵循語意化版本控制 (Semantic Versioning)，例如 v1.2.1。

主版號 (1.x.x)：當 prompt 的核心邏輯或輸出格式有重大、不相容的改變時更新。

次版號 (x.2.x)：當新增功能或對 prompt 進行了顯著優化，但仍保持向下相容時更新。

修訂號 (x.x.1)：當修正錯字、調整語氣等小幅度的優化時更新。

變更日誌 (Changelog)：詳細記錄每個版本的變更內容、修改原因以及優化效果。這對於團隊協作和未來回溯至關重要。

與程式碼分離：盡量將 prompts 從應用程式的程式碼中抽離出來。這樣一來，非工程師的團隊成員（如產品經理、行銷人員）也可以在不需要重新部署整個應用的情況下，參與 prompts 的迭代與優化。

#### 1.1.2 Feature Flag - 靈活部署與風險控制的利器

Feature Flag（功能旗標）是一種允許您在不修改程式碼的情況下，動態開啟或關閉特定功能的技術。將它應用於 Prompt 管理，能帶來巨大的靈活性和安全性。

動態切換 Prompts：想像您有一個 greeting_prompt。透過 Feature Flag，您可以設定一個參數，讓系統根據不同的條件（例如：使用者地區、會員等級、或是一個開關）來決定要使用 greeting_prompt_v1 還是 greeting_prompt_v2_formal。

灰度發布 (Canary Release)：當您開發了一個全新的、更強大的 prompt v3.0，您可能不想立刻將它推送給所有使用者。利用 Feature Flag，您可以先將 v3.0 開放給 1% 的內部員工或測試用戶，觀察其表現。如果效果良好，再逐步擴大到 5%、20%，最終全面上線。這個過程能大幅降低因新 prompt 表現不佳而導致的大規模負面影響。

緊急回退 (Kill Switch)：如果在全面上線後，發現新版的 prompt 在某些邊界情況下會產生有害或不當的內容，您可以立即透過 Feature Flag 將其關閉，讓系統瞬間切換回上一個穩定的版本，而不需要緊急進行程式碼的重新部署。

### 1.2 核心 Prompt 技術的應用場景 (Few-shot, CoT, ReAct)
了解了如何管理 prompts 之後，我們來深入探討三種能顯著提升 LLM 表現的核心技術。了解它們各自的適用場景，是成為高級 Prompt Engineer 的關鍵。

#### 1.2.1 Few-shot Learning - 給模型幾個範例，讓它學得更快

核心思想：在您的問題之前，提供幾個完整的「問題-答案」範例。這就像是給模型一個小型的「速成班」，讓它在回答您真正的問題之前，先理解您期望的格式、風格和邏輯。

應用場景：

格式化輸出：當您需要模型以特定的格式（如 JSON、Markdown 表格、特定 XML 結構）回覆時，提供幾個範例是最高效的方式。

特定風格的文本生成：例如，要求模型撰寫一封正式的商業郵件。您可以先提供一兩個符合公司風格的範例郵件，模型就能更好地模仿該語氣和用詞。

複雜分類任務：假設您要將用戶評論分為「正面」、「負面」、「中性」和「建議」。您可以給出幾個典型評論及其分類的範例，幫助模型更精準地進行判斷。

Zero-shot vs. Few-shot：Zero-shot (零樣本) 是指不給任何範例，直接提出問題。當任務非常簡單或模型已經非常熟悉時，可以使用。但只要任務稍微複雜或需要特定格式，Few-shot 的效果通常會遠勝於 Zero-shot。

#### 1.2.2 Chain of Thought (CoT) - 引導模型「思考」而不是「猜測」

核心思想：不僅僅給模型答案，而是向模型展示「如何一步步推導出答案」的思考過程。這會激發模型內部的推理能力，使其在處理複雜問題時，表現得更像一個真正的思考者。

應用場景：

數學與邏輯推理：這是 CoT 最經典的應用。例如，在解決一個數學應用題時，您會先列出已知條件，然後寫下計算步驟，最後得出答案。將這個過程展示給模型，它解決類似問題的準確率會大幅提升。

多步驟指令的任務規劃：例如，「幫我規劃一個週末去陽明山的行程，需要包含午餐地點，並且考慮到下午可能會下雨。」使用 CoT，您可以引導模型先思考：1. 選擇陽明山景點。2. 查詢天氣預報。3. 根據天氣推薦上午的戶外景點和下午的室內備案。4. 推薦午餐地點。

根本原因分析 (Root Cause Analysis)：當面對一個複雜的問題（例如：「為什麼我的電商網站上個月的轉換率下降了？」），您可以透過 CoT 引導模型從數據、市場、產品等多個角度進行逐步分析，而不是直接給出一個猜測性的答案。

#### 1.2.3 ReAct (Reasoning and Acting) - 讓模型成為一個會使用工具的智慧體

核心思想：結合了 CoT 的「思考」(Reasoning) 和與外部工具「互動」(Acting) 的能力。這讓 LLM 不再只是一個封閉的知識庫，而是一個可以主動獲取最新資訊、執行程式碼、與 API 互動的智慧代理 (Agent)。

運作流程：思考 (Thought) -> 行動 (Action) -> 觀察 (Observation) -> 思考 (Thought) ...

應用場景：

需要即時資訊的問答：例如，「Google 最近的股價是多少？並分析一下近期的趨勢。」模型會 思考 到需要查詢股價，於是 行動 (呼叫一個股票查詢 API)，得到 觀察 (股價數據)，然後再 思考 如何基於這些數據進行分析。

與外部服務互動：建立一個能幫您預訂餐廳、查詢訂單狀態或是在您的行事曆上新增活動的 AI 助理。模型會根據您的指令，思考需要呼叫哪個 API (行動)，並根據 API 的回傳結果 (觀察) 進行下一步。

自動化研究與報告生成：給定一個主題，ReAct 框架可以讓模型主動上網搜尋資料 (行動)，閱讀並總結搜尋結果 (觀察 & 思考)，最終生成一份結構完整的報告。

### 1.3 Prompt 測試與 A/B 比較 - 用數據驅動優化
一個好的 prompt 不是憑感覺想出來的，而是透過嚴謹的測試和數據分析迭代出來的。

#### 1.3.1 建立評估標準 (Evaluation Metrics)

在開始測試前，您必須先定義「好」的標準是什麼。

客觀指標：

準確率 (Accuracy)：對於分類或事實性問答，答案是否正確。

完整性 (Completeness)：回答是否涵蓋了問題的所有方面。

格式符合率 (Format Compliance)：輸出是否嚴格遵守了您要求的格式 (例如，JSON 格式是否合法)。

主觀指標：

流暢度 (Fluency)：文本是否通順、自然。

相關性 (Relevance)：回答是否緊扣主題，沒有無關的廢話。

安全性 (Safety)：是否包含有害、偏見或不當的內容。

業務指標：

轉換率 (Conversion Rate)：行銷文案 prompt 是否提升了點擊率或購買率。

用戶滿意度 (Customer Satisfaction)：客服機器人的 prompt 是否提升了用戶的滿意度分數。

#### 1.3.2 測試方法

黃金測試集 (Golden Set)：建立一個包含數十到數百個具代表性的輸入案例和其對應的「標準答案」的測試集。每當您修改 prompt 後，都用這個測試集來進行回歸測試，確保新的 prompt 沒有在舊的、重要的案例上出錯。

A/B 測試 (A/B Testing)：

這是線上評估 prompt 效果最科學的方法。

將您的用戶流量隨機分成兩組（或多組）。A 組使用舊的 baseline prompt，B 組使用新的優化版 prompt。

運行一段時間後，根據您預先設定的業務指標（如點擊率、用戶留存時間等）來比較哪一組的表現更好。

A/B 測試的結果是最有說服力的，因為它反映了 prompt 在真實世界中的真實表現。

實作 Lab：建立三版 Prompt，用 Feature Flag 動態切換
目標：模擬一個為電商產品生成簡短行銷文案的場景，並體驗如何透過 Feature Flag 在不同版本的 Prompt 之間進行切換。

場景：我們需要為一個名為「Aura 智慧香氛機」的產品生成一段吸引人的社群媒體貼文。

步驟 1：定義三版 Prompts

v1_baseline (基礎版)

Prompt: "為「Aura 智慧香氛機」寫一段社群媒體的行銷文案。"

目的：這是一個最簡單、最直接的 prompt，作為我們比較的基準。

v2_few_shot (範例學習版)

Prompt:

為產品寫一段吸引人的社群媒體行銷文案。

範例1：
產品：SleekPods 無線藍牙耳機
文案：🎶 告別纏線，擁抱自由！SleekPods 帶來沉浸式音質與全天候舒適配戴感。#無線自由 #音樂隨行

範例2：
產品：Zenith 手沖咖啡壺
文案：☕️ 每個早晨，都值得一杯完美的咖啡。Zenith 手沖咖啡壺，精準溫控，釋放咖啡豆的極致風味。#手沖咖啡 #生活美學

現在，請為「Aura 智慧香氛機」寫一段社群媒體的行銷文案。
目的：使用 Few-shot learning，提供範例來引導模型生成包含 Emoji 和 Hashtag 的、更符合社群媒體風格的文案。

v3_optimized (優化版)

Prompt:

你是一位頂尖的社群行銷專家。你的任務是為新產品「Aura 智慧香氛機」撰寫一段引人入勝、不超過150字的 Instagram 貼文。

**產品核心賣點**:
1.  可透過 App 遠端遙控，並設定排程。
2.  能與智慧家庭系統（如 Google Home）連動。
3.  使用天然植物精油，安靜運作。

**寫作要求**:
- 開頭要能立刻抓住眼球。
- 文案中需自然地融入至少兩個核心賣點。
- 語氣需溫暖、有質感，能喚起放鬆和科技感。
- 結尾必須包含一個行動呼籲 (Call to Action)。
- 最後附上 3-4 個相關的 Hashtag。
目的：這是一個更精緻的 prompt，明確定義了角色 (Persona)、上下文 (Context)、任務細節 (Task Specifics) 和輸出格式 (Output Format)，期望能生成質量最高的文案。

步驟 2：用 Feature Flag 實現切換（概念程式碼）

這裡我們用 Python 偽代碼來展示這個概念。在真實世界中，您可能會使用像 LaunchDarkly、Flagsmith 這樣的 Feature Flag 服務。

Python

import random

# --- Prompt Repository (可以存在資料庫或設定檔中) ---
PROMPTS = {
    "v1_baseline": "為「Aura 智慧香氛機」寫一段社群媒體的行銷文案。",
    "v2_few_shot": """... (省略如上) ...""",
    "v3_optimized": """... (省略如上) ..."""
}

# --- Feature Flag 服務的模擬 ---
# 在真實應用中，這個函式會連接到您的 Feature Flag 服務
def get_marketing_prompt_version(user_id):
    """
    根據用戶 ID 或其他規則決定使用哪個版本的 Prompt。
    這裡我們用一個簡單的隨機分配來模擬 A/B 測試。
    """
    # 假設我們 80% 流量用 baseline，20% 流量測試 optimized
    if random.random() < 0.8:
        return "v1_baseline"
    else:
        # 在真實場景中，這裡可能是 v2 或 v3
        return "v3_optimized" 

# --- 應用程式邏輯 ---
def generate_product_copy(product_name, user_id):
    """
    根據 Feature Flag 獲取對應的 Prompt 版本，並生成文案。
    """
    # 1. 根據 Feature Flag 決定要用哪個版本
    prompt_version = get_marketing_prompt_version(user_id)
    
    # 2. 從我們的 Prompt 庫中獲取 Prompt 內容
    prompt_template = PROMPTS.get(prompt_version, PROMPTS["v1_baseline"])
    
    # 這裡的 prompt_template 已經根據我們的 Feature Flag 規則動態選擇了
    print(f"--- 正在為 User {user_id} 使用 Prompt 版本: {prompt_version} ---")
    
    # 3. (模擬) 呼叫 LLM API
    # response = call_llm_api(prompt_template.format(product_name=product_name))
    # return response
    
    # 為了演示，我們直接返回 prompt 內容
    return prompt_template


# --- 模擬不同用戶請求 ---
user_a = 101
user_b = 202

print("為 User A 生成文案:")
copy_for_a = generate_product_copy("Aura 智慧香氛機", user_a)
# print(copy_for_a) # 在真實應用中，你會看到 LLM 的生成結果

print("\n" + "="*50 + "\n")

print("為 User B 生成文案:")
copy_for_b = generate_product_copy("Aura 智慧香氛機", user_b)
# print(copy_for_b) # 在真實應用中，你會看到 LLM 的生成結果

Lab 總結與討論

完成這個 Lab 後，請思考：

比較三版 prompt 可能生成的結果，它們在品質、風格和內容上有何不同？

如果 v3 (優化版) 在線上測試時，發現生成的文案轉換率反而下降了，您會如何利用 Feature Flag 系統快速應對？

除了 A/B 測試，Feature Flag 在 Prompt 管理上還能帶來哪些好處？（例如：針對 VIP 用戶提供更優質的 prompt 版本）

---

## 📘 模組 2：LLM API 與 UX 整合（第 2 週）

### 🎯 學習目標
掌握三種 API 模式和對應的 UX 設計模式

### 📚 核心內容

#### 2.1 API 呼叫模式深度解析

```python
class LLMAPIPatterns:
    """三種 API 模式的最佳實踐"""
    
    @staticmethod
    def completion_mode(prompt):
        """補全模式：適合單次生成"""
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt=prompt,
            max_tokens=150,
            temperature=0.7
        )
        return response.choices[0].text
    
    @staticmethod
    def chat_mode(messages):
        """對話模式：適合多輪交互"""
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=messages,  # [{"role": "user", "content": "..."}]
            temperature=0.7
        )
        return response.choices[0].message.content
    
    @staticmethod
    async def streaming_mode(prompt, callback):
        """串流模式：適合即時回饋"""
        stream = await openai.ChatCompletion.acreate(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            stream=True
        )
        
        full_response = ""
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                full_response += content
                await callback(content)  # 即時顯示
        
        return full_response
```

#### 2.2 三種對話 UX 模式實戰

```python
class ConversationUX:
    """對話 UX 的三種核心模式"""
    
    def command_mode(self, user_input):
        """
        Command 模式：用戶下指令，系統執行
        適合：明確任務、單次操作
        """
        # 範例：/translate <text> to <language>
        if user_input.startswith("/translate"):
            _, text, _, language = user_input.split()
            return self.execute_translation(text, language)
    
    def clarification_mode(self, user_input, context):
        """
        Clarification 模式：系統主動詢問，澄清需求
        適合：複雜任務、模糊指令
        """
        ambiguity_score = self.detect_ambiguity(user_input)
        
        if ambiguity_score > 0.7:
            clarifying_questions = [
                "您是指 A 還是 B？",
                "需要包含 X 嗎？",
                "時間範圍是？"
            ]
            return {"needs_clarification": True, "questions": clarifying_questions}
        
        return {"needs_clarification": False, "response": self.process(user_input)}
    
    def suggestion_mode(self, user_input, history):
        """
        Suggestion 模式：系統提供建議選項
        適合：探索性任務、新手引導
        """
        response = self.generate_response(user_input)
        
        # 智慧建議下一步
        suggestions = [
            "📊 查看詳細數據",
            "📧 發送報告",
            "🔄 修改參數重試"
        ]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "quick_actions": self.generate_quick_actions(context=history)
        }
```

#### 2.3 信任層設計（關鍵但常被忽略）

```python
class OutputValidator:
    """LLM 輸出的信任層"""
    
    def __init__(self):
        self.validators = {
            "email": re.compile(r'^[\w\.-]+@[\w\.-]+\.\w+$'),
            "phone": re.compile(r'^\+?1?\d{9,15}$'),
            "json": self.validate_json,
            "sql": self.validate_sql_safety
        }
    
    def validate_json(self, output):
        """JSON 格式驗證"""
        try:
            parsed = json.loads(output)
            # 額外的 schema 驗證
            return jsonschema.validate(parsed, self.schema)
        except:
            return False
    
    def validate_sql_safety(self, sql):
        """SQL 安全性檢查"""
        dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER']
        sql_upper = sql.upper()
        
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                raise SecurityError(f"Dangerous SQL detected: {keyword}")
        
        return True
    
    def validate_and_fix(self, output, output_type):
        """驗證並嘗試修復"""
        if output_type not in self.validators:
            return output
        
        validator = self.validators[output_type]
        
        if isinstance(validator, re.Pattern):
            if not validator.match(output):
                # 嘗試修復（例如：提取 email）
                fixed = self.extract_pattern(output, validator)
                if fixed:
                    return fixed
                raise ValidationError(f"Invalid {output_type}: {output}")
        else:
            # 函數驗證器
            if not validator(output):
                raise ValidationError(f"Validation failed for {output_type}")
        
        return output
```

### 🔬 Lab 實作：智慧客服 Bot 三種模式

```python
# Lab: 實作一個支援三種 UX 模式的客服 Bot
class SmartCustomerServiceBot:
    def __init__(self):
        self.mode = "auto"  # auto, command, clarify, suggest
        self.validator = OutputValidator()
        self.context_manager = ContextManager()
    
    async def handle_message(self, message, user_id):
        # 1. 模式判斷
        if message.startswith("/"):
            return await self.handle_command(message)
        
        # 2. 模糊度分析
        ambiguity = self.analyze_ambiguity(message)
        if ambiguity > 0.6:
            return await self.handle_clarification(message)
        
        # 3. 一般處理 + 建議
        response = await self.generate_response(message)
        suggestions = self.generate_suggestions(message, response)
        
        return {
            "mode": "suggestion",
            "response": response,
            "suggestions": suggestions,
            "typing_time": self.calculate_typing_time(response)
        }
    
    async def handle_command(self, command):
        """Command 模式處理"""
        parts = command.split()
        cmd = parts[0]
        
        commands = {
            "/status": self.check_order_status,
            "/refund": self.process_refund,
            "/escalate": self.escalate_to_human
        }
        
        if cmd in commands:
            return await commands[cmd](parts[1:])
        
        return "Unknown command. Type /help for available commands."
    
    async def handle_clarification(self, message):
        """Clarification 模式處理"""
        # 智慧問題生成
        questions = self.generate_clarifying_questions(message)
        
        return {
            "mode": "clarification",
            "message": "我需要更多資訊來幫助您：",
            "questions": questions,
            "quick_replies": [q["short"] for q in questions]
        }
    
    def calculate_typing_time(self, response):
        """模擬真人打字時間"""
        words = len(response.split())
        # 假設打字速度：40 words/min
        return min(max(words / 40 * 60 * 1000, 1000), 5000)  # 1-5秒

# 實際測試
bot = SmartCustomerServiceBot()

test_messages = [
    "/status ORDER123",  # Command mode
    "我的訂單怎麼了",     # Clarification mode
    "我要退貨，產品有問題" # Suggestion mode
]

for msg in test_messages:
    result = await bot.handle_message(msg, "user_123")
    print(f"Input: {msg}")
    print(f"Mode: {result.get('mode', 'default')}")
    print(f"Response: {result}")
    print("-" * 50)
```

### 💡 實戰心得
> 🎯 **Pro Tip**：不要一開始就用 Streaming。先用 Completion 模式驗證邏輯，穩定後再升級到 Streaming 改善體驗。

---

## 📘 模組 3：Context Engineering 必修基礎（第 3 週）

### 🎯 學習目標
理解並管理 LLM 的「記憶系統」——這是系統工程師的必修簡化版

### 📚 核心內容

#### 3.1 三層記憶架構

```python
class MemoryArchitecture:
    """LLM 應用的記憶管理系統"""
    
    def __init__(self):
        # 三層記憶體系
        self.system_prompt = SystemPrompt()      # 長期記憶（不變）
        self.user_context = UserContext()        # 中期記憶（session）
        self.conversation = ConversationBuffer() # 短期記憶（對話）
        
        # Token 預算管理
        self.token_budget = {
            "system": 1000,      # 系統提示
            "context": 2000,     # 用戶上下文
            "conversation": 5000, # 對話歷史
            "response": 1000     # 預留給回應
        }
    
    def build_context(self, user_input):
        """構建完整上下文"""
        # 1. 計算各部分 token
        system_tokens = self.count_tokens(self.system_prompt.get())
        
        # 2. 動態調整空間分配
        remaining = 8000 - system_tokens - 1000  # 總共 8K，預留 1K
        
        # 3. 智慧壓縮
        context = {
            "system": self.system_prompt.get(),
            "user_context": self.compress_context(
                self.user_context.get(), 
                max_tokens=remaining * 0.3
            ),
            "conversation": self.compress_conversation(
                self.conversation.get(),
                max_tokens=remaining * 0.7
            ),
            "current_input": user_input
        }
        
        return self.format_context(context)
```

#### 3.2 Context 壓縮策略

```python
class ContextCompressor:
    """上下文壓縮器"""
    
    def __init__(self):
        self.strategies = {
            "summarization": self.summarize,
            "sliding_window": self.sliding_window,
            "importance_sampling": self.importance_sampling
        }
    
    def summarize(self, messages, max_tokens):
        """摘要壓縮：適合長對話"""
        if self.count_tokens(messages) <= max_tokens:
            return messages
        
        # 分組摘要
        chunks = self.chunk_messages(messages, chunk_size=10)
        summaries = []
        
        for chunk in chunks[:-1]:  # 保留最新的不摘要
            summary = llm.complete(f"Summarize: {chunk}", max_tokens=100)
            summaries.append({
                "role": "system",
                "content": f"[Earlier conversation summary]: {summary}"
            })
        
        # 保留最新消息原文
        return summaries + chunks[-1]
    
    def sliding_window(self, messages, max_tokens):
        """滑動窗口：保留最近 N 條"""
        total_tokens = 0
        kept_messages = []
        
        # 從最新的開始保留
        for msg in reversed(messages):
            msg_tokens = self.count_tokens(msg)
            if total_tokens + msg_tokens <= max_tokens:
                kept_messages.insert(0, msg)
                total_tokens += msg_tokens
            else:
                break
        
        # 加入摘要提示
        if len(kept_messages) < len(messages):
            kept_messages.insert(0, {
                "role": "system",
                "content": f"[{len(messages) - len(kept_messages)} earlier messages omitted]"
            })
        
        return kept_messages
    
    def importance_sampling(self, messages, max_tokens):
        """重要性採樣：保留關鍵訊息"""
        # 計算每條訊息的重要性分數
        scored_messages = []
        for msg in messages:
            score = self.calculate_importance(msg)
            scored_messages.append((score, msg))
        
        # 排序並選擇
        scored_messages.sort(reverse=True)
        selected = []
        total_tokens = 0
        
        for score, msg in scored_messages:
            msg_tokens = self.count_tokens(msg)
            if total_tokens + msg_tokens <= max_tokens:
                selected.append(msg)
                total_tokens += msg_tokens
        
        # 保持時間順序
        return sorted(selected, key=lambda m: messages.index(m))
    
    def calculate_importance(self, message):
        """計算訊息重要性"""
        score = 0.0
        
        # 關鍵詞權重
        keywords = ["決定", "重要", "問題", "錯誤", "確認"]
        for keyword in keywords:
            if keyword in message.get("content", ""):
                score += 0.2
        
        # 用戶訊息權重更高
        if message.get("role") == "user":
            score += 0.3
        
        # 長度懲罰（太長的可能是廢話）
        length = len(message.get("content", ""))
        if length > 500:
            score -= 0.1
        
        # 時間衰減
        # score *= time_decay_factor
        
        return score
```

#### 3.3 記憶管理實戰

```python
class ConversationMemoryManager:
    """對話記憶管理器"""
    
    def __init__(self, model="gpt-4", max_tokens=8000):
        self.model = model
        self.max_tokens = max_tokens
        self.compressor = ContextCompressor()
        
        # 分層記憶
        self.memories = {
            "episodic": [],      # 事件記憶
            "semantic": {},      # 語義記憶
            "working": []        # 工作記憶
        }
    
    def add_turn(self, user_input, assistant_response):
        """添加一輪對話"""
        turn = {
            "user": user_input,
            "assistant": assistant_response,
            "timestamp": datetime.now(),
            "tokens": self.count_tokens(user_input + assistant_response)
        }
        
        # 加入工作記憶
        self.memories["working"].append(turn)
        
        # 檢查是否需要壓縮
        if self.get_total_tokens() > self.max_tokens * 0.8:
            self.compress()
        
        # 提取重要資訊到語義記憶
        self.extract_semantic_memory(turn)
    
    def compress(self):
        """壓縮記憶"""
        # 將舊的工作記憶轉為事件記憶
        if len(self.memories["working"]) > 10:
            # 摘要前 5 輪
            to_compress = self.memories["working"][:5]
            summary = self.create_summary(to_compress)
            
            self.memories["episodic"].append({
                "summary": summary,
                "original_turns": len(to_compress),
                "timestamp": to_compress[0]["timestamp"]
            })
            
            # 移除已壓縮的
            self.memories["working"] = self.memories["working"][5:]
    
    def extract_semantic_memory(self, turn):
        """提取語義記憶（實體、關係、事實）"""
        # 簡化版實體提取
        entities = self.extract_entities(turn["user"])
        for entity in entities:
            if entity not in self.memories["semantic"]:
                self.memories["semantic"][entity] = []
            
            self.memories["semantic"][entity].append({
                "context": turn["assistant"][:100],
                "timestamp": turn["timestamp"]
            })
    
    def get_relevant_context(self, query):
        """獲取相關上下文"""
        context_parts = []
        
        # 1. 相關的語義記憶
        relevant_entities = self.extract_entities(query)
        for entity in relevant_entities:
            if entity in self.memories["semantic"]:
                context_parts.append(
                    f"關於{entity}：{self.memories['semantic'][entity][-1]['context']}"
                )
        
        # 2. 最近的事件記憶
        if self.memories["episodic"]:
            latest_episode = self.memories["episodic"][-1]
            context_parts.append(f"早期對話摘要：{latest_episode['summary']}")
        
        # 3. 完整的工作記憶
        for turn in self.memories["working"][-5:]:  # 最近 5 輪
            context_parts.append(f"User: {turn['user']}")
            context_parts.append(f"Assistant: {turn['assistant']}")
        
        return "\n".join(context_parts)
```

### 🔬 Lab 實作：多輪對話摘要系統

```python
# Lab: 實作一個智慧對話摘要系統
class SmartConversationManager:
    def __init__(self):
        self.memory_manager = ConversationMemoryManager()
        self.token_limit = 4000
        
    async def chat(self, user_input, session_id):
        # 1. 載入 session 記憶
        context = self.memory_manager.get_relevant_context(user_input)
        
        # 2. 檢查 token 數量
        context_tokens = self.count_tokens(context)
        if context_tokens > self.token_limit:
            # 動態壓縮
            context = self.compress_context(context)
        
        # 3. 構建 prompt
        messages = [
            {"role": "system", "content": "你是一個智慧助理。"},
            {"role": "system", "content": f"[Context]: {context}"},
            {"role": "user", "content": user_input}
        ]
        
        # 4. 生成回應
        response = await self.generate_response(messages)
        
        # 5. 更新記憶
        self.memory_manager.add_turn(user_input, response)
        
        # 6. 顯示記憶體使用狀況
        memory_stats = {
            "working_memory_turns": len(self.memory_manager.memories["working"]),
            "episodic_memories": len(self.memory_manager.memories["episodic"]),
            "semantic_entities": len(self.memory_manager.memories["semantic"]),
            "total_tokens": self.memory_manager.get_total_tokens(),
            "compression_ratio": self.calculate_compression_ratio()
        }
        
        return {
            "response": response,
            "memory_stats": memory_stats
        }
    
    def compress_context(self, context):
        """智慧壓縮上下文"""
        strategies = [
            ("summarization", 0.5),
            ("sliding_window", 0.3),
            ("importance_sampling", 0.2)
        ]
        
        # 根據內容特性選擇策略
        if self.is_technical_discussion(context):
            # 技術討論保留更多細節
            return self.memory_manager.compressor.sliding_window(
                context, self.token_limit
            )
        else:
            # 一般對話可以摘要
            return self.memory_manager.compressor.summarize(
                context, self.token_limit
            )

# 測試長對話
manager = SmartConversationManager()
session_id = "test_session_001"

conversation = [
    "我想了解你們的退貨政策",
    "我上週買了一個產品，但是有問題",
    "訂單號是 ORD-12345",
    "產品是藍色的藍牙耳機",
    "問題是左耳常常斷線",
    "我已經試過重置了，沒有用",
    "可以換貨嗎？",
    "如果不能換貨，可以退款嗎？",
    "退款需要多久？",
    "需要支付運費嗎？"
]

for i, msg in enumerate(conversation):
    print(f"\n=== Turn {i+1} ===")
    result = await manager.chat(msg, session_id)
    print(f"User: {msg}")
    print(f"Assistant: {result['response'][:100]}...")
    print(f"Memory Stats: {result['memory_stats']}")
    
    # 模擬記憶體壓力
    if i == 4:
        print("\n[觸發記憶壓縮...]")
```

### 💡 實戰心得
> 💾 **Memory is Money**：每個 token 都是成本。學會壓縮是省錢的關鍵。我們曾經把一個客服系統的成本降低 60%，就是優化了記憶管理。

---

## 📘 模組 4：知識掛載與 RAG 基礎（第 4 週）

### 🎯 學習目標
掌握 RAG 的核心概念和失敗處理——不需要懂向量資料庫原理

### 📚 核心內容

#### 4.1 簡化版 RAG Pipeline

```python
class SimpleRAG:
    """應用工程師版的 RAG 系統"""
    
    def __init__(self):
        # 使用現成的向量資料庫服務
        self.vector_db = Pinecone(api_key="your-key")
        self.embedder = OpenAIEmbeddings()
        
        # 失敗處理策略
        self.fallback_strategies = {
            "no_results": self.handle_no_results,
            "conflicting": self.handle_conflicts,
            "low_confidence": self.handle_low_confidence
        }
    
    def search(self, query, k=5):
        """基礎檢索"""
        # 1. 生成 embedding（不需要懂原理）
        query_embedding = self.embedder.embed(query)
        
        # 2. 向量檢索
        results = self.vector_db.query(
            vector=query_embedding,
            top_k=k,
            include_metadata=True
        )
        
        # 3. 處理檢索失敗
        if not results or results[0].score < 0.7:
            return self.fallback_strategies["no_results"](query)
        
        # 4. 檢查衝突
        if self.has_conflicts(results):
            return self.fallback_strategies["conflicting"](results)
        
        return results
    
    def has_conflicts(self, results):
        """檢測結果是否衝突"""
        # 簡單規則：如果前兩個結果的內容矛盾
        if len(results) >= 2:
            doc1 = results[0].metadata['content']
            doc2 = results[1].metadata['content']
            
            # 用 LLM 檢測矛盾
            prompt = f"""
            Document 1: {doc1}
            Document 2: {doc2}
            
            Do these documents contradict each other? (Yes/No)
            """
            
            response = llm.complete(prompt)
            return "yes" in response.lower()
        
        return False
```

#### 4.2 RAG 失敗處理的藝術

```python
class RAGFailureHandler:
    """RAG 失敗處理專家"""
    
    def handle_no_results(self, query):
        """找不到相關文件"""
        strategies = [
            self.try_rephrase,        # 改寫查詢
            self.try_decompose,       # 拆解查詢
            self.try_generalize,      # 泛化查詢
            self.fallback_to_llm      # 直接用 LLM
        ]
        
        for strategy in strategies:
            result = strategy(query)
            if result["success"]:
                return result["data"]
        
        # 優雅失敗
        return {
            "found": False,
            "message": "抱歉，我在知識庫中找不到相關資訊。讓我用一般知識來回答...",
            "fallback_response": self.generate_general_response(query)
        }
    
    def try_rephrase(self, query):
        """改寫查詢詞"""
        rephrases = [
            f"換句話說：{query}",
            f"相關於：{query}",
            f"關於{self.extract_keywords(query)}"
        ]
        
        for rephrase in rephrases:
            results = self.search(rephrase)
            if results:
                return {"success": True, "data": results}
        
        return {"success": False}
    
    def handle_conflicts(self, conflicting_results):
        """處理矛盾的結果"""
        # 策略 1：顯示所有觀點
        response = "我找到了不同的資訊：\n"
        for i, result in enumerate(conflicting_results[:2]):
            response += f"\n觀點 {i+1}：{result.metadata['content'][:200]}...\n"
        response += "\n請注意這些資訊可能有所差異。"
        
        # 策略 2：讓 LLM 綜合判斷
        synthesis_prompt = f"""
        以下是關於同一問題的不同資料：
        {[r.metadata['content'] for r in conflicting_results]}
        
        請綜合這些資訊，給出平衡的答案。
        """
        
        synthesized = llm.complete(synthesis_prompt)
        
        return {
            "has_conflicts": True,
            "all_views": response,
            "synthesis": synthesized
        }
    
    def handle_low_confidence(self, results):
        """處理低信心度結果"""
        disclaimer = "⚠️ 以下資訊可能不完全準確，僅供參考：\n\n"
        
        # 加入信心度指示
        enriched_response = ""
        for result in results:
            confidence = result.score
            if confidence > 0.9:
                confidence_indicator = "✅ 高度相關"
            elif confidence > 0.7:
                confidence_indicator = "⚠️ 部分相關"
            else:
                confidence_indicator = "❌ 相關性較低"
            
            enriched_response += f"{confidence_indicator}: {result.metadata['content']}\n\n"
        
        return disclaimer + enriched_response
```

#### 4.3 Chunking 策略（簡化版）

```python
class SimpleChunker:
    """文件切塊器 - 應用層面就夠了"""
    
    def __init__(self, chunk_size=500, overlap=50):
        self.chunk_size = chunk_size
        self.overlap = overlap
    
    def chunk_document(self, document):
        """基礎切塊策略"""
        chunks = []
        
        # 策略 1：按段落切
        paragraphs = document.split('\n\n')
        
        current_chunk = ""
        for para in paragraphs:
            if len(current_chunk) + len(para) < self.chunk_size:
                current_chunk += para + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para + "\n\n"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # 加入 overlap
        chunks_with_overlap = []
        for i, chunk in enumerate(chunks):
            if i > 0:
                # 加入前一塊的結尾
                prev_end = chunks[i-1][-self.overlap:] if len(chunks[i-1]) > self.overlap else chunks[i-1]
                chunk = prev_end + "\n...\n" + chunk
            
            if i < len(chunks) - 1:
                # 加入下一塊的開頭
                next_start = chunks[i+1][:self.overlap] if len(chunks[i+1]) > self.overlap else chunks[i+1]
                chunk = chunk + "\n...\n" + next_start
            
            chunks_with_overlap.append(chunk)
        
        return chunks_with_overlap
```

### 🔬 Lab 實作：FAQ Bot with Fallback

```python
# Lab: 建立一個有完善 fallback 的 FAQ Bot
class SmartFAQBot:
    def __init__(self):
        self.rag = SimpleRAG()
        self.failure_handler = RAGFailureHandler()
        self.response_cache = {}
        
        # 預載入 FAQ
        self.load_faqs()
    
    def load_faqs(self):
        """載入常見問題"""
        faqs = [
            {
                "question": "如何退貨？",
                "answer": "您可以在收到商品後 7 天內申請退貨...",
                "keywords": ["退貨", "退款", "return"]
            },
            {
                "question": "運費怎麼算？",
                "answer": "運費根據地區和重量計算...",
                "keywords": ["運費", "配送", "shipping"]
            }
        ]
        
        for faq in faqs:
            # 向量化並存入資料庫
            embedding = self.rag.embedder.embed(faq["question"])
            self.rag.vector_db.upsert(
                id=f"faq_{hash(faq['question'])}",
                vector=embedding,
                metadata=faq
            )
    
    async def answer(self, question):
        # 1. 檢查 cache
        if question in self.response_cache:
            return self.response_cache[question]
        
        # 2. RAG 檢索
        results = self.rag.search(question, k=3)
        
        # 3. 處理各種情況
        if isinstance(results, dict):
            if not results.get("found", True):
                # 沒找到：使用 fallback
                response = await self.generate_fallback_response(question)
            elif results.get("has_conflicts"):
                # 有衝突：顯示多個觀點
                response = self.format_conflicting_response(results)
            else:
                # 低信心度
                response = results
        else:
            # 正常情況：基於檢索結果生成答案
            response = await self.generate_answer(question, results)
        
        # 4. 快取結果
        self.response_cache[question] = response
        
        # 5. 記錄 metrics
        self.log_metrics(question, results, response)
        
        return response
    
    async def generate_answer(self, question, search_results):
        """基於檢索結果生成答案"""
        context = "\n".join([r.metadata['answer'] for r in search_results[:2]])
        
        prompt = f"""
        基於以下資訊回答用戶問題：
        
        資訊：
        {context}
        
        用戶問題：{question}
        
        要求：
        1. 如果資訊足夠，直接回答
        2. 如果資訊不足，說明哪部分無法回答
        3. 保持友善專業的語氣
        """
        
        return await llm.complete(prompt)
    
    async def generate_fallback_response(self, question):
        """生成 fallback 回應"""
        # 多層 fallback
        fallbacks = [
            # Level 1: 嘗試用通用知識
            lambda: llm.complete(f"用一般知識回答：{question}"),
            
            # Level 2: 提供相關連結
            lambda: f"我無法直接回答您的問題，但您可以查看我們的幫助中心：https://help.example.com",
            
            # Level 3: 轉人工
            lambda: "這個問題較為複雜，建議您聯繫客服人員。是否需要我幫您轉接？"
        ]
        
        for fallback in fallbacks:
            try:
                return fallback()
            except:
                continue
        
        return "抱歉，我暫時無法回答這個問題。"

# 測試各種場景
bot = SmartFAQBot()

test_cases = [
    "如何退貨？",           # 正常匹配
    "退貨政策是什麼？",     # 需要改寫
    "你們賣火箭嗎？",       # 完全無關
    "退貨和換貨的區別？",   # 部分匹配
    "Can I return this?",   # 其他語言
]

for question in test_cases:
    print(f"\n問題：{question}")
    answer = await bot.answer(question)
    print(f"回答：{answer[:200]}...")
    print("-" * 50)
```

### 💡 實戰心得
> 🎯 **RAG 的精髓不是檢索，而是失敗處理**。一個好的 RAG 系統，80% 的程式碼都在處理「沒找到」或「找錯了」的情況。

---

## 📘 模組 5：產品思維 for LLM Apps（第 5 週）

### 🎯 學習目標
培養產品思維，知道何時該用/不該用 LLM

### 📚 核心內容

#### 5.1 LLM 的能力矩陣

| 任務類型 | 適合用 LLM | 不適合用 LLM | 替代方案 |
|---------|-----------|-------------|---------|
| **創意生成** | ✅ 文案、故事、點子 | ❌ 需要事實準確的內容 | 人工創作 + LLM 輔助 |
| **格式轉換** | ✅ JSON↔自然語言 | ❌ 複雜的資料轉換 | 專門的 Parser |
| **分類任務** | ✅ 情感分析、主題分類 | ❌ 需要 100% 準確率 | 傳統 ML 模型 |
| **計算任務** | ✅ 簡單估算 | ❌ 精確計算 | Calculator API |
| **搜尋任務** | ✅ 語義搜尋 | ❌ 精確匹配 | 傳統搜尋引擎 |
| **決策任務** | ✅ 建議、推薦 | ❌ 關鍵決策 | 規則引擎 + 人工 |

#### 5.2 成本-延遲-體驗三角

```python
class ProductDecisionFramework:
    """產品決策框架"""
    
    def __init__(self):
        self.metrics = {
            "cost": {"weight": 0.3, "threshold": 0.1},      # $0.1 per request
            "latency": {"weight": 0.3, "threshold": 2000},  # 2 seconds
            "quality": {"weight": 0.4, "threshold": 0.85}   # 85% satisfaction
        }
    
    def evaluate_llm_fit(self, use_case):
        """評估是否適合用 LLM"""
        score = 0
        reasons = []
        
        # 正面因素
        if use_case["requires_creativity"]:
            score += 30
            reasons.append("✅ 需要創意生成")
        
        if use_case["handles_natural_language"]:
            score += 25
            reasons.append("✅ 處理自然語言")
        
        if use_case["needs_flexibility"]:
            score += 20
            reasons.append("✅ 需要靈活性")
        
        # 負面因素
        if use_case["requires_deterministic"]:
            score -= 40
            reasons.append("❌ 需要確定性結果")
        
        if use_case["cost_sensitive"]:
            score -= 30
            reasons.append("❌ 成本敏感")
        
        if use_case["latency_critical"]:
            score -= 25
            reasons.append("❌ 延遲關鍵")
        
        # 決策
        recommendation = "USE_LLM" if score > 0 else "AVOID_LLM"
        
        return {
            "score": score,
            "recommendation": recommendation,
            "reasons": reasons,
            "alternative": self.suggest_alternative(use_case) if score < 0 else None
        }
    
    def suggest_alternative(self, use_case):
        """建議替代方案"""
        if use_case["requires_deterministic"]:
            return "使用規則引擎或傳統演算法"
        elif use_case["cost_sensitive"]:
            return "使用快取層 + 小模型"
        elif use_case["latency_critical"]:
            return "預生成 + Edge 部署"
        else:
            return "混合方案：關鍵路徑用傳統方法，輔助功能用 LLM"
```

#### 5.3 優雅降級策略

```python
class GracefulDegradation:
    """優雅降級系統"""
    
    def __init__(self):
        self.strategies = [
            self.try_primary,      # 主要策略：完整 LLM
            self.try_cache,        # 快取策略
            self.try_simple_model, # 簡單模型
            self.try_template,     # 模板回覆
            self.try_human         # 人工介入
        ]
        
        self.cache = ResponseCache()
        self.template_engine = TemplateEngine()
    
    async def handle_request(self, request):
        """多層降級處理"""
        start_time = time.time()
        
        for i, strategy in enumerate(self.strategies):
            try:
                # 設定超時
                timeout = self.calculate_timeout(i)
                
                result = await asyncio.wait_for(
                    strategy(request),
                    timeout=timeout
                )
                
                if result["success"]:
                    # 記錄使用了哪個策略
                    result["strategy_used"] = strategy.__name__
                    result["degradation_level"] = i
                    result["total_time"] = time.time() - start_time
                    
                    return result
                    
            except asyncio.TimeoutError:
                print(f"Strategy {strategy.__name__} timeout")
                continue
            except Exception as e:
                print(f"Strategy {strategy.__name__} failed: {e}")
                continue
        
        # 所有策略都失敗
        return self.final_fallback(request)
    
    async def try_primary(self, request):
        """主要策略：完整 LLM 處理"""
        response = await llm.complete(
            request["prompt"],
            model="gpt-4",
            temperature=0.7
        )
        
        return {
            "success": True,
            "response": response,
            "quality": "high"
        }
    
    async def try_cache(self, request):
        """快取策略"""
        # 語義相似度快取
        cached = self.cache.get_similar(request["prompt"], threshold=0.95)
        
        if cached:
            return {
                "success": True,
                "response": cached["response"],
                "quality": "cached",
                "cache_hit": True
            }
        
        return {"success": False}
    
    async def try_simple_model(self, request):
        """使用更簡單的模型"""
        response = await llm.complete(
            request["prompt"],
            model="gpt-3.5-turbo",  # 降級到更快更便宜的模型
            temperature=0.5,
            max_tokens=150
        )
        
        return {
            "success": True,
            "response": response,
            "quality": "medium"
        }
    
    async def try_template(self, request):
        """模板回覆"""
        # 意圖識別
        intent = self.classify_intent(request["prompt"])
        
        if intent in self.template_engine.templates:
            response = self.template_engine.generate(intent, request)
            return {
                "success": True,
                "response": response,
                "quality": "template"
            }
        
        return {"success": False}
    
    async def try_human(self, request):
        """轉人工"""
        # 創建工單
        ticket = self.create_support_ticket(request)
        
        response = f"""
        您的問題較為複雜，我已經為您創建了工單 #{ticket['id']}。
        客服人員將在 30 分鐘內與您聯繫。
        
        您也可以直接撥打客服熱線：400-XXX-XXXX
        """
        
        return {
            "success": True,
            "response": response,
            "quality": "human_escalation",
            "ticket": ticket
        }
    
    def calculate_timeout(self, level):
        """根據降級等級計算超時時間"""
        timeouts = [3.0, 1.0, 0.5, 0.2, 0.1]  # 逐級降低
        return timeouts[min(level, len(timeouts) - 1)]
```

### 🔬 Lab 實作：降級策略設計與測試

```python
# Lab: 設計並測試降級策略
class DegradationTestBench:
    """降級策略測試平台"""
    
    def __init__(self):
        self.degradation = GracefulDegradation()
        self.metrics = {
            "success_rate": [],
            "response_time": [],
            "quality_score": [],
            "cost": []
        }
    
    async def simulate_load(self, requests_per_second=10, duration=60):
        """模擬負載測試"""
        tasks = []
        
        for i in range(duration):
            for j in range(requests_per_second):
                # 模擬不同類型的請求
                request = self.generate_request()
                
                # 隨機注入故障
                if random.random() < 0.1:  # 10% 故障率
                    request["inject_failure"] = True
                
                task = self.process_request(request)
                tasks.append(task)
            
            await asyncio.sleep(1)
        
        results = await asyncio.gather(*tasks)
        self.analyze_results(results)
    
    async def process_request(self, request):
        """處理單個請求"""
        start = time.time()
        
        # 模擬網路問題
        if request.get("inject_failure"):
            await asyncio.sleep(random.uniform(5, 10))  # 超時
        
        result = await self.degradation.handle_request(request)
        
        # 記錄 metrics
        self.metrics["response_time"].append(time.time() - start)
        self.metrics["success_rate"].append(1 if result["success"] else 0)
        self.metrics["quality_score"].append(
            self.calculate_quality_score(result)
        )
        self.metrics["cost"].append(
            self.calculate_cost(result)
        )
        
        return result
    
    def calculate_quality_score(self, result):
        """計算品質分數"""
        quality_map = {
            "high": 1.0,
            "cached": 0.9,
            "medium": 0.7,
            "template": 0.5,
            "human_escalation": 0.3
        }
        return quality_map.get(result.get("quality", "unknown"), 0)
    
    def calculate_cost(self, result):
        """計算成本"""
        cost_map = {
            "try_primary": 0.03,      # GPT-4
            "try_cache": 0.0001,      # 幾乎免費
            "try_simple_model": 0.002, # GPT-3.5
            "try_template": 0,         # 免費
            "try_human": 5.0          # 人工成本
        }
        
        strategy = result.get("strategy_used", "unknown")
        return cost_map.get(strategy, 0)
    
    def analyze_results(self, results):
        """分析測試結果"""
        print("\n=== 降級策略測試報告 ===\n")
        
        # 成功率
        success_rate = sum(self.metrics["success_rate"]) / len(self.metrics["success_rate"])
        print(f"✅ 成功率: {success_rate:.2%}")
        
        # 響應時間
        avg_response = sum(self.metrics["response_time"]) / len(self.metrics["response_time"])
        p95_response = sorted(self.metrics["response_time"])[int(len(self.metrics["response_time"]) * 0.95)]
        print(f"⏱️ 平均響應時間: {avg_response:.2f}秒")
        print(f"⏱️ P95 響應時間: {p95_response:.2f}秒")
        
        # 品質分數
        avg_quality = sum(self.metrics["quality_score"]) / len(self.metrics["quality_score"])
        print(f"⭐ 平均品質分數: {avg_quality:.2f}/1.0")
        
        # 成本
        total_cost = sum(self.metrics["cost"])
        avg_cost = total_cost / len(self.metrics["cost"])
        print(f"💰 總成本: ${total_cost:.2f}")
        print(f"💰 平均成本: ${avg_cost:.4f}/request")
        
        # 策略使用分布
        strategy_counts = {}
        for result in results:
            strategy = result.get("strategy_used", "unknown")
            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
        
        print("\n📊 策略使用分布:")
        for strategy, count in sorted(strategy_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(results) * 100
            print(f"  - {strategy}: {count} ({percentage:.1f}%)")
        
        # 成本效益分析
        cost_per_quality = total_cost / (avg_quality * len(results))
        print(f"\n💡 成本效益比: ${cost_per_quality:.4f}/quality point")
        
        # 建議
        print("\n🎯 優化建議:")
        if avg_response > 2:
            print("  - 響應時間過長，考慮增加快取或使用更快的模型")
        if avg_quality < 0.7:
            print("  - 品質分數偏低，考慮調整降級閾值")
        if avg_cost > 0.01:
            print("  - 成本偏高，增加快取命中率或使用更多模板")

# 執行測試
test_bench = DegradationTestBench()
await test_bench.simulate_load(requests_per_second=5, duration=30)
```

### 💡 實戰心得
> 🎯 **黃金法則**：永遠不要讓 LLM 成為單點故障。每個 LLM 呼叫都應該有至少 2 層 fallback。

---

## 📘 模組 6：應用級 Workflow（第 6 週）

### 🎯 學習目標
設計多步驟任務流程，處理真實世界的髒資料

### 📚 核心內容

#### 6.1 Chain 思維設計模式

```python
class WorkflowChain:
    """工作流鏈設計"""
    
    def __init__(self):
        self.steps = []
        self.error_handlers = {}
        self.validators = {}
    
    def add_step(self, name, function, validator=None, error_handler=None):
        """添加步驟"""
        self.steps.append({
            "name": name,
            "function": function
        })
        
        if validator:
            self.validators[name] = validator
        if error_handler:
            self.error_handlers[name] = error_handler
        
        return self  # 支援鏈式呼叫
    
    async def execute(self, input_data):
        """執行工作流"""
        context = {"input": input_data, "steps": {}}
        
        for step in self.steps:
            step_name = step["name"]
            print(f"執行步驟: {step_name}")
            
            try:
                # 執行步驟
                result = await step["function"](context)
                
                # 驗證結果
                if step_name in self.validators:
                    is_valid = self.validators[step_name](result)
                    if not is_valid:
                        raise ValueError(f"Validation failed for {step_name}")
                
                # 儲存結果
                context["steps"][step_name] = result
                
            except Exception as e:
                # 錯誤處理
                if step_name in self.error_handlers:
                    result = self.error_handlers[step_name](e, context)
                    context["steps"][step_name] = result
                else:
                    raise
        
        return context
```

#### 6.2 髒資料處理大全

```python
class DirtyDataProcessor:
    """髒資料處理專家"""
    
    def __init__(self):
        self.cleaners = {
            "typo": self.fix_typos,
            "mixed_language": self.handle_mixed_language,
            "emotional": self.handle_emotional_input,
            "incomplete": self.handle_incomplete,
            "contradictory": self.handle_contradictory
        }
    
    def clean(self, dirty_input):
        """清理髒資料"""
        cleaned = dirty_input
        issues_found = []
        
        # 檢測並修復各種問題
        for issue_type, cleaner in self.cleaners.items():
            if self.detect_issue(cleaned, issue_type):
                cleaned = cleaner(cleaned)
                issues_found.append(issue_type)
        
        return {
            "original": dirty_input,
            "cleaned": cleaned,
            "issues_found": issues_found,
            "confidence": self.calculate_confidence(issues_found)
        }
    
    def fix_typos(self, text):
        """修正錯字"""
        # 簡單的錯字修正
        common_typos = {
            "teh": "the",
            "recieve": "receive",
            "occured": "occurred",
            "refund": "refund",  
            "cancle": "cancel"
        }
        
        for typo, correct in common_typos.items():
            text = text.replace(typo, correct)
        
        # 使用 LLM 修正更複雜的錯字
        if self.has_potential_typos(text):
            prompt = f"""
            修正以下文字中的錯字，但保持原意：
            原文：{text}
            修正後：
            """
            text = llm.complete(prompt, temperature=0.1)
        
        return text
    
    def handle_mixed_language(self, text):
        """處理混合語言"""
        # 檢測語言
        languages = self.detect_languages(text)
        
        if len(languages) > 1:
            # 策略 1：翻譯成主要語言
            primary_lang = max(languages.items(), key=lambda x: x[1])[0]
            
            prompt = f"""
            將以下混合語言文字統一翻譯成{primary_lang}：
            {text}
            """
            
            return llm.complete(prompt)
        
        return text
    
    def handle_emotional_input(self, text):
        """處理情緒化輸入"""
        emotion_score = self.detect_emotion(text)
        
        if emotion_score > 0.7:  # 高度情緒化
            # 提取核心訴求
            prompt = f"""
            用戶情緒激動地說：{text}
            
            請提取用戶的核心訴求（忽略情緒化表達）：
            """
            
            core_request = llm.complete(prompt)
            
            return {
                "original": text,
                "emotion_level": "high",
                "core_request": core_request,
                "suggested_response_tone": "empathetic"
            }
        
        return text
    
    def handle_incomplete(self, text):
        """處理不完整輸入"""
        if len(text.split()) < 3:  # 太短
            return {
                "original": text,
                "issue": "incomplete",
                "clarification_needed": True,
                "suggested_questions": [
                    "您能詳細說明一下嗎？",
                    "請問具體是什麼問題？",
                    "能提供更多資訊嗎？"
                ]
            }
        
        return text
```

#### 6.3 Agent-like Flow 設計

```python
class SimpleAgent:
    """簡單 Agent 流程"""
    
    def __init__(self):
        self.tools = {
            "search_order": self.search_order,
            "check_inventory": self.check_inventory,
            "calculate_shipping": self.calculate_shipping,
            "process_refund": self.process_refund
        }
        
        self.planner = TaskPlanner()
        self.executor = TaskExecutor()
    
    async def process(self, user_request):
        """處理用戶請求"""
        
        # 1. 理解意圖
        intent = await self.understand_intent(user_request)
        
        # 2. 規劃步驟
        plan = await self.planner.create_plan(intent, self.tools.keys())
        
        # 3. 執行計劃
        results = []
        for step in plan["steps"]:
            result = await self.execute_step(step)
            results.append(result)
            
            # 動態調整計劃
            if result.get("requires_replanning"):
                plan = await self.planner.replan(plan, results)
        
        # 4. 綜合結果
        final_response = await self.synthesize_response(results)
        
        return final_response
    
    async def understand_intent(self, request):
        """理解用戶意圖"""
        prompt = f"""
        分析用戶請求並識別意圖：
        
        用戶說：{request}
        
        可能的意圖：
        - ORDER_STATUS: 查詢訂單狀態
        - REFUND_REQUEST: 申請退款
        - PRODUCT_INQUIRY: 產品諮詢
        - SHIPPING_INFO: 運送資訊
        - COMPLAINT: 投訴
        - OTHER: 其他
        
        返回格式：
        {{
            "primary_intent": "...",
            "entities": {{...}},
            "confidence": 0.X
        }}
        """
        
        response = await llm.complete(prompt)
        return json.loads(response)
    
    async def execute_step(self, step):
        """執行單個步驟"""
        tool_name = step["tool"]
        params = step["params"]
        
        if tool_name not in self.tools:
            return {"error": f"Tool {tool_name} not found"}
        
        try:
            result = await self.tools[tool_name](**params)
            return {"success": True, "data": result}
        except Exception as e:
            return {"success": False, "error": str(e)}
```

### 🔬 Lab 實作：訂單查詢助理

```python
# Lab: 能處理混合語言和模糊輸入的訂單助理
class SmartOrderAssistant:
    def __init__(self):
        self.workflow = WorkflowChain()
        self.data_processor = DirtyDataProcessor()
        self.agent = SimpleAgent()
        
        # 設定工作流
        self.setup_workflow()
    
    def setup_workflow(self):
        """設定工作流程"""
        self.workflow \
            .add_step("clean_input", self.clean_input) \
            .add_step("extract_info", self.extract_order_info) \
            .add_step("search_order", self.search_order) \
            .add_step("check_status", self.check_order_status) \
            .add_step("generate_response", self.generate_response)
    
    async def clean_input(self, context):
        """步驟 1：清理輸入"""
        raw_input = context["input"]
        
        # 處理髒資料
        cleaned = self.data_processor.clean(raw_input)
        
        # 處理特殊情況
        if "mixed_language" in cleaned["issues_found"]:
            # 統一語言
            cleaned["cleaned"] = await self.translate_to_primary(cleaned["cleaned"])
        
        if "emotional" in cleaned["issues_found"]:
            # 記錄情緒狀態
            context["emotional_state"] = "high"
            context["response_tone"] = "empathetic"
        
        return cleaned
    
    async def extract_order_info(self, context):
        """步驟 2：提取訂單資訊"""
        cleaned_input = context["steps"]["clean_input"]["cleaned"]
        
        prompt = f"""
        從以下文字中提取訂單相關資訊：
        {cleaned_input}
        
        提取：
        - order_id: 訂單號（如果有）
        - product_name: 產品名稱
        - issue: 問題描述
        - date: 相關日期
        
        如果資訊不完整，標記 needs_clarification: true
        """
        
        extracted = await llm.complete(prompt, response_format={"type": "json"})
        
        # 驗證提取結果
        if not extracted.get("order_id"):
            # 嘗試模糊匹配
            extracted["possible_orders"] = await self.fuzzy_search_orders(cleaned_input)
        
        return extracted
    
    async def search_order(self, context):
        """步驟 3：搜尋訂單"""
        order_info = context["steps"]["extract_info"]
        
        if order_info.get("order_id"):
            # 精確搜尋
            order = await self.db.find_order(order_info["order_id"])
        elif order_info.get("possible_orders"):
            # 讓用戶確認
            return {
                "found_multiple": True,
                "orders": order_info["possible_orders"],
                "needs_confirmation": True
            }
        else:
            # 根據其他資訊搜尋
            orders = await self.db.search_orders(
                customer_id=context.get("customer_id"),
                product=order_info.get("product_name"),
                date_range=self.parse_date_range(order_info.get("date"))
            )
            
            if len(orders) == 1:
                order = orders[0]
            elif len(orders) > 1:
                return {"found_multiple": True, "orders": orders}
            else:
                return {"found": False}
        
        return {"found": True, "order": order}
    
    async def generate_response(self, context):
        """步驟 5：生成回應"""
        order_result = context["steps"]["search_order"]
        
        # 根據不同情況生成回應
        if not order_result.get("found"):
            response = "抱歉，我找不到相關訂單。請確認訂單號或提供更多資訊。"
        elif order_result.get("found_multiple"):
            response = self.format_multiple_orders(order_result["orders"])
        else:
            order = order_result["order"]
            status = context["steps"]["check_status"]
            response = self.format_order_status(order, status)
        
        # 根據情緒狀態調整語氣
        if context.get("emotional_state") == "high":
            response = self.add_empathy(response)
        
        return response
    
    async def handle_user_input(self, user_input):
        """主入口：處理用戶輸入"""
        
        # 測試各種髒輸入
        test_inputs = [
            "我的訂單（訂單號：ORD12345）到哪了？？？",  # 正常
            "Check my order status ORDER12345 謝謝",      # 混合語言
            "wtf 我的東西呢！！！都三天了！！！",         # 情緒化
            "訂單",                                        # 不完整
            "我上週買的藍牙耳機怎麼還沒到",                # 模糊
            "ORD1234... 不對是 ORD12346",                 # 矛盾
        ]
        
        results = []
        for test_input in test_inputs:
            print(f"\n處理輸入: {test_input}")
            
            try:
                result = await self.workflow.execute(test_input)
                response = result["steps"]["generate_response"]
                
                print(f"清理後: {result['steps']['clean_input']['cleaned']}")
                print(f"提取資訊: {result['steps']['extract_info']}")
                print(f"回應: {response}")
                
                results.append({
                    "input": test_input,
                    "success": True,
                    "response": response
                })
                
            except Exception as e:
                print(f"錯誤: {e}")
                results.append({
                    "input": test_input,
                    "success": False,
                    "error": str(e)
                })
        
        # 統計成功率
        success_rate = sum(1 for r in results if r["success"]) / len(results)
        print(f"\n成功率: {success_rate:.1%}")
        
        return results

# 執行測試
assistant = SmartOrderAssistant()
results = await assistant.handle_user_input("測試輸入")
```

### 💡 實戰心得
> 🔧 **髒資料是常態，不是例外**。一個產品級的 LLM 應用，50% 的程式碼都在處理各種邊界情況。

---

## 📘 模組 7：可靠性與可觀測性（第 7 週）

### 🎯 學習目標
建立監控體系，優化成本與性能

### 📚 核心內容

#### 7.1 成本工程實戰

```python
class CostEngineering:
    """成本工程系統"""
    
    def __init__(self):
        self.token_prices = {
            "gpt-4": {"input": 0.03, "output": 0.06},      # per 1K tokens
            "gpt-3.5-turbo": {"input": 0.001, "output": 0.002},
            "claude-3-opus": {"input": 0.015, "output": 0.075},
            "claude-3-sonnet": {"input": 0.003, "output": 0.015}
        }
        
        self.optimizers = {
            "batching": BatchingOptimizer(),
            "caching": CachingOptimizer(),
            "routing": ModelRouter(),
            "compression": PromptCompressor()
        }
    
    def optimize_request(self, request):
        """優化單個請求"""
        original_cost = self.estimate_cost(request)
        optimized = request.copy()
        
        # 1. 壓縮 Prompt
        optimized["prompt"] = self.optimizers["compression"].compress(
            request["prompt"]
        )
        
        # 2. 選擇最佳模型
        optimized["model"] = self.optimizers["routing"].select_model(
            task_type=request["task_type"],
            quality_requirement=request.get("quality", 0.8),
            budget=request.get("budget", float('inf'))
        )
        
        # 3. 檢查快取
        cached = self.optimizers["caching"].get(optimized["prompt"])
        if cached:
            return {
                "response": cached,
                "cost": 0,
                "source": "cache",
                "savings": original_cost
            }
        
        # 4. 批次處理
        if self.optimizers["batching"].should_batch(optimized):
            batch_id = self.optimizers["batching"].add_to_batch(optimized)
            return {
                "batch_id": batch_id,
                "estimated_wait": self.optimizers["batching"].estimate_wait(),
                "estimated_savings": original_cost * 0.3
            }
        
        final_cost = self.estimate_cost(optimized)
        
        return {
            "optimized_request": optimized,
            "original_cost": original_cost,
            "optimized_cost": final_cost,
            "savings": original_cost - final_cost,
            "savings_percentage": (original_cost - final_cost) / original_cost * 100
        }
    
    def estimate_cost(self, request):
        """估算成本"""
        model = request["model"]
        prompt_tokens = self.count_tokens(request["prompt"])
        
        # 估算輸出 tokens（經驗值）
        estimated_output = prompt_tokens * 0.8
        
        input_cost = (prompt_tokens / 1000) * self.token_prices[model]["input"]
        output_cost = (estimated_output / 1000) * self.token_prices[model]["output"]
        
        return input_cost + output_cost
```

#### 7.2 可觀測性架構

```python
class ObservabilitySystem:
    """可觀測性系統"""
    
    def __init__(self):
        self.metrics = MetricsCollector()
        self.tracer = DistributedTracer()
        self.logger = StructuredLogger()
        self.profiler = PerformanceProfiler()
        
        # 關鍵指標
        self.key_metrics = {
            "latency": {"threshold": 2000, "unit": "ms"},
            "error_rate": {"threshold": 0.01, "unit": "%"},
            "token_cost": {"threshold": 0.1, "unit": "$"},
            "user_satisfaction": {"threshold": 0.85, "unit": "score"}
        }
    
    def trace_request(self, request_id):
        """追蹤請求全流程"""
        
        @self.tracer.span("llm_request")
        async def traced_execution():
            span = self.tracer.current_span()
            
            # 記錄請求屬性
            span.set_attributes({
                "request.id": request_id,
                "request.model": request.get("model"),
                "request.prompt_length": len(request.get("prompt", "")),
                "request.timestamp": datetime.now().isoformat()
            })
            
            try:
                # Prompt 處理階段
                with self.tracer.span("prompt_processing"):
                    prompt = await self.process_prompt(request)
                    span.set_attribute("prompt.tokens", self.count_tokens(prompt))
                
                # LLM 呼叫階段
                with self.tracer.span("llm_call"):
                    start_time = time.time()
                    response = await self.call_llm(prompt)
                    latency = (time.time() - start_time) * 1000
                    
                    span.set_attributes({
                        "llm.latency_ms": latency,
                        "llm.response_tokens": self.count_tokens(response),
                        "llm.total_tokens": self.count_tokens(prompt + response)
                    })
                
                # 後處理階段
                with self.tracer.span("post_processing"):
                    final_response = await self.post_process(response)
                
                # 記錄成功metrics
                self.metrics.record("request_success", 1)
                self.metrics.record("request_latency", latency)
                
                return final_response
                
            except Exception as e:
                # 記錄錯誤
                span.set_status("ERROR")
                span.set_attribute("error.message", str(e))
                
                self.metrics.record("request_error", 1)
                self.logger.error(f"Request failed: {e}", extra={
                    "request_id": request_id,
                    "error_type": type(e).__name__
                })
                
                raise
        
        return await traced_execution()
```

#### 7.3 A/B 測試框架

```python
class ABTestingFramework:
    """A/B 測試框架"""
    
    def __init__(self):
        self.experiments = {}
        self.results = defaultdict(lambda: {
            "impressions": 0,
            "conversions": 0,
            "total_latency": 0,
            "total_cost": 0,
            "errors": 0
        })
    
    def create_experiment(self, name, variants):
        """創建實驗"""
        self.experiments[name] = {
            "variants": variants,
            "traffic_split": self.calculate_traffic_split(len(variants)),
            "created_at": datetime.now(),
            "status": "running"
        }
    
    async def run_variant(self, experiment_name, user_id):
        """執行變體"""
        experiment = self.experiments[experiment_name]
        
        # 分配變體
        variant = self.assign_variant(user_id, experiment)
        variant_config = experiment["variants"][variant]
        
        # 執行並追蹤
        start_time = time.time()
        try:
            # 根據變體配置執行
            result = await self.execute_variant(variant_config)
            
            # 記錄成功metrics
            self.results[f"{experiment_name}_{variant}"]["impressions"] += 1
            self.results[f"{experiment_name}_{variant}"]["total_latency"] += (time.time() - start_time)
            
            # 計算成本
            cost = self.calculate_cost(variant_config, result)
            self.results[f"{experiment_name}_{variant}"]["total_cost"] += cost
            
            return result
            
        except Exception as e:
            self.results[f"{experiment_name}_{variant}"]["errors"] += 1
            raise
    
    def analyze_experiment(self, experiment_name):
        """分析實驗結果"""
        experiment = self.experiments[experiment_name]
        analysis = {}
        
        for variant in experiment["variants"]:
            key = f"{experiment_name}_{variant}"
            data = self.results[key]
            
            if data["impressions"] > 0:
                analysis[variant] = {
                    "conversion_rate": data["conversions"] / data["impressions"],
                    "avg_latency": data["total_latency"] / data["impressions"],
                    "avg_cost": data["total_cost"] / data["impressions"],
                    "error_rate": data["errors"] / data["impressions"],
                    "sample_size": data["impressions"]
                }
                
                # 計算統計顯著性
                if len(analysis) > 1:
                    analysis[variant]["statistical_significance"] = \
                        self.calculate_significance(analysis)
        
        # 推薦獲勝者
        winner = self.recommend_winner(analysis)
        
        return {
            "analysis": analysis,
            "winner": winner,
            "confidence": self.calculate_confidence(analysis),
            "recommendation": self.generate_recommendation(analysis, winner)
        }
```

### 🔬 Lab 實作：成本優化實驗

```python
# Lab: Streaming vs Batch 實驗
class StreamingVsBatchExperiment:
    def __init__(self):
        self.ab_test = ABTestingFramework()
        self.cost_engine = CostEngineering()
        self.observability = ObservabilitySystem()
        
        # 定義實驗變體
        self.setup_experiment()
    
    def setup_experiment(self):
        """設定實驗"""
        self.ab_test.create_experiment(
            name="streaming_vs_batch",
            variants={
                "streaming": {
                    "mode": "streaming",
                    "model": "gpt-3.5-turbo",
                    "batch_size": 1,
                    "timeout": 30
                },
                "batch_small": {
                    "mode": "batch",
                    "model": "gpt-3.5-turbo",
                    "batch_size": 5,
                    "timeout": 10
                },
                "batch_large": {
                    "mode": "batch",
                    "model": "gpt-3.5-turbo",
                    "batch_size": 20,
                    "timeout": 5
                }
            }
        )
    
    async def run_test(self, num_requests=100):
        """執行測試"""
        tasks = []
        
        for i in range(num_requests):
            user_id = f"user_{i % 10}"  # 模擬 10 個用戶
            
            # 創建測試請求
            request = {
                "prompt": f"Test prompt {i}: Explain quantum computing",
                "user_id": user_id,
                "timestamp": datetime.now()
            }
            
            # 執行實驗
            task = self.process_with_monitoring(request, user_id)
            tasks.append(task)
            
            # 模擬真實流量
            await asyncio.sleep(random.uniform(0.1, 0.5))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 分析結果
        self.analyze_results(results)
    
    async def process_with_monitoring(self, request, user_id):
        """帶監控的處理"""
        
        # 開始追蹤
        with self.observability.tracer.span("experiment_request") as span:
            span.set_attribute("user_id", user_id)
            
            try:
                # 執行變體
                result = await self.ab_test.run_variant(
                    "streaming_vs_batch",
                    user_id
                )
                
                # 記錄詳細metrics
                self.observability.metrics.record("request_success", 1, {
                    "variant": result.get("variant"),
                    "user_id": user_id
                })
                
                # 模擬用戶行為（轉換）
                if self.simulate_user_satisfaction(result):
                    variant_key = f"streaming_vs_batch_{result['variant']}"
                    self.ab_test.results[variant_key]["conversions"] += 1
                
                return result
                
            except Exception as e:
                self.observability.logger.error(f"Experiment failed: {e}")
                raise
    
    def simulate_user_satisfaction(self, result):
        """模擬用戶滿意度"""
        # 基於延遲和品質計算滿意度
        latency_score = 1.0 if result.get("latency", 0) < 2000 else 0.5
        quality_score = result.get("quality", 0.8)
        
        satisfaction = (latency_score * 0.4 + quality_score * 0.6)
        
        # 隨機決定是否轉換
        return random.random() < satisfaction
    
    def analyze_results(self, results):
        """分析測試結果"""
        analysis = self.ab_test.analyze_experiment("streaming_vs_batch")
        
        print("\n" + "="*60)
        print("📊 A/B 測試結果分析")
        print("="*60)
        
        for variant, data in analysis["analysis"].items():
            print(f"\n🔹 變體: {variant}")
            print(f"   轉換率: {data['conversion_rate']:.2%}")
            print(f"   平均延遲: {data['avg_latency']:.2f}秒")
            print(f"   平均成本: ${data['avg_cost']:.4f}")
            print(f"   錯誤率: {data['error_rate']:.2%}")
            print(f"   樣本數: {data['sample_size']}")
        
        print(f"\n🏆 獲勝者: {analysis['winner']}")
        print(f"📈 信心度: {analysis['confidence']:.2%}")
        print(f"\n💡 建議: {analysis['recommendation']}")
        
        # 成本節省分析
        self.calculate_cost_savings(analysis)
    
    def calculate_cost_savings(self, analysis):
        """計算成本節省"""
        baseline = analysis["analysis"].get("streaming", {})
        
        print("\n💰 成本節省分析:")
        for variant, data in analysis["analysis"].items():
            if variant != "streaming":
                savings = baseline.get("avg_cost", 0) - data["avg_cost"]
                savings_pct = (savings / baseline.get("avg_cost", 1)) * 100
                
                print(f"   {variant}: 節省 ${savings:.4f}/request ({savings_pct:.1f}%)")
                
                # 月度預估
                monthly_requests = 100000
                monthly_savings = savings * monthly_requests
                print(f"      預估月節省: ${monthly_savings:,.2f}")

# 執行實驗
experiment = StreamingVsBatchExperiment()
await experiment.run_test(num_requests=100)
```

### 💡 實戰心得
> 📊 **數據驅動決策**：不要憑感覺優化，要用 A/B 測試證明。我們曾經以為 streaming 一定更好，結果發現批次處理在某些場景下成本降低 70%。

---

## 📘 模組 8：應用落地與 UX 強化（第 8 週）

### 🎯 學習目標
將應用推向生產環境，加強用戶體驗

### 📚 核心內容

#### 8.1 產品指標體系設計

```python
class ProductMetrics:
    """產品指標系統"""
    
    def __init__(self):
        # 技術指標
        self.technical_metrics = {
            "latency_p50": {"target": 1000, "unit": "ms", "weight": 0.2},
            "latency_p95": {"target": 3000, "unit": "ms", "weight": 0.1},
            "error_rate": {"target": 0.01, "unit": "%", "weight": 0.2},
            "token_cost_per_request": {"target": 0.05, "unit": "$", "weight": 0.2}
        }
        
        # 業務指標
        self.business_metrics = {
            "csat": {"target": 0.85, "unit": "score", "weight": 0.3},  # 客戶滿意度
            "resolution_rate": {"target": 0.80, "unit": "%", "weight": 0.3},  # 解決率
            "fallback_rate": {"target": 0.10, "unit": "%", "weight": 0.2},  # 降級率
            "escalation_rate": {"target": 0.05, "unit": "%", "weight": 0.2}  # 轉人工率
        }
        
        # 綜合健康分數
        self.health_score_calculator = HealthScoreCalculator()
    
    def calculate_health_score(self, current_metrics):
        """計算健康分數"""
        technical_score = 0
        business_score = 0
        
        # 計算技術分數
        for metric, config in self.technical_metrics.items():
            current = current_metrics.get(metric, 0)
            target = config["target"]
            
            # 反向指標（越低越好）
            if metric in ["latency_p50", "latency_p95", "error_rate", "token_cost_per_request"]:
                score = min(1.0, target / max(current, 0.001))
            else:
                score = min(1.0, current / target)
            
            technical_score += score * config["weight"]
        
        # 計算業務分數
        for metric, config in self.business_metrics.items():
            current = current_metrics.get(metric, 0)
            target = config["target"]
            
            # 反向指標
            if metric in ["fallback_rate", "escalation_rate"]:
                score = min(1.0, target / max(current, 0.001))
            else:
                score = min(1.0, current / target)
            
            business_score += score * config["weight"]
        
        # 綜合分數
        overall_score = technical_score * 0.4 + business_score * 0.6
        
        return {
            "overall": overall_score,
            "technical": technical_score,
            "business": business_score,
            "status": self.get_status(overall_score),
            "recommendations": self.generate_recommendations(current_metrics)
        }
    
    def get_status(self, score):
        """獲取狀態"""
        if score >= 0.9:
            return "🟢 Excellent"
        elif score >= 0.7:
            return "🟡 Good"
        elif score >= 0.5:
            return "🟠 Needs Improvement"
        else:
            return "🔴 Critical"
    
    def generate_recommendations(self, metrics):
        """生成優化建議"""
        recommendations = []
        
        # 延遲問題
        if metrics.get("latency_p95", 0) > 5000:
            recommendations.append("⚡ 考慮使用更快的模型或增加快取")
        
        # 成本問題
        if metrics.get("token_cost_per_request", 0) > 0.1:
            recommendations.append("💰 優化 Prompt 長度或使用更便宜的模型")
        
        # 滿意度問題
        if metrics.get("csat", 1) < 0.7:
            recommendations.append("😊 改善回應品質，考慮增加人工審核")
        
        # 降級率問題
        if metrics.get("fallback_rate", 0) > 0.2:
            recommendations.append("🔧 檢查主要服務穩定性，優化降級策略")
        
        return recommendations
```

#### 8.2 LLM 特有的 UX 模式

```python
class LLMSpecificUX:
    """LLM 特有的 UX 元件"""
    
    def __init__(self):
        self.components = {
            "thinking_indicator": ThinkingIndicator(),
            "confidence_display": ConfidenceDisplay(),
            "quick_fix": QuickFixComponent(),
            "streaming_renderer": StreamingRenderer()
        }
    
    def create_thinking_indicator(self):
        """思考過程可視化"""
        return {
            "type": "thinking_indicator",
            "stages": [
                {"id": "understanding", "label": "理解問題", "duration": 500},
                {"id": "searching", "label": "搜尋資料", "duration": 1000},
                {"id": "analyzing", "label": "分析中", "duration": 1500},
                {"id": "generating", "label": "生成回答", "duration": 800}
            ],
            "animations": {
                "dots": "...",
                "spinner": "⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏",
                "progress": "████░░░░░░"
            }
        }
    
    def create_confidence_display(self, response, confidence_score):
        """信心度顯示"""
        if confidence_score > 0.9:
            indicator = "✅ 高信心度"
            color = "green"
            disclaimer = None
        elif confidence_score > 0.7:
            indicator = "⚠️ 中等信心度"
            color = "yellow"
            disclaimer = "此回答可能不完全準確，建議進一步確認"
        else:
            indicator = "⚡ 低信心度"
            color = "red"
            disclaimer = "此回答僅供參考，強烈建議人工確認"
        
        return {
            "type": "confidence_display",
            "score": confidence_score,
            "indicator": indicator,
            "color": color,
            "disclaimer": disclaimer,
            "show_sources": confidence_score < 0.8  # 低信心時顯示來源
        }
    
    def create_quick_fix_component(self, response):
        """快速修正元件"""
        return {
            "type": "quick_fix",
            "actions": [
                {
                    "id": "regenerate",
                    "label": "🔄 重新生成",
                    "hotkey": "Ctrl+R",
                    "action": "regenerate_response"
                },
                {
                    "id": "report",
                    "label": "🚩 回報問題",
                    "hotkey": "Ctrl+F",
                    "action": "report_issue"
                },
                {
                    "id": "edit",
                    "label": "✏️ 編輯回答",
                    "hotkey": "Ctrl+E",
                    "action": "edit_response"
                }
            ],
            "feedback_options": [
                "不準確",
                "不完整",
                "不相關",
                "語氣不當"
            ]
        }
    
    def create_streaming_ux(self):
        """串流 UX 設計"""
        return {
            "type": "streaming",
            "features": {
                "typing_effect": {
                    "enabled": True,
                    "speed": 50,  # 字/秒
                    "variable_speed": True  # 模擬真人打字節奏
                },
                "partial_render": {
                    "enabled": True,
                    "chunk_size": 10,  # 每 10 個字渲染一次
                    "markdown_preview": True
                },
                "interrupt": {
                    "enabled": True,
                    "hotkey": "Esc",
                    "show_stop_button": True
                },
                "progress": {
                    "show_token_count": True,
                    "show_estimated_time": True,
                    "show_cost": False  # 生產環境不顯示成本
                }
            }
        }
```

#### 8.3 部署檢查清單

```python
class DeploymentChecklist:
    """部署檢查清單"""
    
    def __init__(self):
        self.checks = {
            "security": [
                ("prompt_injection_protection", self.check_prompt_injection),
                ("api_key_management", self.check_api_keys),
                ("rate_limiting", self.check_rate_limits),
                ("data_privacy", self.check_data_privacy)
            ],
            "reliability": [
                ("fallback_strategy", self.check_fallback),
                ("error_handling", self.check_error_handling),
                ("timeout_configuration", self.check_timeouts),
                ("retry_logic", self.check_retry_logic)
            ],
            "performance": [
                ("response_time", self.check_response_time),
                ("concurrent_requests", self.check_concurrency),
                ("cache_configuration", self.check_cache),
                ("model_optimization", self.check_model_optimization)
            ],
            "monitoring": [
                ("logging_setup", self.check_logging),
                ("metrics_collection", self.check_metrics),
                ("alerting_rules", self.check_alerts),
                ("dashboard_setup", self.check_dashboards)
            ],
            "cost": [
                ("budget_limits", self.check_budget_limits),
                ("cost_tracking", self.check_cost_tracking),
                ("optimization_rules", self.check_optimizations),
                ("billing_alerts", self.check_billing_alerts)
            ]
        }
    
    def run_all_checks(self):
        """執行所有檢查"""
        results = {}
        total_passed = 0
        total_checks = 0
        
        for category, checks in self.checks.items():
            results[category] = {}
            
            for check_name, check_func in checks:
                result = check_func()
                results[category][check_name] = result
                
                if result["passed"]:
                    total_passed += 1
                total_checks += 1
        
        # 生成報告
        return self.generate_report(results, total_passed, total_checks)
    
    def generate_report(self, results, passed, total):
        """生成部署報告"""
        score = passed / total * 100
        
        report = f"""
        ========================================
        📋 部署就緒檢查報告
        ========================================
        
        總分: {score:.1f}/100
        狀態: {'✅ 可以部署' if score > 80 else '❌ 需要改進'}
        
        詳細結果:
        """
        
        for category, checks in results.items():
            report += f"\n{category.upper()}:\n"
            for check, result in checks.items():
                status = "✅" if result["passed"] else "❌"
                report += f"  {status} {check}: {result['message']}\n"
        
        # 關鍵問題
        critical_issues = self.find_critical_issues(results)
        if critical_issues:
            report += "\n⚠️ 關鍵問題:\n"
            for issue in critical_issues:
                report += f"  - {issue}\n"
        
        return report
```

### 🔬 Lab 實作：完整客服 Bot 部署

```python
# Lab: 部署一個生產級客服 Bot
class ProductionCustomerBot:
    def __init__(self):
        self.metrics = ProductMetrics()
        self.ux = LLMSpecificUX()
        self.deployment = DeploymentChecklist()
        
        # 初始化各個組件
        self.setup_components()
    
    def setup_components(self):
        """設定所有組件"""
        # 核心功能
        self.llm_handler = LLMHandler()
        self.fallback_system = GracefulDegradation()
        self.cache = ResponseCache()
        
        # 監控
        self.monitoring = ObservabilitySystem()
        self.analytics = AnalyticsTracker()
        
        # UX 元件
        self.ui_components = {
            "thinking": self.ux.create_thinking_indicator(),
            "confidence": None,  # 動態生成
            "quick_fix": self.ux.create_quick_fix_component(None),
            "streaming": self.ux.create_streaming_ux()
        }
    
    async def handle_customer_query(self, query, session_id):
        """處理客戶查詢 - 完整流程"""
        
        # 1. 開始追蹤
        trace_id = self.monitoring.start_trace()
        
        try:
            # 2. 顯示思考指示器
            await self.show_thinking_process()
            
            # 3. 處理查詢（帶降級）
            response_data = await self.fallback_system.handle_request({
                "prompt": query,
                "session_id": session_id,
                "trace_id": trace_id
            })
            
            # 4. 計算信心度
            confidence = self.calculate_confidence(response_data)
            
            # 5. 準備 UX 元件
            ui_response = {
                "message": response_data["response"],
                "confidence": self.ux.create_confidence_display(
                    response_data["response"],
                    confidence
                ),
                "quick_actions": self.ux.create_quick_fix_component(
                    response_data["response"]
                ),
                "metadata": {
                    "strategy_used": response_data.get("strategy_used"),
                    "response_time": response_data.get("total_time"),
                    "trace_id": trace_id
                }
            }
            
            # 6. 記錄 metrics
            await self.record_metrics(response_data, confidence)
            
            # 7. 用戶反饋收集
            ui_response["feedback_widget"] = self.create_feedback_widget(trace_id)
            
            return ui_response
            
        except Exception as e:
            # 錯誤處理
            self.monitoring.record_error(e, trace_id)
            return self.create_error_response(e)
        
        finally:
            # 結束追蹤
            self.monitoring.end_trace(trace_id)
    
    async def show_thinking_process(self):
        """顯示思考過程"""
        stages = self.ui_components["thinking"]["stages"]
        
        for stage in stages:
            # 發送狀態更新到前端
            await self.send_status_update({
                "type": "thinking",
                "stage": stage["id"],
                "label": stage["label"]
            })
            
            # 模擬處理時間
            await asyncio.sleep(stage["duration"] / 1000)
    
    def calculate_confidence(self, response_data):
        """計算回應信心度"""
        factors = {
            "strategy_level": {
                "try_primary": 1.0,
                "try_cache": 0.9,
                "try_simple_model": 0.7,
                "try_template": 0.5,
                "try_human": 0.3
            },
            "response_time": 1.0 if response_data.get("total_time", 0) < 2 else 0.8,
            "cache_hit": 0.9 if response_data.get("cache_hit") else 1.0
        }
        
        strategy = response_data.get("strategy_used", "unknown")
        confidence = factors["strategy_level"].get(strategy, 0.5)
        confidence *= factors["response_time"]
        
        if response_data.get("cache_hit"):
            confidence *= factors["cache_hit"]
        
        return min(confidence, 1.0)
    
    async def record_metrics(self, response_data, confidence):
        """記錄各項指標"""
        metrics = {
            "latency_p50": response_data.get("total_time", 0) * 1000,
            "error_rate": 0 if response_data.get("success") else 1,
            "token_cost_per_request": response_data.get("cost", 0),
            "csat": confidence,  # 暫時用信心度代替
            "resolution_rate": 1 if confidence > 0.7 else 0,
            "fallback_rate": 1 if response_data.get("degradation_level", 0) > 0 else 0,
            "escalation_rate": 1 if response_data.get("strategy_used") == "try_human" else 0
        }
        
        # 記錄到監控系統
        for metric, value in metrics.items():
            self.monitoring.metrics.record(metric, value)
        
        # 計算健康分數
        health = self.metrics.calculate_health_score(metrics)
        
        # 如果健康分數低，發送警報
        if health["overall"] < 0.5:
            await self.send_alert(f"Health score critical: {health['overall']:.2f}")
    
    def create_feedback_widget(self, trace_id):
        """創建反饋小工具"""
        return {
            "type": "feedback",
            "trace_id": trace_id,
            "options": [
                {"emoji": "👍", "value": "helpful"},
                {"emoji": "👎", "value": "not_helpful"},
                {"emoji": "😕", "value": "confusing"},
                {"emoji": "🎯", "value": "accurate"},
                {"emoji": "❌", "value": "wrong"}
            ],
            "allow_text": True,
            "placeholder": "告訴我們如何改進..."
        }
    
    async def run_deployment_checks(self):
        """執行部署前檢查"""
        print("🚀 開始部署前檢查...\n")
        
        report = self.deployment.run_all_checks()
        print(report)
        
        # 模擬一些指標
        test_metrics = {
            "latency_p50": 800,
            "latency_p95": 2500,
            "error_rate": 0.005,
            "token_cost_per_request": 0.03,
            "csat": 0.88,
            "resolution_rate": 0.82,
            "fallback_rate": 0.08,
            "escalation_rate": 0.03
        }
        
        health = self.metrics.calculate_health_score(test_metrics)
        
        print("\n📊 系統健康報告:")
        print(f"  整體分數: {health['overall']:.2f} - {health['status']}")
        print(f"  技術分數: {health['technical']:.2f}")
        print(f"  業務分數: {health['business']:.2f}")
        
        if health["recommendations"]:
            print("\n💡 優化建議:")
            for rec in health["recommendations"]:
                print(f"  {rec}")
        
        return health["overall"] > 0.7

# 測試部署
bot = ProductionCustomerBot()

# 1. 執行部署檢查
ready = await bot.run_deployment_checks()

if ready:
    print("\n✅ 系統已準備就緒，可以部署！")
    
    # 2. 測試一些查詢
    test_queries = [
        "我的訂單什麼時候到？",
        "如何申請退款？",
        "你們的客服電話是多少？"
    ]
    
    for query in test_queries:
        print(f"\n測試查詢: {query}")
        response = await bot.handle_customer_query(query, "test_session")
        print(f"回應: {response['message'][:100]}...")
        print(f"信心度: {response['confidence']['indicator']}")
else:
    print("\n❌ 系統尚未準備好，請解決上述問題後再部署。")
```

### 💡 實戰心得
> 🚀 **UX 決定成敗**：技術再好，用戶體驗差就是失敗。花 50% 的時間在 UX 上不為過。

---

## 🎓 終極專題：Capstone Project

### 🎯 專題目標
整合所有模組知識，開發一個**真正可用的 LLM OS 應用**

### 📝 專題選項

#### Option 1: 智慧客服助手（推薦新手）
- **功能要求**：多輪對話、RAG、情緒管理、工單系統整合
- **技術挑戰**：處理情緒化客戶、多語言支援、降級策略
- **評分重點**：回應品質、處理效率、用戶滿意度

#### Option 2: 程式碼審查 Copilot
- **功能要求**：程式碼分析、bug 檢測、重構建議、最佳實踐檢查
- **技術挑戰**：理解程式碼上下文、提供可執行建議
- **評分重點**：建議準確性、實用性、整合便利性

#### Option 3: 智慧文件助理
- **功能要求**：文件上傳、智慧問答、摘要生成、引用追蹤
- **技術挑戰**：處理大文件、準確引用、多格式支援
- **評分重點**：檢索準確性、回答完整性、引用可靠性

### 📊 評分標準

| 面向 | 權重 | 評分要點 |
|------|------|---------|
| **技術實現** | 40% | API 整合完整性、錯誤處理完善度、效能優化程度、成本控制能力 |
| **產品完成度** | 40% | UX 流暢性、功能完整性、實際解決問題能力、部署就緒程度 |
| **創新性** | 20% | 場景創意、Prompt 設計巧思、UX 差異化、技術亮點 |

### 🏆 優秀專題範例

```python
class ExcellentCapstoneExample:
    """優秀專題範例：智慧 HR 助手"""
    
    def __init__(self):
        # 完整的模組整合
        self.modules = {
            "prompt_manager": PromptManager(),        # 模組 1
            "api_handler": LLMAPIPatterns(),         # 模組 2
            "context_engine": MemoryArchitecture(),  # 模組 3
            "rag_system": SimpleRAG(),               # 模組 4
            "product_logic": ProductDecisionFramework(), # 模組 5
            "workflow": WorkflowChain(),             # 模組 6
            "monitoring": ObservabilitySystem(),     # 模組 7
            "ux_system": LLMSpecificUX()            # 模組 8
        }
        
        # 創新點
        self.innovations = {
            "multi_persona": self.handle_multiple_personas,
            "proactive_suggestions": self.generate_proactive_suggestions,
            "sentiment_routing": self.route_by_sentiment
        }
    
    async def demo_flow(self):
        """展示完整流程"""
        
        # 場景：員工詢問請假政策
        query = "我想請病假，需要什麼手續？最近壓力很大..."
        
        # 1. 情緒檢測與路由（創新點）
        sentiment = await self.detect_sentiment(query)
        if sentiment["stress_level"] > 0.7:
            # 切換到關懷模式
            self.modules["prompt_manager"].switch_mode("empathetic")
        
        # 2. 多角色處理（創新點）
        response = await self.handle_with_persona(
            query,
            persona="hr_counselor"  # 不只是 HR，還有心理關懷
        )
        
        # 3. 主動建議（創新點）
        suggestions = await self.generate_proactive_suggestions(query)
        # 例如：建議 EAP 服務、推薦減壓資源
        
        # 4. 完整的產品化輸出
        return {
            "primary_response": response,
            "care_package": {
                "detected_stress": True,
                "eap_resources": self.get_eap_resources(),
                "anonymous_counseling": self.get_counseling_link()
            },
            "next_steps": suggestions,
            "follow_up_scheduled": self.schedule_follow_up(query)
        }
```

---

## 🚀 學習路徑總結

### 🎯 快速通道（4 週兼職學習）

**Week 1-2: 基礎速成**
- Day 1-3: Prompt Engineering + 版本管理
- Day 4-5: API 模式 + UX 基礎
- Day 6-7: 簡單 RAG + Context 管理
- **產出**: 能對話的 Bot Demo

**Week 3: 核心實戰**
- Day 1-2: 產品思維 + 成本優化
- Day 3-4: Workflow 設計
- Day 5-7: 可靠性基礎
- **產出**: 有 fallback 的穩定 Bot

**Week 4: 專題衝刺**
- Day 1-5: 開發完整專題
- Day 6-7: 部署與優化
- **產出**: 可部署的 MVP

### 🎓 完整通道（8 週深度學習）

按照完整 8 個模組循序漸進，每週一個模組，最後用 2 週完成專題。

---

## 💼 職涯發展建議

### 📈 技能成長路線圖

```
初級（0-6個月）
├── 掌握 Prompt Engineering
├── 熟悉主流 LLM API
└── 能開發簡單 Bot

中級（6-18個月）
├── 精通 RAG 和 Context 管理  
├── 設計複雜 Workflow
├── 優化成本和性能
└── 領導小型專案

高級（18個月+）
├── 架構大型 LLM 系統
├── 制定技術標準
├── 培訓團隊
└── 推動創新

專家（3年+）
├── 定義產品策略
├── 跨團隊協作
├── 開源貢獻
└── 行業影響力
```

## 🎯 立即行動計劃

### 今天就開始（Day 1）

```python
# Step 1: 設定環境
pip install openai langchain pinecone-client

# Step 2: 第一個 Prompt Manager
class MyFirstPromptManager:
    def __init__(self):
        self.prompts = {
            "v1": "You are a helpful assistant.",
            "v2": "You are a helpful and empathetic assistant."
        }
        self.current = "v1"
    
    def get_prompt(self):
        return self.prompts[self.current]

# Step 3: 測試版本差異
manager = MyFirstPromptManager()
for version in ["v1", "v2"]:
    manager.current = version
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": manager.get_prompt()},
            {"role": "user", "content": "I'm feeling stressed"}
        ]
    )
    print(f"{version}: {response.choices[0].message.content}")
```

### 本週目標（Week 1）

- [ ] 完成模組 1-2 的學習
- [ ] 實作 3 個不同的 Prompt 策略
- [ ] 測試 3 種 UX 模式
- [ ] 建立第一個帶驗證的 API 呼叫

### 本月目標（Month 1）

- [ ] 完成模組 1-6
- [ ] 開發一個完整的 FAQ Bot
- [ ] 實現成本優化，降低 50% 開銷
- [ ] 部署到測試環境

---

## 📚 學習資源推薦

### 📖 必讀資源
- [OpenAI Cookbook](https://cookbook.openai.com/) - 官方最佳實踐
- [LangChain Docs](https://docs.langchain.com/) - 應用開發框架
- [Pinecone Learning Center](https://www.pinecone.io/learn/) - 向量資料庫入門

### 🎓 進階課程
- [Building LLM Apps with LangChain.js](https://www.deeplearning.ai/short-courses/building-applications-vector-databases/) - DeepLearning.AI
- [LLM Application Development](https://www.coursera.org/learn/llm-applications) - Coursera
- [Full Stack LLM Bootcamp](https://fullstackdeeplearning.com/llm-bootcamp/) - FSDL

### 🛠 開發工具
- **Prompt 測試**: [Promptfoo](https://promptfoo.dev/), [Langfuse](https://langfuse.com/)
- **監控平台**: [Helicone](https://helicone.ai/), [Langsmith](https://smith.langchain.com/)
- **向量資料庫**: [Pinecone](https://pinecone.io/), [Weaviate](https://weaviate.io/)

### 👥 社群資源
- [r/LocalLLaMA](https://reddit.com/r/LocalLLaMA) - Reddit 社群
- [LLM Discord](https://discord.gg/llm) - Discord 討論群
- [AI Builder Club](https://aibuilder.club/) - 開發者社群

---

## 🏁 結語：成為市場需要的 LLM 應用工程師

還記得開頭提到的問題嗎？為什麼 90% 的 LLM 應用都只是「玩具」？

現在你有答案了：**因為缺乏應用工程的系統化思維。**

透過這 8 個模組的學習，你將掌握：
- ✅ 如何管理 Prompt 資產，而不只是寫 Prompt
- ✅ 如何設計降級策略，而不是祈禱 API 不會掛
- ✅ 如何優化成本效益，而不是燒錢做 Demo
- ✅ 如何打造用戶體驗，而不只是技術炫技

**市場現狀**：
- 每家企業都想導入 AI，但缺乏落地能力
- 大量職缺湧現，但合格人才稀缺
- 薪資持續上漲，機會窗口正在開啟

**你的機會**：
- 不需要 PhD，不需要懂模型原理
- 只要 2-3 個月，就能掌握核心技能
- 市場需求是系統工程師的 **5-10 倍**

### 🚀 最後的行動呼籲

**不要再等了。** 每天都有新的 LLM 應用上線，每天都有公司在找 LLM 應用工程師。

現在就開始：
1. **今天**：設定環境，寫第一個 Prompt Manager
2. **本週**：完成模組 1-2，做出 Demo
3. **本月**：開發第一個完整應用
4. **三個月後**：成為合格的 LLM 應用工程師

記住：**在 AI 時代，應用層才是主戰場。**

系統工程師建造引擎，但**應用工程師開車上路**。

問題是——**你準備好上路了嗎？**

---

**最後更新**：2025年8月  
**作者**：Ian Chou  
**聯絡方式**：i@wo94.com

---

### 🔗 相關文章推薦
- [🧭 建造你的 LLM OS：從 Prompt 到 Production 的完整建構指南](/blog/2025-08-llm-os-complete-guide) - LLM OS 系統架構深度指南
- [🚀 AI 編程助手比較：Claude vs ChatGPT vs Gemini 開發者實戰評測](/blog/2025-06-ai-coding-assistant-comparison-claude-chatgpt-gemini-developers) - AI 編程工具對比
- [📊 台灣軟體工程師就業市場分析：2025 年趨勢與機會](/blog/2025-06-taiwan-software-engineer-job-market-analysis) - 職涯發展參考
- [🔧 規格驅動開發：2025 年軟體開發的新典範](/blog/2025-07-specification-driven-development-2025-paradigm) - 新興開發模式