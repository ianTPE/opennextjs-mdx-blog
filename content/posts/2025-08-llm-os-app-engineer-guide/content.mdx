## 前言：90% 的 LLM 專案為何停在 POC 階段？

根據 Gartner 與 McKinsey 的觀察，超過八成的 LLM 專案停留在概念驗證（POC），從未進入正式生產環境。

原因不在技術不可行，而在於：

- 缺乏穩定性設計（non-deterministic output）
- 成本不可預測（token usage 波動大）
- 無法與現有系統整合（data pipeline, auth, audit log）
- 缺少監控與除錯工具

換句話說：我們擅長「展示能力」，但不擅長「工程建構後交付」。

這門課的目標，是填補這道鴻溝——
讓你從「會用 Token API 的開發者」，轉型為「能交付穩定 LLM OS 應用的系統設計者」。

> 💡 **定位明確**：你不需要理解 Transformer 的數學原理，也不需要會訓練模型。你需要的是把 LLM OS 當作「新時代的 API」，並用工程化的方式打造應用。

---

## 📊 LLM OS 應用工程師 vs 系統工程師

| 面向 | 系統工程師 | **應用工程師** | 
|---|---|---|
| **關注重點** | 底層架構、模型優化 | 產品體驗、業務價值 |
| **核心技能** | RAG 原理、向量資料庫、模型部署 | Prompt 版本管理、UX 設計、成本控制 |
| **工作內容** | 建構 LLM 基礎設施 | 開發 Bot、Copilot、Agent |
| **市場需求** | 每家公司 1-2 位 | **每家公司 5-10 位** |
| **學習曲線** | 陡峭（6-12 個月） | **適中（2-3 個月）** |

---

## 🎯 學習目標與能力出口

完成這個課程後，你將能夠：

### ✅ 核心能力
- 把一個 LLM OS 應用從**設計 → API → UX → 上線**
- 處理 **80% 的產品問題**（不穩定、成本高、體驗差）
- 具備**產品思維**，知道何時該用/不該用 LLM

### 🚀 可開發的應用類型
1. 對話與互動應用
- 智慧客服：處理複雜詢問、多輪對話、情緒管理
- 企業內部 Copilot：幫助員工快速查詢文件、操作系統
- 多語翻譯與文化轉換助手 <br />

👉 用到的模組：System Prompt、上下文管理、Function Calling

2. 文件與知識應用
- 文件助手：摘要、問答、比對、法規檢索
- 研究助理：文獻搜尋、比較、生成研究筆記
- 會議/合約助理：自動生成摘要、風險提示、重點標註 <br />

👉 用到的模組：RAG、進階 Context Engineering、Plan→Solve→Verify

3. 數據與分析應用
- 報告生成器：輸入數據，自動產出決策報告
- 財務分析助手：KPI 分析、異常檢測、決策建議
- 行銷數據助理：從 GA/CRM 撈數據 → 分析 → 生成 insights <br />

👉 用到的模組：Function Calling、Chain-of-Thought、成本工程

4. 開發者工具
- Coding Copilot：程式碼生成、解釋、重構建議
- 測試案例生成器：根據需求自動產出測試案例
- Pipeline Debugger：輔助排查數據流程或 API 連動問題 <br />

👉 用到的模組：LLM 選型、進階 Prompt 工程、自檢 / 自一致性

5. 商務與生產力
- 銷售助理：自動生成銷售話術、郵件回覆
- 專案助理：追蹤進度、生成週報、風險預警
- 行銷內容工廠：自動產生廣告文案、標題、社群貼文 <br />

👉 用到的模組：成本工程、上下文管理、可觀測性

6. Agent 與自動化
- Workflow Agent：自動完成多步驟任務（如搜尋 → 分析 → 報告）
- 多 Agent 協作：分工完成複雜專案
- 系統自動化：串接 ERP / CRM / 工單系統，減少人工流程 <br />

👉 用到的模組：Agent 架構、ReAct、工具路由、進階 RAG

學完這些模組，您不只是能做一個聊天機器人，而是能：
- 讓 LLM 穩定輸出（可控 / 可驗證）
- 把 LLM 嵌入不同業務流程（文件、數據、客服、開發）
- 設計長期可用的框架（成本、觀測、流程管理） <br />

👉 這就是 LLM OS 應用工程師的核心價值：把 LLM OS 當作「新一代 API」，應用到各種產品與產業場景。

### 📈 職涯發展路徑

<CareerPathDiagram />

---

## 🏗 完整課程架構（8 週速成）

### 📚 課程設計理念
- **70% 應用實作**：直接動手做產品
- **30% 系統必修**：理解必要的底層概念
- **100% 實戰導向**：每個模組都有實際產出

---

## 📘 模組 1：Prompt for Applications（第 1 週）

### 🎯 學習目標
從「寫 Prompt」升級到「管理 Prompt 資產」

### 📚 核心內容
在這個模組中，我們將深入探討如何將 Prompt Engineering 從一門藝術轉化為一門科學。您將學習如何系統化地管理、優化和測試您的 prompts，確保它們在實際應用中能夠發揮最大效用，並為您的產品或服務帶來可預測、可依賴的成果。

### 1.1 Prompt 版本管理：從開發到部署的雙循環
為什麼版本管理至關重要？
因為在 AI 應用中，每一條 Prompt 都是一個直接影響用戶體驗和商業成果的「產品功能」。

想像一下，您是一家運動品牌的電商，正在使用 LLM 為新上架的跑鞋自動生成行銷文案。

- 初始版本 (Prompt A - by 產品經理):
產品經理設計了一個穩定、中性的 Prompt，專注於準確描述跑鞋的功能和規格。這個版本上線後，產品頁面的購買轉換率穩定在 2%。

- 新版實驗 (Prompt B - by 行銷團隊):
為了迎接夏季促銷，行銷團隊提出了一個更具創意、更富煽動性的 Prompt，希望能激發消費者的購買慾望。新版本上線後，團隊發現廣告的點擊率 (CTR) 明顯上升，看似是個好消息。

這時，問題出現了：

一週後，數據分析師發現，雖然點擊率變高了，但最終的購買轉換率卻從 2% 下滑到了 1.5%。團隊推測，可能是過於誇大的文案風格，反而讓進入頁面的訪客產生了不信任感。

現在，整個產品和行銷團隊都面臨著一系列緊急問題：

1. 如何快速反應？ 我們能立刻將文案切換回表現更穩定的 Prompt A 嗎？還是只能等工程師緊急加班重新部署？

2. 如何驗證假設？ 我們能不能設計一個 A/B 測試，讓 50% 的用戶看到 Prompt A 的文案，另外 50% 看到 Prompt B 的文案，用真實數據來驗證我們的猜測？

3. 如何追蹤與學習？ Prompt B 到底在哪一天上線的？它的完整內容是什麼？我們從這次失敗的實驗中學到了什麼，如何記錄下來以避免未來再犯？

如果沒有一個好的版本管理系統，上述問題的答案將是災難性的。團隊會陷入混亂：手忙腳亂地尋找舊的 Prompt 文字、無法進行科學的 A/B 測試來指導決策、也無法系統性地從昂貴的失敗中積累經驗。

這就是為什麼版本管理至關重要。 它不僅僅是為了防止工程師的「失誤」，更是為了賦能「產品和業務團隊」，讓他們能夠安全、高效地進行商業實驗，用數據驅動決策，並最終找到能夠最大化商業價值的溝通方式。

#### 1.1.1 版本控制 (Version Control) - 您的 Prompt 開發與品管中心

版本控制不僅僅是為 prompt 加上 v1, v2 的標籤。一個專業的流程需要一個中央化的平台來管理、評估和迭代。

- 集中式管理：除了使用 Git，更專業的做法是將所有 Prompts 存放在專為 LLM 應用設計的平台上，例如 LangFuse 或 Pezzo。

    - 優點：這些平台提供了 UI 介面，讓團隊（包括非工程師）可以輕鬆查看、比較和管理所有 Prompts。您可以為每個 Prompt 附加元數據(metadata)，如作者、目標、以及版本說明。

- 明確的命名與註釋：在 LangFuse/Pezzo 這類工具中，您可以為每個 Prompt 創建不同的版本 (e.g., v1, v2)。這些版本不僅僅是文本不同，它們是您可以獨立追蹤和評估的對象。

- 與程式碼分離 (Decoupling)：

    - 這是 LangFuse/Pezzo 的核心優勢之一。您的應用程式程式碼不再寫死 Prompt 內容，而是透過 SDK 向這些平台請求特定版本的 Prompt (langfuse.get_prompt("marketing-copy", version=2))。這使得 Prompt 的更新和程式碼的部署完全分離。

#### 1.1.2 Feature Flag - 您的 Prompt 線上策略部署中心

當您在 LangFuse 或 Pezzo 中擁有了幾個經過測試、品質優良的 Prompt 候選版本後，下一個問題是：如何策略性地將它們部署到線上，並衡量其商業影響？這就是 Feature Flag 工具 LaunchDarkly 或 Flagsmith 發揮作用的地方。

- 整個工作流程是：

    1. 開發階段：在 LangFuse/Pezzo 中創建和版本化您的 Prompts (e.g., product-description-v1, product-description-v2)。

    2. 部署階段：在 LaunchDarkly 中創建一個名為 productDescriptionPrompt 的 Feature Flag，並設定兩個變體 (variants)：一個返回字串 "v1"，另一個返回字串 "v2"。

    3. 應用程式邏輯：您的程式碼首先訪問 LaunchDarkly 得到當前用戶應該使用哪個版本 ("v1" 或 "v2")，然後拿著這個版本號去 LangFuse/Pezzo 獲取對應的 Prompt 內容來執行。

- Feature Flag（功能旗標）的主要功能：

    - 動態切換 Prompts：想像您有一個 greeting_prompt。透過 Feature Flag，您可以設定一個參數，讓系統根據不同的條件（例如：使用者地區、會員等級、或是一個開關）來決定要使用 greeting_prompt_v1 還是 greeting_prompt_v2_formal。

    - 灰度發布 (Canary Release)：當您開發了一個全新的、更強大的 prompt v3.0，您可能不想立刻將它推送給所有使用者。利用 Feature Flag，您可以先將 v3.0 開放給 1% 的內部員工或測試用戶，觀察其表現。如果效果良好，再逐步擴大到 5%、20%，最終全面上線。這個過程能大幅降低因新 prompt 表現不佳而導致的大規模負面影響。

    - 緊急回退 (Kill Switch)：如果在全面上線後，發現新版的 prompt 在某些邊界情況下會產生有害或不當的內容，您可以立即透過 Feature Flag 將其關閉，讓系統瞬間切換回上一個穩定的版本，而不需要緊急進行程式碼的重新部署。

### 1.2 核心 Prompt 技術的應用場景 (Few-shot, CoT, ReAct)
了解了如何管理 prompts 之後，我們來深入探討三種能顯著提升 LLM 表現的核心技術。了解它們各自的適用場景，是成為高級 Prompt Engineer 的關鍵。

#### 1.2.1 Few-shot Learning - 給模型幾個範例，讓它學得更快

- 核心思想：在您的問題之前，提供幾個完整的「問題-答案」範例。這就像是給模型一個小型的「速成班」，讓它在回答您真正的問題之前，先理解您期望的格式、風格和邏輯。

- 應用場景：

    - 格式化輸出：當您需要模型以特定的格式（如 JSON、Markdown 表格、特定 XML 結構）回覆時，提供幾個範例是最高效的方式。

    - 特定風格的文本生成：例如，要求模型撰寫一封正式的商業郵件。您可以先提供一兩個符合公司風格的範例郵件，模型就能更好地模仿該語氣和用詞。

    - 複雜分類任務：假設您要將用戶評論分為「正面」、「負面」、「中性」和「建議」。您可以給出幾個典型評論及其分類的範例，幫助模型更精準地進行判斷。

    - Zero-shot vs. Few-shot：Zero-shot (零樣本) 是指不給任何範例，直接提出問題。當任務非常簡單或模型已經非常熟悉時，可以使用。但只要任務稍微複雜或需要特定格式，Few-shot 的效果通常會遠勝於 Zero-shot。

#### 1.2.2 Chain of Thought (CoT) - 引導模型「思考」而不是「猜測」

- 核心思想：不僅僅給模型答案，而是向模型展示「如何一步步推導出答案」的思考過程。這會激發模型內部的推理能力，使其在處理複雜問題時，表現得更像一個真正的思考者。

- 應用場景：

    - 數學與邏輯推理：這是 CoT 最經典的應用。例如，在解決一個數學應用題時，您會先列出已知條件，然後寫下計算步驟，最後得出答案。將這個過程展示給模型，它解決類似問題的準確率會大幅提升。

    - 多步驟指令的任務規劃：例如，「幫我規劃一個週末去陽明山的行程，需要包含午餐地點，並且考慮到下午可能會下雨。」使用 CoT，您可以引導模型先思考：1. 選擇陽明山景點。2. 查詢天氣預報。3. 根據天氣推薦上午的戶外景點和下午的室內備案。4. 推薦午餐地點。

    - 根本原因分析 (Root Cause Analysis)：當面對一個複雜的問題（例如：「為什麼我的電商網站上個月的轉換率下降了？」），您可以透過 CoT 引導模型從數據、市場、產品等多個角度進行逐步分析，而不是直接給出一個猜測性的答案。

#### 1.2.3 ReAct (Reasoning and Acting) - 讓模型成為一個會使用工具的智慧體

- 核心思想：結合了 CoT 的「思考」(Reasoning) 和與外部工具「互動」(Acting) 的能力。這讓 LLM 不再只是一個封閉的知識庫，而是一個可以主動獲取最新資訊、執行程式碼、與 API 互動的智慧代理 (Agent)。

- 運作流程：思考 (Thought) -> 行動 (Action) -> 觀察 (Observation) -> 思考 (Thought) ...

- 應用場景：

    - 需要即時資訊的問答：例如，「Google 最近的股價是多少？並分析一下近期的趨勢。」模型會 思考 到需要查詢股價，於是 行動 (呼叫一個股票查詢 API)，得到 觀察 (股價數據)，然後再 思考 如何基於這些數據進行分析。

    - 與外部服務互動：建立一個能幫您預訂餐廳、查詢訂單狀態或是在您的行事曆上新增活動的 AI 助理。模型會根據您的指令，思考需要呼叫哪個 API (行動)，並根據 API 的回傳結果 (觀察) 進行下一步。

    - 自動化研究與報告生成：給定一個主題，ReAct 框架可以讓模型主動上網搜尋資料 (行動)，閱讀並總結搜尋結果 (觀察 & 思考)，最終生成一份結構完整的報告。

> 💡 教學提示：「當您在設計這些不同策略的 Prompt 時，最佳實踐是將它們作為不同的版本保存在您的 Prompt 管理平台（如 LangFuse）中。例如，您可以有一個 baseline 版本、一個 few-shot 版本和一個 CoT 版本，這樣便於後續進行系統化的測試和比較。」

### 1.3 Prompt 測試與 A/B 比較：從實驗室到真實世界的雙層次評估法
一個好的 Prompt 不是憑感覺想出來的，而是需要經過科學驗證。這個驗證過程就像新藥上市，需要經過兩個核心階段：實驗室裡的嚴格品管，和真實世界裡的臨床試驗。

#### 1.3.1 層次一：上線前的「品質檢驗」(The "Lab Coat" Phase)

在這個階段，我們像科學家一樣在控制環境中做測試。我們的目標不是看它能不能賺錢，而是回答一個更基本的問題：「這個 Prompt 安全、穩定、正確嗎？」

- 由誰主導？ 主要由工程師和 AI 團隊主導。

- 測試方法：黃金測試集 (Golden Set)

    - 我們會準備一個包含數十到數百個「考題」的測試集 (e.g., 不同的產品名稱、用戶問題)。

    - 用這個測試集去執行我們的 Prompt 新版本，確保它不會產生有害內容、不會跑出奇怪的格式、並且答案品質在一個基本水準之上。

- 評估指標： 這時我們關注的是客觀指標和主觀指標。

    - 格式符合率：輸出的 JSON 是否總是合法？

    - 安全性：是否會生成不當言論？

    - 準確率：對於某些任務，回答是否正確？

- 核心工具： 這就是 LangFuse, Pezzo, LangSmith 這類 LLMOps 平台發揮巨大價值的地方。它們能幫助我們管理黃金測試集，自動化地運行測試，並記錄下每個 Prompt 版本在這些品質指標上的表現（例如成本、延遲、評分）。

一句話總結： 在這個階段，我們淘汰掉那些「不及格」的 Prompt，篩選出幾個品質優良的「候選版本」進入下一輪。

#### 1.3.2 層次二：上線後的「市場驗證」(The "In the Wild" Phase)

當一個 Prompt 通過了品質檢驗，證明它是一個「好」的 Prompt 後，我們還需要將它放到真實的市場中去驗證，回答一個商業問題：「這個 Prompt 能為我們帶來商業價值嗎？」

- 由誰主導？ 主要由產品經理和行銷團隊主導。

- 測試方法：A/B 測試 (A/B Testing)

    - 我們將通過品質檢驗的「候選版本」（例如，舊的穩定版 vs. 新的優化版）同時推送給線上用戶。

    - 透過隨機分流，讓一部分用戶看到 A 版本，另一部分看到 B 版本。

- 評估指標： 這時我們關注的是業務指標。

    - 轉換率：哪個版本的文案帶來了更多的銷售？

    - 用戶滿意度：哪個版本的客服機器人收到了更多的好評？

- 核心工具組合：

    1. 功能旗標服務 (LaunchDarkly/Flagsmith)：用它強大的後台來設定流量分配規則（例如 50% vs 50%），並可以隨時調整或關閉實驗，而不需要工程師修改程式碼。

    2. 數據分析工具 (Google Analytics, Mixpanel 等)：用來衡量和比較不同組別在業務指標上的表現。

一句話總結： 在這個階段，我們用真實的市場數據，從幾個「候選版本」中找出最終的「冠軍版本」。

*實作 Lab：模擬一個從開發、品管到線上測試的完整工作流程*
現在，讓我們透過為「Aura 智慧香氛機」設計行銷文案這個場景，來走一遍上面提到的完整流程。

*情境*
我們的目標是為新產品找到最佳的社群媒體文案。團隊已經腦力激盪出三版 Prompts，現在需要透過科學的方法來決定最終要用哪一版。

步驟 1：開發與版本定義 (Development & Version Definition)

這一步對應的是 Prompt 的開發階段。在真實世界中，這三版 Prompt 會被儲存在 LangFuse 或 Pezzo 中進行集中管理，並賦予明確的版本號。

1. v1_baseline (基礎版)

- Prompt: "為「Aura 智慧香氛機」寫一段社群媒體的行銷文案。"

- 目的：這是一個最簡單、最直接的 prompt，作為我們比較的基準。

2. v2_few_shot (範例學習版)

- Prompt:

為產品寫一段吸引人的社群媒體行銷文案。

```
範例1：
產品：SleekPods 無線藍牙耳機
文案：🎶 告別纏線，擁抱自由！SleekPods 帶來沉浸式音質與全天候舒適配戴感。#無線自由 #音樂隨行

範例2：
產品：Zenith 手沖咖啡壺
文案：☕️ 每個早晨，都值得一杯完美的咖啡。Zenith 手沖咖啡壺，精準溫控，釋放咖啡豆的極致風味。#手沖咖啡 #生活美學

現在，請為「Aura 智慧香氛機」寫一段社群媒體的行銷文案。
```

- 目的：使用 Few-shot learning，提供範例來引導模型生成包含 Emoji 和 Hashtag 的、更符合社群媒體風格的文案。

3. v3_optimized (優化版)

- Prompt:

```
你是一位頂尖的社群行銷專家。你的任務是為新產品「Aura 智慧香氛機」撰寫一段引人入勝、不超過150字的 Instagram 貼文。

**產品核心賣點**:
1.  可透過 App 遠端遙控，並設定排程。
2.  能與智慧家庭系統（如 Google Home）連動。
3.  使用天然植物精油，安靜運作。

**寫作要求**:
- 開頭要能立刻抓住眼球。
- 文案中需自然地融入至少兩個核心賣點。
- 語氣需溫暖、有質感，能喚起放鬆和科技感。
- 結尾必須包含一個行動呼籲 (Call to Action)。
- 最後附上 3-4 個相關的 Hashtag。
```

- 目的：這是一個更精緻的 prompt，明確定義了角色 (Persona)、上下文 (Context)、任務細節 (Task Specifics) 和輸出格式 (Output Format)，期望能生成質量最高的文案。

步驟 2：(模擬) 品質檢驗 (Simulated QA)
在真實場景中，工程師會用一個包含 50 個不同產品名稱的「黃金測試集」來測試這三版 Prompt。他們可能會得出以下結論：

- v1_baseline：輸出品質普通，但格式非常穩定。(通過品管)

- v2_few_shot：風格討喜，但偶爾會模仿範例到忘記產品本身，導致文案不相關。(品管不通過)

- v3_optimized：輸出品質高，且嚴格遵循所有寫作要求，表現最穩定。(通過品管)

基於品管結果，團隊決定淘汰 v2，讓表現穩定的 v1 和 v3 進入下一階段的真人 A/B 測試，來看看用戶到底更喜歡哪一種。

步驟 3：用 Feature Flag 實現線上 A/B 測試 (Implementation)

我們將使用 Python 偽代碼來模擬這個過程。

```Python
import random

# --- 步驟 1: 在 Prompt 管理平台 (如 LangFuse/Pezzo) 中定義好的 Prompts ---
# 在真實應用中，這些內容是透過 API 從 LangFuse/Pezzo 獲取的，而不是寫死在本地。
PROMPT_REPOSITORY = {
    "v1_baseline": "為「Aura 智慧香氛機」寫一段社群媒體的行銷文案。",
    "v3_optimized": """你是一位頂尖的社群行銷專家... (省略如上) ..."""
}

# --- 步驟 2: 連接 Feature Flag 服務 (如 LaunchDarkly) 來決定使用哪個版本 ---
# 產品經理可以在 LaunchDarkly 的儀表板上設定 A/B 測試，例如各分配 50% 的流量。
def get_prompt_version_from_feature_flag(user_id):
    """
    模擬從 LaunchDarkly 獲取決策。
    這個函式決定了特定用戶應該看到哪個實驗版本。
    """
    # 簡單的 50/50 分流邏輯
    if user_id % 2 == 0:
        return "v3_optimized"  # 偶數 ID 的用戶看到優化版
    else:
        return "v1_baseline"   # 奇數 ID 的用戶看到基礎版

# --- 應用程式主邏輯 ---
def generate_product_copy(product_name, user_id):
    """
    一個完整的請求流程：
    1. 詢問 Feature Flag 我該用哪個版本。
    2. 根據版本號去 Prompt 平台拿對應的 Prompt。
    3. 執行 Prompt 並返回結果。
    """
    # 1. 從 LaunchDarkly 獲取版本決策
    version_to_use = get_prompt_version_from_feature_flag(user_id)
    
    # 2. 從 LangFuse/Pezzo 獲取對應的 Prompt 內容
    prompt_template = PROMPT_REPOSITORY.get(version_to_use)
    
    print(f"--- User {user_id} 正在參與 A/B 測試，分配到的版本是: {version_to_use} ---")
    
    # 3. (模擬) 呼叫 LLM API
    # response = call_llm_api(prompt_template.format(product_name=product_name))
    # print(response)
    
    return f"用戶看到的文案將由 {version_to_use} 版本生成。"


# --- 模擬兩個不同用戶的請求 ---
user_a = 101  # 奇數 ID
user_b = 202  # 偶數 ID

print("處理 User A 的請求:")
generate_product_copy("Aura 智慧香氛機", user_a)

print("\n" + "="*50 + "\n")

print("處理 User B 的請求:")
generate_product_copy("Aura 智慧香氛機", user_b)

```

Lab 總結與討論

完成這個 Lab 後，請思考：

1. 我們為什麼在 A/B 測試前要先進行「品質檢驗」？如果直接把 v2_few_shot 版本也加入 A/B 測試，可能會帶來什麼風險？

2. 在 A/B 測試進行中，產品經理發現 v3_optimized 版本的轉換率遠超預期。她應該如何使用 Feature Flag 系統來結束實驗，並將 100% 的流量都切換到 v3 版本？這個過程需要工程師介入嗎？

3. 請描述在這個完整的流程中，LangFuse (或 Pezzo) 和 LaunchDarkly 是如何協同工作的？它們分別解決了哪個階段的核心問題？

---

## 📘 模組 2：LLM API 與 UX 整合（第 2 週）

### 🎯 學習目標
本模組將帶領學員跨越單純的 Prompt Engineering，進入應用開發的實務層面。學員將學習如何根據不同的使用者情境，選擇最適合的 API 呼叫模式，並設計出符合使用者直覺的對話體驗。最後，我們將探討如何建立一道「信任層」，確保從 LLM 獲得的輸出是可控、可靠且能被後端系統使用的。

### 📚 核心內容

### **2.1 LLM API 呼叫模式 (API Call Patterns)**

**核心問題：** 我們該如何與 LLM API 溝通？不同的溝通方式會如何影響應⽤的效能和使⽤者體驗？

#### **2.1.1 Completion 模式（一次性完成模式）**

- **定義：** 這是最基礎的互動模式。你送出一個完整的提示 (Prompt)，API 回傳一個完整的答案。這是一種「一次性請求-回應」的無狀態 (Stateless) 互動。
    
- **比喻：** 就像寫一封 Email，你把所有問題寫完寄出，然後等待對方完整的回覆。
    
- **優點：**
    
    - 實作簡單、直觀。
        
    - 適合不需要上下文記憶的單次任務。
        
- **適用情境：**
    
    - **內容生成：** 寫一篇文章、產生一首詩、草擬一封郵件。
        
    - **文本摘要：** 給定一篇文章，生成其摘要。
        
    - **簡單問答：** 「法國的首都是哪裡？」
        
- **範例程式碼 (概念)：**
       
    ```python
    response = llm.complete(
        prompt="請為一家新開的咖啡店想三個有創意的名字。"
    )
    print(response.text)
    # >> 1. 啡語流光 2. 城市焙思 3. 滴答手沖
    ```
    

#### **2.1.2 Chat 模式（對話模式）**

- **定義：** 專為多輪對話設計的模式。API 不只接收當前的問題，還會接收過去的對話歷史紀錄。這是一種有狀態 (Stateful) 的互動。
    
- **比喻：** 就像使用 LINE 或 Messenger，每一句話都建立在前文的基礎上，形成連續的對話。
    
- **關鍵概念：**
    
    - **角色 (Roles)：** 通常包含 `system` (設定 AI 的行為準則)、`user` (使用者輸入)、`assistant` (AI 的回覆)。
        
    - **對話歷史 (History)：** 每次請求都必須附上之前的對話內容，AI 才能「記住」上下文。
        
- **優點：**
    
    - 能處理複雜、有上下文關聯的任務。
        
    - 提供更自然、更具互動性的使用者體驗。
        
- **適用情境：**
    
    - **聊天機器人 (Chatbot)：** 客服、個人助理。
        
    - **逐步引導任務：** 「幫我規劃一趟去東京的五日遊。」 -> 「第一天想去哪些地方？」
        
    - **程式碼協作：** 「寫一個 Python 函式...」 -> 「不錯，現在幫我加上錯誤處理。」
        
- **範例程式碼 (概念)：**
    
    ```python
    messages = [
        {"role": "system", "content": "你是一位友善的旅遊規劃助理。"},
        {"role": "user", "content": "我想去一個溫暖的海島國家，有推薦嗎？"},
        {"role": "assistant", "content": "當然！泰國的普吉島和印尼的峇里島都是很棒的選擇，您對哪個比較感興趣呢？"},
        {"role": "user", "content": "那先介紹一下峇里島吧。"}
    ]
    response = llm.chat(messages=messages)
    print(response.text)
    ```
    

#### **2.1.3 Streaming 模式（串流模式）**

- **定義：** API 不會等所有內容生成完畢才一次性回傳，而是以「字詞」或「Token」為單位，即時、逐字地將結果串流回客戶端。
    
- **比喻：** 像是觀看 YouTube 直播，畫面是即時傳送過來的，而不是等整部影片下載完才播放。也像看著真人在打字，一個字一個字出現。
    
- **優點：**
    
    - **大幅降低感知延遲 (Perceived Latency)：** 使用者幾乎立刻就能看到回應，避免了漫長的等待焦慮。
        
    - **提升互動感：** 感覺更像在與一個「正在思考並回應」的對象交流。
        
- **適用情境：**
    
    - 所有需要即時互動的 Chat 應用。
        
    - 生成長文或程式碼時，讓使用者能先看到開頭部分。
        
- **挑戰：** 前端需要實作對應的邏輯來接收和拼接這些串流的字塊。
    

|模式|核心概念|使用者體驗|適用場景|
|---|---|---|---|
|**Completion**|一問一答，無記憶|快速直接，但生硬|內容總結、文案生成|
|**Chat**|多輪對話，有記憶|自然流暢，具互動性|客服、虛擬助理、教學|
|**Streaming**|即時逐字回傳|低延遲、高互動感|所有對話式應用|

---

### **2.2 三種對話 UX 模式 (Conversational UX Patterns)**

**核心問題：** 我們該如何設計對話的「流程」，讓使用者覺得 AI 是聰明且有幫助的？

#### **2.2.1 Command 模式（命令模式）**

- **定義：** 使用者給出明確、具體的指令，期望 AI 直接執行並給出結果。
    
- **互動心態：** 使用者把 AI 當作一個「高效率的工具」。
    
- **設計重點：**
    
    - **意圖辨識要精準：** AI 必須準確理解使用者的指令。
        
    - **回應要簡潔：** 直接給出答案或確認執行的結果，不多廢話。
        
- **範例：**
    
    - 使用者：「幫我設定明天早上 7 點的鬧鐘。」 -> AI：「好的，已設定明天早上 7 點的鬧鐘。」
        
    - 使用者：「查詢訂單 `A12345678` 的狀態。」 -> AI：「訂單 `A12345678` 目前狀態為：已出貨。」
        

#### **2.2.2 Clarification 模式（澄清模式）**

- **定義：** 當使用者的指令模糊或資訊不足時，AI 主動提出問題，以澄清意圖、補足資訊。
    
- **互動心態：** 使用者把 AI 當作一個「細心的夥伴」。
    
- **設計重點：**
    
    - **識別模糊地帶：** 知道何時該問問題，而不是猜測或直接拒絕。
        
    - **提問要聰明：** 提出的問題應該是關鍵性的，最好提供選項。
        
- **範例：**
    
    - 使用者：「幫我訂一張去東京的機票。」
        
    - AI (澄清)：「好的，請問您預計的出發日期是什麼時候呢？」
        
    - 使用者：「我想退貨。」
        
    - AI (澄清)：「沒問題，請問您想退貨的是哪一筆訂單呢？可以提供訂單編號嗎？」
        

#### **2.2.3 Suggestion 模式（建議模式）**

- **定義：** AI 在完成使用者的指令後，基於上下文，主動提供相關的、可能有幫助的建議或下一步操作。
    
- **互動心態：** 使用者把 AI 當作一個「有遠見的專家」。
    
- **設計重點：**
    
    - **建議要相關：** 提供的建議必須與當前對話高度相關。
        
    - **時機要恰當：** 在使用者完成一個主要任務節點後提出，避免打斷流程。
        
    - **不要強迫：** 以提議的口吻呈現，讓使用者可以輕鬆接受或拒絕。
        
- **範例：**
    
    - AI：「您的訂單 `A12345678` 已成功取消並辦理退款。」
        
    - AI (建議)：「很高興為您服務。順帶一提，您上次購買的《原子習慣》同系列作者有本新書《高效人士的七個習慣》，需要為您介紹嗎？」
        
    - 使用者：「幫我查一下台北今天的天氣。」
        
    - AI：「台北今天天氣晴朗，氣溫 28-34 度。」
        
    - AI (建議)：「天氣炎熱，提醒您多補充水分。需要幫您查詢附近的飲料店嗎？」
        

---

### **2.3 API 輸出信任層 (API Output Trust Layer)**

**核心問題：** LLM 的輸出是不確定的，有時甚至是「胡說八道」或格式錯誤。如何確保我們從 API 得到的結果是結構化、可靠、且能被程式其他部分安全使用的？

這一層是介於「LLM 原始輸出」和「你的應用程式邏輯」之間的**防護網**和**格式轉換器**。

#### **2.3.1 正則表達式 (Regular Expressions)**

- **用途：** 當你需要從 LLM 回傳的一段自然語言文字中，**抽取**出特定格式的簡單資訊時。
    
- **範例：**
    
    - **任務：** 從「我的訂單編號是 `ORD-2025-08-23-001`，請幫我查詢。」中提取訂單編號。
        
    - **作法：** 使用正則表達式 `ORD-\d{4}-\d{2}-\d{2}-\d{3}` 來匹配並抽取出 `ORD-2025-08-23-001`。
        
- **優點：** 快速、輕量，適合處理格式固定的簡單字串。
    
- **缺點：** 對於複雜的巢狀結構（如 JSON）無能為力，且規則寫起來較為繁瑣。
    

#### **2.3.2 Schema Validation (結構化驗證)**

- **用途：** 當你要求 LLM 輸出一種**複雜的、結構化的資料**（最常見的是 JSON），用以驗證其格式是否完全符合預期。
    
- **核心流程：**
    
    1. **定義 Schema：** 在 Prompt 中，明確指示 LLM 必須以 JSON 格式回覆，並提供 JSON 的結構範例。
        
    2. **LLM 輸出：** LLM 嘗試生成符合要求的 JSON 字串。
        
    3. **解析與驗證：** 你的程式碼先嘗試將 LLM 回傳的字串 `JSON.parse()`。成功後，再用一個預先定義好的 Schema（例如 Pydantic、JSON Schema）去驗證這個 JSON 物件的欄位、型別是否都正確。
        
    4. **重試機制：** 如果驗證失敗，可以將錯誤訊息連同原始請求再次發送給 LLM，要求它「修正錯誤並重新輸出」。
        
- **範例：**
    
    - **任務：** 從「幫我預約一位叫 John Doe 的客戶，電話是 0912-345-678，時間是明天下午 3 點」中提取預約資訊。
        
    - **Schema (Pydantic)：**
        
        ```python
        from pydantic import BaseModel
        class Appointment(BaseModel):
            name: str
            phone: str
            time: str
        ```
        
    - **驗證：** 程式會檢查 LLM 的輸出是否包含 `name`, `phone`, `time` 三個欄位，且其值是否為字串。
        
- **進階概念：** 現代的 LLM API（如 OpenAI 的 Function Calling）已經內建了類似的功能，能更可靠地強制 LLM 輸出符合特定結構的 JSON，這是 Schema Validation 的更穩健實踐。
    

---

### **Lab：做一個客服 Bot，測試三種 UX 模式**

**目標：** 綜合運用本模組所學，為一個虛構的電商平台「智慧小舖」打造一個多功能客服 Bot。

**場景設定：**

1. **Command 模式實作：查詢訂單**
    
    - **使用者輸入：** 「幫我查訂單 `S20250823001`」
        
    - **Bot 任務：**
        
        1. 使用**正則表達式**從使用者輸入中準確提取訂單編號。
            
        2. 呼叫一個假的後端函式 `getOrderStatus(orderId)`。
            
        3. 回傳訂單狀態，例如：「您好，訂單 `S20250823001` 的狀態是【已出貨】，預計 2 天內送達。」
            
    - **學習重點：** 指令理解、資訊抽取 (正則)。
        
2. **Clarification 模式實作：申請退貨**
    
    - **使用者輸入：** 「我想要退貨。」
        
    - **Bot 任務：**
        
        1. 辨識到使用者的意圖是「退貨」，但缺少關鍵資訊「訂單編號」。
            
        2. 進入 **Chat 模式**，發起澄清式提問：「好的，請問您要申請退貨的訂單編號是？」。
            
        3. 使用者提供編號後，Bot 再繼續後續流程。
            
    - **學習重點：** 模糊意圖處理、多輪對話 (Chat 模式)、狀態管理。
        
3. **Suggestion 模式實作：智慧推薦**
    
    - **情境接續：** 在使用者成功查詢完一筆「已完成」的訂單後（例如訂單內容是購買了一本《AI 技術的未來》）。
        
    - **Bot 任務：**
        
        1. 完成主要任務：「您的訂單 `S20250823001` 已於 8 月 20 日順利送達。」
            
        2. 觸發建議模式：「看到您對 AI 主題感興趣，我們最近剛上架一本新書《大型語言模型入門與實踐》，許多讀者反應熱烈，需要為您加入購物車嗎？」
            
    - **學習重點：** 上下文感知、主動服務、提升使用者價值。
        

**進階挑戰 (Bonus)：**

- 將 Bot 的所有回覆都改為 **Streaming 模式**，讓使用者能即時看到 Bot 的打字效果，提升互動體驗。
    
- 在處理使用者退貨請求時，要求 LLM 將退貨原因和訂單編號整理成一個固定的 JSON 格式，並用 **Schema Validation** 進行驗證，驗證通過後才模擬呼叫後端 API。

---

## 📘 模組 3：Context Engineering 必修基礎（第 3 週）

### 🎯 學習目標
理解並管理 LLM 的「記憶系統」——這是系統工程師的必修簡化版

### 📚 核心內容

#### 3.1 三層記憶架構

```python
class MemoryArchitecture:
    """LLM 應用的記憶管理系統"""
    
    def __init__(self):
        # 三層記憶體系
        self.system_prompt = SystemPrompt()      # 長期記憶（不變）
        self.user_context = UserContext()        # 中期記憶（session）
        self.conversation = ConversationBuffer() # 短期記憶（對話）
        
        # Token 預算管理
        self.token_budget = {
            "system": 1000,      # 系統提示
            "context": 2000,     # 用戶上下文
            "conversation": 5000, # 對話歷史
            "response": 1000     # 預留給回應
        }
    
    def build_context(self, user_input):
        """構建完整上下文"""
        # 1. 計算各部分 token
        system_tokens = self.count_tokens(self.system_prompt.get())
        
        # 2. 動態調整空間分配
        remaining = 8000 - system_tokens - 1000  # 總共 8K，預留 1K
        
        # 3. 智慧壓縮
        context = {
            "system": self.system_prompt.get(),
            "user_context": self.compress_context(
                self.user_context.get(), 
                max_tokens=remaining * 0.3
            ),
            "conversation": self.compress_conversation(
                self.conversation.get(),
                max_tokens=remaining * 0.7
            ),
            "current_input": user_input
        }
        
        return self.format_context(context)
```

#### 3.2 Context 壓縮策略

```python
class ContextCompressor:
    """上下文壓縮器"""
    
    def __init__(self):
        self.strategies = {
            "summarization": self.summarize,
            "sliding_window": self.sliding_window,
            "importance_sampling": self.importance_sampling
        }
    
    def summarize(self, messages, max_tokens):
        """摘要壓縮：適合長對話"""
        if self.count_tokens(messages) <= max_tokens:
            return messages
        
        # 分組摘要
        chunks = self.chunk_messages(messages, chunk_size=10)
        summaries = []
        
        for chunk in chunks[:-1]:  # 保留最新的不摘要
            summary = llm.complete(f"Summarize: {chunk}", max_tokens=100)
            summaries.append({
                "role": "system",
                "content": f"[Earlier conversation summary]: {summary}"
            })
        
        # 保留最新消息原文
        return summaries + chunks[-1]
    
    def sliding_window(self, messages, max_tokens):
        """滑動窗口：保留最近 N 條"""
        total_tokens = 0
        kept_messages = []
        
        # 從最新的開始保留
        for msg in reversed(messages):
            msg_tokens = self.count_tokens(msg)
            if total_tokens + msg_tokens <= max_tokens:
                kept_messages.insert(0, msg)
                total_tokens += msg_tokens
            else:
                break
        
        # 加入摘要提示
        if len(kept_messages) < len(messages):
            kept_messages.insert(0, {
                "role": "system",
                "content": f"[{len(messages) - len(kept_messages)} earlier messages omitted]"
            })
        
        return kept_messages
    
    def importance_sampling(self, messages, max_tokens):
        """重要性採樣：保留關鍵訊息"""
        # 計算每條訊息的重要性分數
        scored_messages = []
        for msg in messages:
            score = self.calculate_importance(msg)
            scored_messages.append((score, msg))
        
        # 排序並選擇
        scored_messages.sort(reverse=True)
        selected = []
        total_tokens = 0
        
        for score, msg in scored_messages:
            msg_tokens = self.count_tokens(msg)
            if total_tokens + msg_tokens <= max_tokens:
                selected.append(msg)
                total_tokens += msg_tokens
        
        # 保持時間順序
        return sorted(selected, key=lambda m: messages.index(m))
    
    def calculate_importance(self, message):
        """計算訊息重要性"""
        score = 0.0
        
        # 關鍵詞權重
        keywords = ["決定", "重要", "問題", "錯誤", "確認"]
        for keyword in keywords:
            if keyword in message.get("content", ""):
                score += 0.2
        
        # 用戶訊息權重更高
        if message.get("role") == "user":
            score += 0.3
        
        # 長度懲罰（太長的可能是廢話）
        length = len(message.get("content", ""))
        if length > 500:
            score -= 0.1
        
        # 時間衰減
        # score *= time_decay_factor
        
        return score
```

#### 3.3 記憶管理實戰

```python
class ConversationMemoryManager:
    """對話記憶管理器"""
    
    def __init__(self, model="gpt-4", max_tokens=8000):
        self.model = model
        self.max_tokens = max_tokens
        self.compressor = ContextCompressor()
        
        # 分層記憶
        self.memories = {
            "episodic": [],      # 事件記憶
            "semantic": {},      # 語義記憶
            "working": []        # 工作記憶
        }
    
    def add_turn(self, user_input, assistant_response):
        """添加一輪對話"""
        turn = {
            "user": user_input,
            "assistant": assistant_response,
            "timestamp": datetime.now(),
            "tokens": self.count_tokens(user_input + assistant_response)
        }
        
        # 加入工作記憶
        self.memories["working"].append(turn)
        
        # 檢查是否需要壓縮
        if self.get_total_tokens() > self.max_tokens * 0.8:
            self.compress()
        
        # 提取重要資訊到語義記憶
        self.extract_semantic_memory(turn)
    
    def compress(self):
        """壓縮記憶"""
        # 將舊的工作記憶轉為事件記憶
        if len(self.memories["working"]) > 10:
            # 摘要前 5 輪
            to_compress = self.memories["working"][:5]
            summary = self.create_summary(to_compress)
            
            self.memories["episodic"].append({
                "summary": summary,
                "original_turns": len(to_compress),
                "timestamp": to_compress[0]["timestamp"]
            })
            
            # 移除已壓縮的
            self.memories["working"] = self.memories["working"][5:]
    
    def extract_semantic_memory(self, turn):
        """提取語義記憶（實體、關係、事實）"""
        # 簡化版實體提取
        entities = self.extract_entities(turn["user"])
        for entity in entities:
            if entity not in self.memories["semantic"]:
                self.memories["semantic"][entity] = []
            
            self.memories["semantic"][entity].append({
                "context": turn["assistant"][:100],
                "timestamp": turn["timestamp"]
            })
    
    def get_relevant_context(self, query):
        """獲取相關上下文"""
        context_parts = []
        
        # 1. 相關的語義記憶
        relevant_entities = self.extract_entities(query)
        for entity in relevant_entities:
            if entity in self.memories["semantic"]:
                context_parts.append(
                    f"關於{entity}：{self.memories['semantic'][entity][-1]['context']}"
                )
        
        # 2. 最近的事件記憶
        if self.memories["episodic"]:
            latest_episode = self.memories["episodic"][-1]
            context_parts.append(f"早期對話摘要：{latest_episode['summary']}")
        
        # 3. 完整的工作記憶
        for turn in self.memories["working"][-5:]:  # 最近 5 輪
            context_parts.append(f"User: {turn['user']}")
            context_parts.append(f"Assistant: {turn['assistant']}")
        
        return "\n".join(context_parts)
```

### 🔬 Lab 實作：多輪對話摘要系統

```python
# Lab: 實作一個智慧對話摘要系統
class SmartConversationManager:
    def __init__(self):
        self.memory_manager = ConversationMemoryManager()
        self.token_limit = 4000
        
    async def chat(self, user_input, session_id):
        # 1. 載入 session 記憶
        context = self.memory_manager.get_relevant_context(user_input)
        
        # 2. 檢查 token 數量
        context_tokens = self.count_tokens(context)
        if context_tokens > self.token_limit:
            # 動態壓縮
            context = self.compress_context(context)
        
        # 3. 構建 prompt
        messages = [
            {"role": "system", "content": "你是一個智慧助理。"},
            {"role": "system", "content": f"[Context]: {context}"},
            {"role": "user", "content": user_input}
        ]
        
        # 4. 生成回應
        response = await self.generate_response(messages)
        
        # 5. 更新記憶
        self.memory_manager.add_turn(user_input, response)
        
        # 6. 顯示記憶體使用狀況
        memory_stats = {
            "working_memory_turns": len(self.memory_manager.memories["working"]),
            "episodic_memories": len(self.memory_manager.memories["episodic"]),
            "semantic_entities": len(self.memory_manager.memories["semantic"]),
            "total_tokens": self.memory_manager.get_total_tokens(),
            "compression_ratio": self.calculate_compression_ratio()
        }
        
        return {
            "response": response,
            "memory_stats": memory_stats
        }
    
    def compress_context(self, context):
        """智慧壓縮上下文"""
        strategies = [
            ("summarization", 0.5),
            ("sliding_window", 0.3),
            ("importance_sampling", 0.2)
        ]
        
        # 根據內容特性選擇策略
        if self.is_technical_discussion(context):
            # 技術討論保留更多細節
            return self.memory_manager.compressor.sliding_window(
                context, self.token_limit
            )
        else:
            # 一般對話可以摘要
            return self.memory_manager.compressor.summarize(
                context, self.token_limit
            )

# 測試長對話
manager = SmartConversationManager()
session_id = "test_session_001"

conversation = [
    "我想了解你們的退貨政策",
    "我上週買了一個產品，但是有問題",
    "訂單號是 ORD-12345",
    "產品是藍色的藍牙耳機",
    "問題是左耳常常斷線",
    "我已經試過重置了，沒有用",
    "可以換貨嗎？",
    "如果不能換貨，可以退款嗎？",
    "退款需要多久？",
    "需要支付運費嗎？"
]

for i, msg in enumerate(conversation):
    print(f"\n=== Turn {i+1} ===")
    result = await manager.chat(msg, session_id)
    print(f"User: {msg}")
    print(f"Assistant: {result['response'][:100]}...")
    print(f"Memory Stats: {result['memory_stats']}")
    
    # 模擬記憶體壓力
    if i == 4:
        print("\n[觸發記憶壓縮...]")
```

### 💡 實戰心得
> 💾 **Memory is Money**：每個 token 都是成本。學會壓縮是省錢的關鍵。我們曾經把一個客服系統的成本降低 60%，就是優化了記憶管理。

---

## 📘 模組 4：知識掛載與 RAG 基礎（第 4 週）

### 🎯 學習目標
掌握 RAG 的核心概念和失敗處理——不需要懂向量資料庫原理

### 📚 核心內容

#### 4.1 簡化版 RAG Pipeline

```python
class SimpleRAG:
    """應用工程師版的 RAG 系統"""
    
    def __init__(self):
        # 使用現成的向量資料庫服務
        self.vector_db = Pinecone(api_key="your-key")
        self.embedder = OpenAIEmbeddings()
        
        # 失敗處理策略
        self.fallback_strategies = {
            "no_results": self.handle_no_results,
            "conflicting": self.handle_conflicts,
            "low_confidence": self.handle_low_confidence
        }
    
    def search(self, query, k=5):
        """基礎檢索"""
        # 1. 生成 embedding（不需要懂原理）
        query_embedding = self.embedder.embed(query)
        
        # 2. 向量檢索
        results = self.vector_db.query(
            vector=query_embedding,
            top_k=k,
            include_metadata=True
        )
        
        # 3. 處理檢索失敗
        if not results or results[0].score < 0.7:
            return self.fallback_strategies["no_results"](query)
        
        # 4. 檢查衝突
        if self.has_conflicts(results):
            return self.fallback_strategies["conflicting"](results)
        
        return results
    
    def has_conflicts(self, results):
        """檢測結果是否衝突"""
        # 簡單規則：如果前兩個結果的內容矛盾
        if len(results) >= 2:
            doc1 = results[0].metadata['content']
            doc2 = results[1].metadata['content']
            
            # 用 LLM 檢測矛盾
            prompt = f"""
            Document 1: {doc1}
            Document 2: {doc2}
            
            Do these documents contradict each other? (Yes/No)
            """
            
            response = llm.complete(prompt)
            return "yes" in response.lower()
        
        return False
```

#### 4.2 RAG 失敗處理的藝術

```python
class RAGFailureHandler:
    """RAG 失敗處理專家"""
    
    def handle_no_results(self, query):
        """找不到相關文件"""
        strategies = [
            self.try_rephrase,        # 改寫查詢
            self.try_decompose,       # 拆解查詢
            self.try_generalize,      # 泛化查詢
            self.fallback_to_llm      # 直接用 LLM
        ]
        
        for strategy in strategies:
            result = strategy(query)
            if result["success"]:
                return result["data"]
        
        # 優雅失敗
        return {
            "found": False,
            "message": "抱歉，我在知識庫中找不到相關資訊。讓我用一般知識來回答...",
            "fallback_response": self.generate_general_response(query)
        }
    
    def try_rephrase(self, query):
        """改寫查詢詞"""
        rephrases = [
            f"換句話說：{query}",
            f"相關於：{query}",
            f"關於{self.extract_keywords(query)}"
        ]
        
        for rephrase in rephrases:
            results = self.search(rephrase)
            if results:
                return {"success": True, "data": results}
        
        return {"success": False}
    
    def handle_conflicts(self, conflicting_results):
        """處理矛盾的結果"""
        # 策略 1：顯示所有觀點
        response = "我找到了不同的資訊：\n"
        for i, result in enumerate(conflicting_results[:2]):
            response += f"\n觀點 {i+1}：{result.metadata['content'][:200]}...\n"
        response += "\n請注意這些資訊可能有所差異。"
        
        # 策略 2：讓 LLM 綜合判斷
        synthesis_prompt = f"""
        以下是關於同一問題的不同資料：
        {[r.metadata['content'] for r in conflicting_results]}
        
        請綜合這些資訊，給出平衡的答案。
        """
        
        synthesized = llm.complete(synthesis_prompt)
        
        return {
            "has_conflicts": True,
            "all_views": response,
            "synthesis": synthesized
        }
    
    def handle_low_confidence(self, results):
        """處理低信心度結果"""
        disclaimer = "⚠️ 以下資訊可能不完全準確，僅供參考：\n\n"
        
        # 加入信心度指示
        enriched_response = ""
        for result in results:
            confidence = result.score
            if confidence > 0.9:
                confidence_indicator = "✅ 高度相關"
            elif confidence > 0.7:
                confidence_indicator = "⚠️ 部分相關"
            else:
                confidence_indicator = "❌ 相關性較低"
            
            enriched_response += f"{confidence_indicator}: {result.metadata['content']}\n\n"
        
        return disclaimer + enriched_response
```

#### 4.3 Chunking 策略（簡化版）

```python
class SimpleChunker:
    """文件切塊器 - 應用層面就夠了"""
    
    def __init__(self, chunk_size=500, overlap=50):
        self.chunk_size = chunk_size
        self.overlap = overlap
    
    def chunk_document(self, document):
        """基礎切塊策略"""
        chunks = []
        
        # 策略 1：按段落切
        paragraphs = document.split('\n\n')
        
        current_chunk = ""
        for para in paragraphs:
            if len(current_chunk) + len(para) < self.chunk_size:
                current_chunk += para + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para + "\n\n"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # 加入 overlap
        chunks_with_overlap = []
        for i, chunk in enumerate(chunks):
            if i > 0:
                # 加入前一塊的結尾
                prev_end = chunks[i-1][-self.overlap:] if len(chunks[i-1]) > self.overlap else chunks[i-1]
                chunk = prev_end + "\n...\n" + chunk
            
            if i < len(chunks) - 1:
                # 加入下一塊的開頭
                next_start = chunks[i+1][:self.overlap] if len(chunks[i+1]) > self.overlap else chunks[i+1]
                chunk = chunk + "\n...\n" + next_start
            
            chunks_with_overlap.append(chunk)
        
        return chunks_with_overlap
```

### 🔬 Lab 實作：FAQ Bot with Fallback

```python
# Lab: 建立一個有完善 fallback 的 FAQ Bot
class SmartFAQBot:
    def __init__(self):
        self.rag = SimpleRAG()
        self.failure_handler = RAGFailureHandler()
        self.response_cache = {}
        
        # 預載入 FAQ
        self.load_faqs()
    
    def load_faqs(self):
        """載入常見問題"""
        faqs = [
            {
                "question": "如何退貨？",
                "answer": "您可以在收到商品後 7 天內申請退貨...",
                "keywords": ["退貨", "退款", "return"]
            },
            {
                "question": "運費怎麼算？",
                "answer": "運費根據地區和重量計算...",
                "keywords": ["運費", "配送", "shipping"]
            }
        ]
        
        for faq in faqs:
            # 向量化並存入資料庫
            embedding = self.rag.embedder.embed(faq["question"])
            self.rag.vector_db.upsert(
                id=f"faq_{hash(faq['question'])}",
                vector=embedding,
                metadata=faq
            )
    
    async def answer(self, question):
        # 1. 檢查 cache
        if question in self.response_cache:
            return self.response_cache[question]
        
        # 2. RAG 檢索
        results = self.rag.search(question, k=3)
        
        # 3. 處理各種情況
        if isinstance(results, dict):
            if not results.get("found", True):
                # 沒找到：使用 fallback
                response = await self.generate_fallback_response(question)
            elif results.get("has_conflicts"):
                # 有衝突：顯示多個觀點
                response = self.format_conflicting_response(results)
            else:
                # 低信心度
                response = results
        else:
            # 正常情況：基於檢索結果生成答案
            response = await self.generate_answer(question, results)
        
        # 4. 快取結果
        self.response_cache[question] = response
        
        # 5. 記錄 metrics
        self.log_metrics(question, results, response)
        
        return response
    
    async def generate_answer(self, question, search_results):
        """基於檢索結果生成答案"""
        context = "\n".join([r.metadata['answer'] for r in search_results[:2]])
        
        prompt = f"""
        基於以下資訊回答用戶問題：
        
        資訊：
        {context}
        
        用戶問題：{question}
        
        要求：
        1. 如果資訊足夠，直接回答
        2. 如果資訊不足，說明哪部分無法回答
        3. 保持友善專業的語氣
        """
        
        return await llm.complete(prompt)
    
    async def generate_fallback_response(self, question):
        """生成 fallback 回應"""
        # 多層 fallback
        fallbacks = [
            # Level 1: 嘗試用通用知識
            lambda: llm.complete(f"用一般知識回答：{question}"),
            
            # Level 2: 提供相關連結
            lambda: f"我無法直接回答您的問題，但您可以查看我們的幫助中心：https://help.example.com",
            
            # Level 3: 轉人工
            lambda: "這個問題較為複雜，建議您聯繫客服人員。是否需要我幫您轉接？"
        ]
        
        for fallback in fallbacks:
            try:
                return fallback()
            except:
                continue
        
        return "抱歉，我暫時無法回答這個問題。"

# 測試各種場景
bot = SmartFAQBot()

test_cases = [
    "如何退貨？",           # 正常匹配
    "退貨政策是什麼？",     # 需要改寫
    "你們賣火箭嗎？",       # 完全無關
    "退貨和換貨的區別？",   # 部分匹配
    "Can I return this?",   # 其他語言
]

for question in test_cases:
    print(f"\n問題：{question}")
    answer = await bot.answer(question)
    print(f"回答：{answer[:200]}...")
    print("-" * 50)
```

### 💡 實戰心得
> 🎯 **RAG 的精髓不是檢索，而是失敗處理**。一個好的 RAG 系統，80% 的程式碼都在處理「沒找到」或「找錯了」的情況。

---

## 📘 模組 5：產品思維 for LLM Apps（第 5 週）

### 🎯 學習目標
培養產品思維，知道何時該用/不該用 LLM

### 📚 核心內容

#### 5.1 LLM 的能力矩陣

| 任務類型 | 適合用 LLM | 不適合用 LLM | 替代方案 |
|---------|-----------|-------------|---------|
| **創意生成** | ✅ 文案、故事、點子 | ❌ 需要事實準確的內容 | 人工創作 + LLM 輔助 |
| **格式轉換** | ✅ JSON↔自然語言 | ❌ 複雜的資料轉換 | 專門的 Parser |
| **分類任務** | ✅ 情感分析、主題分類 | ❌ 需要 100% 準確率 | 傳統 ML 模型 |
| **計算任務** | ✅ 簡單估算 | ❌ 精確計算 | Calculator API |
| **搜尋任務** | ✅ 語義搜尋 | ❌ 精確匹配 | 傳統搜尋引擎 |
| **決策任務** | ✅ 建議、推薦 | ❌ 關鍵決策 | 規則引擎 + 人工 |

#### 5.2 成本-延遲-體驗三角

```python
class ProductDecisionFramework:
    """產品決策框架"""
    
    def __init__(self):
        self.metrics = {
            "cost": {"weight": 0.3, "threshold": 0.1},      # $0.1 per request
            "latency": {"weight": 0.3, "threshold": 2000},  # 2 seconds
            "quality": {"weight": 0.4, "threshold": 0.85}   # 85% satisfaction
        }
    
    def evaluate_llm_fit(self, use_case):
        """評估是否適合用 LLM"""
        score = 0
        reasons = []
        
        # 正面因素
        if use_case["requires_creativity"]:
            score += 30
            reasons.append("✅ 需要創意生成")
        
        if use_case["handles_natural_language"]:
            score += 25
            reasons.append("✅ 處理自然語言")
        
        if use_case["needs_flexibility"]:
            score += 20
            reasons.append("✅ 需要靈活性")
        
        # 負面因素
        if use_case["requires_deterministic"]:
            score -= 40
            reasons.append("❌ 需要確定性結果")
        
        if use_case["cost_sensitive"]:
            score -= 30
            reasons.append("❌ 成本敏感")
        
        if use_case["latency_critical"]:
            score -= 25
            reasons.append("❌ 延遲關鍵")
        
        # 決策
        recommendation = "USE_LLM" if score > 0 else "AVOID_LLM"
        
        return {
            "score": score,
            "recommendation": recommendation,
            "reasons": reasons,
            "alternative": self.suggest_alternative(use_case) if score < 0 else None
        }
    
    def suggest_alternative(self, use_case):
        """建議替代方案"""
        if use_case["requires_deterministic"]:
            return "使用規則引擎或傳統演算法"
        elif use_case["cost_sensitive"]:
            return "使用快取層 + 小模型"
        elif use_case["latency_critical"]:
            return "預生成 + Edge 部署"
        else:
            return "混合方案：關鍵路徑用傳統方法，輔助功能用 LLM"
```

#### 5.3 優雅降級策略

```python
class GracefulDegradation:
    """優雅降級系統"""
    
    def __init__(self):
        self.strategies = [
            self.try_primary,      # 主要策略：完整 LLM
            self.try_cache,        # 快取策略
            self.try_simple_model, # 簡單模型
            self.try_template,     # 模板回覆
            self.try_human         # 人工介入
        ]
        
        self.cache = ResponseCache()
        self.template_engine = TemplateEngine()
    
    async def handle_request(self, request):
        """多層降級處理"""
        start_time = time.time()
        
        for i, strategy in enumerate(self.strategies):
            try:
                # 設定超時
                timeout = self.calculate_timeout(i)
                
                result = await asyncio.wait_for(
                    strategy(request),
                    timeout=timeout
                )
                
                if result["success"]:
                    # 記錄使用了哪個策略
                    result["strategy_used"] = strategy.__name__
                    result["degradation_level"] = i
                    result["total_time"] = time.time() - start_time
                    
                    return result
                    
            except asyncio.TimeoutError:
                print(f"Strategy {strategy.__name__} timeout")
                continue
            except Exception as e:
                print(f"Strategy {strategy.__name__} failed: {e}")
                continue
        
        # 所有策略都失敗
        return self.final_fallback(request)
    
    async def try_primary(self, request):
        """主要策略：完整 LLM 處理"""
        response = await llm.complete(
            request["prompt"],
            model="gpt-4",
            temperature=0.7
        )
        
        return {
            "success": True,
            "response": response,
            "quality": "high"
        }
    
    async def try_cache(self, request):
        """快取策略"""
        # 語義相似度快取
        cached = self.cache.get_similar(request["prompt"], threshold=0.95)
        
        if cached:
            return {
                "success": True,
                "response": cached["response"],
                "quality": "cached",
                "cache_hit": True
            }
        
        return {"success": False}
    
    async def try_simple_model(self, request):
        """使用更簡單的模型"""
        response = await llm.complete(
            request["prompt"],
            model="gpt-3.5-turbo",  # 降級到更快更便宜的模型
            temperature=0.5,
            max_tokens=150
        )
        
        return {
            "success": True,
            "response": response,
            "quality": "medium"
        }
    
    async def try_template(self, request):
        """模板回覆"""
        # 意圖識別
        intent = self.classify_intent(request["prompt"])
        
        if intent in self.template_engine.templates:
            response = self.template_engine.generate(intent, request)
            return {
                "success": True,
                "response": response,
                "quality": "template"
            }
        
        return {"success": False}
    
    async def try_human(self, request):
        """轉人工"""
        # 創建工單
        ticket = self.create_support_ticket(request)
        
        response = f"""
        您的問題較為複雜，我已經為您創建了工單 #{ticket['id']}。
        客服人員將在 30 分鐘內與您聯繫。
        
        您也可以直接撥打客服熱線：400-XXX-XXXX
        """
        
        return {
            "success": True,
            "response": response,
            "quality": "human_escalation",
            "ticket": ticket
        }
    
    def calculate_timeout(self, level):
        """根據降級等級計算超時時間"""
        timeouts = [3.0, 1.0, 0.5, 0.2, 0.1]  # 逐級降低
        return timeouts[min(level, len(timeouts) - 1)]
```

### 🔬 Lab 實作：降級策略設計與測試

```python
# Lab: 設計並測試降級策略
class DegradationTestBench:
    """降級策略測試平台"""
    
    def __init__(self):
        self.degradation = GracefulDegradation()
        self.metrics = {
            "success_rate": [],
            "response_time": [],
            "quality_score": [],
            "cost": []
        }
    
    async def simulate_load(self, requests_per_second=10, duration=60):
        """模擬負載測試"""
        tasks = []
        
        for i in range(duration):
            for j in range(requests_per_second):
                # 模擬不同類型的請求
                request = self.generate_request()
                
                # 隨機注入故障
                if random.random() < 0.1:  # 10% 故障率
                    request["inject_failure"] = True
                
                task = self.process_request(request)
                tasks.append(task)
            
            await asyncio.sleep(1)
        
        results = await asyncio.gather(*tasks)
        self.analyze_results(results)
    
    async def process_request(self, request):
        """處理單個請求"""
        start = time.time()
        
        # 模擬網路問題
        if request.get("inject_failure"):
            await asyncio.sleep(random.uniform(5, 10))  # 超時
        
        result = await self.degradation.handle_request(request)
        
        # 記錄 metrics
        self.metrics["response_time"].append(time.time() - start)
        self.metrics["success_rate"].append(1 if result["success"] else 0)
        self.metrics["quality_score"].append(
            self.calculate_quality_score(result)
        )
        self.metrics["cost"].append(
            self.calculate_cost(result)
        )
        
        return result
    
    def calculate_quality_score(self, result):
        """計算品質分數"""
        quality_map = {
            "high": 1.0,
            "cached": 0.9,
            "medium": 0.7,
            "template": 0.5,
            "human_escalation": 0.3
        }
        return quality_map.get(result.get("quality", "unknown"), 0)
    
    def calculate_cost(self, result):
        """計算成本"""
        cost_map = {
            "try_primary": 0.03,      # GPT-4
            "try_cache": 0.0001,      # 幾乎免費
            "try_simple_model": 0.002, # GPT-3.5
            "try_template": 0,         # 免費
            "try_human": 5.0          # 人工成本
        }
        
        strategy = result.get("strategy_used", "unknown")
        return cost_map.get(strategy, 0)
    
    def analyze_results(self, results):
        """分析測試結果"""
        print("\n=== 降級策略測試報告 ===\n")
        
        # 成功率
        success_rate = sum(self.metrics["success_rate"]) / len(self.metrics["success_rate"])
        print(f"✅ 成功率: {success_rate:.2%}")
        
        # 響應時間
        avg_response = sum(self.metrics["response_time"]) / len(self.metrics["response_time"])
        p95_response = sorted(self.metrics["response_time"])[int(len(self.metrics["response_time"]) * 0.95)]
        print(f"⏱️ 平均響應時間: {avg_response:.2f}秒")
        print(f"⏱️ P95 響應時間: {p95_response:.2f}秒")
        
        # 品質分數
        avg_quality = sum(self.metrics["quality_score"]) / len(self.metrics["quality_score"])
        print(f"⭐ 平均品質分數: {avg_quality:.2f}/1.0")
        
        # 成本
        total_cost = sum(self.metrics["cost"])
        avg_cost = total_cost / len(self.metrics["cost"])
        print(f"💰 總成本: ${total_cost:.2f}")
        print(f"💰 平均成本: ${avg_cost:.4f}/request")
        
        # 策略使用分布
        strategy_counts = {}
        for result in results:
            strategy = result.get("strategy_used", "unknown")
            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
        
        print("\n📊 策略使用分布:")
        for strategy, count in sorted(strategy_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(results) * 100
            print(f"  - {strategy}: {count} ({percentage:.1f}%)")
        
        # 成本效益分析
        cost_per_quality = total_cost / (avg_quality * len(results))
        print(f"\n💡 成本效益比: ${cost_per_quality:.4f}/quality point")
        
        # 建議
        print("\n🎯 優化建議:")
        if avg_response > 2:
            print("  - 響應時間過長，考慮增加快取或使用更快的模型")
        if avg_quality < 0.7:
            print("  - 品質分數偏低，考慮調整降級閾值")
        if avg_cost > 0.01:
            print("  - 成本偏高，增加快取命中率或使用更多模板")

# 執行測試
test_bench = DegradationTestBench()
await test_bench.simulate_load(requests_per_second=5, duration=30)
```

### 💡 實戰心得
> 🎯 **黃金法則**：永遠不要讓 LLM 成為單點故障。每個 LLM 呼叫都應該有至少 2 層 fallback。

---

## 📘 模組 6：應用級 Workflow（第 6 週）

### 🎯 學習目標
設計多步驟任務流程，處理真實世界的髒資料

### 📚 核心內容

#### 6.1 Chain 思維設計模式

```python
class WorkflowChain:
    """工作流鏈設計"""
    
    def __init__(self):
        self.steps = []
        self.error_handlers = {}
        self.validators = {}
    
    def add_step(self, name, function, validator=None, error_handler=None):
        """添加步驟"""
        self.steps.append({
            "name": name,
            "function": function
        })
        
        if validator:
            self.validators[name] = validator
        if error_handler:
            self.error_handlers[name] = error_handler
        
        return self  # 支援鏈式呼叫
    
    async def execute(self, input_data):
        """執行工作流"""
        context = {"input": input_data, "steps": {}}
        
        for step in self.steps:
            step_name = step["name"]
            print(f"執行步驟: {step_name}")
            
            try:
                # 執行步驟
                result = await step["function"](context)
                
                # 驗證結果
                if step_name in self.validators:
                    is_valid = self.validators[step_name](result)
                    if not is_valid:
                        raise ValueError(f"Validation failed for {step_name}")
                
                # 儲存結果
                context["steps"][step_name] = result
                
            except Exception as e:
                # 錯誤處理
                if step_name in self.error_handlers:
                    result = self.error_handlers[step_name](e, context)
                    context["steps"][step_name] = result
                else:
                    raise
        
        return context
```

#### 6.2 髒資料處理大全

```python
class DirtyDataProcessor:
    """髒資料處理專家"""
    
    def __init__(self):
        self.cleaners = {
            "typo": self.fix_typos,
            "mixed_language": self.handle_mixed_language,
            "emotional": self.handle_emotional_input,
            "incomplete": self.handle_incomplete,
            "contradictory": self.handle_contradictory
        }
    
    def clean(self, dirty_input):
        """清理髒資料"""
        cleaned = dirty_input
        issues_found = []
        
        # 檢測並修復各種問題
        for issue_type, cleaner in self.cleaners.items():
            if self.detect_issue(cleaned, issue_type):
                cleaned = cleaner(cleaned)
                issues_found.append(issue_type)
        
        return {
            "original": dirty_input,
            "cleaned": cleaned,
            "issues_found": issues_found,
            "confidence": self.calculate_confidence(issues_found)
        }
    
    def fix_typos(self, text):
        """修正錯字"""
        # 簡單的錯字修正
        common_typos = {
            "teh": "the",
            "recieve": "receive",
            "occured": "occurred",
            "refund": "refund",  
            "cancle": "cancel"
        }
        
        for typo, correct in common_typos.items():
            text = text.replace(typo, correct)
        
        # 使用 LLM 修正更複雜的錯字
        if self.has_potential_typos(text):
            prompt = f"""
            修正以下文字中的錯字，但保持原意：
            原文：{text}
            修正後：
            """
            text = llm.complete(prompt, temperature=0.1)
        
        return text
    
    def handle_mixed_language(self, text):
        """處理混合語言"""
        # 檢測語言
        languages = self.detect_languages(text)
        
        if len(languages) > 1:
            # 策略 1：翻譯成主要語言
            primary_lang = max(languages.items(), key=lambda x: x[1])[0]
            
            prompt = f"""
            將以下混合語言文字統一翻譯成{primary_lang}：
            {text}
            """
            
            return llm.complete(prompt)
        
        return text
    
    def handle_emotional_input(self, text):
        """處理情緒化輸入"""
        emotion_score = self.detect_emotion(text)
        
        if emotion_score > 0.7:  # 高度情緒化
            # 提取核心訴求
            prompt = f"""
            用戶情緒激動地說：{text}
            
            請提取用戶的核心訴求（忽略情緒化表達）：
            """
            
            core_request = llm.complete(prompt)
            
            return {
                "original": text,
                "emotion_level": "high",
                "core_request": core_request,
                "suggested_response_tone": "empathetic"
            }
        
        return text
    
    def handle_incomplete(self, text):
        """處理不完整輸入"""
        if len(text.split()) < 3:  # 太短
            return {
                "original": text,
                "issue": "incomplete",
                "clarification_needed": True,
                "suggested_questions": [
                    "您能詳細說明一下嗎？",
                    "請問具體是什麼問題？",
                    "能提供更多資訊嗎？"
                ]
            }
        
        return text
```

#### 6.3 Agent-like Flow 設計

```python
class SimpleAgent:
    """簡單 Agent 流程"""
    
    def __init__(self):
        self.tools = {
            "search_order": self.search_order,
            "check_inventory": self.check_inventory,
            "calculate_shipping": self.calculate_shipping,
            "process_refund": self.process_refund
        }
        
        self.planner = TaskPlanner()
        self.executor = TaskExecutor()
    
    async def process(self, user_request):
        """處理用戶請求"""
        
        # 1. 理解意圖
        intent = await self.understand_intent(user_request)
        
        # 2. 規劃步驟
        plan = await self.planner.create_plan(intent, self.tools.keys())
        
        # 3. 執行計劃
        results = []
        for step in plan["steps"]:
            result = await self.execute_step(step)
            results.append(result)
            
            # 動態調整計劃
            if result.get("requires_replanning"):
                plan = await self.planner.replan(plan, results)
        
        # 4. 綜合結果
        final_response = await self.synthesize_response(results)
        
        return final_response
    
    async def understand_intent(self, request):
        """理解用戶意圖"""
        prompt = f"""
        分析用戶請求並識別意圖：
        
        用戶說：{request}
        
        可能的意圖：
        - ORDER_STATUS: 查詢訂單狀態
        - REFUND_REQUEST: 申請退款
        - PRODUCT_INQUIRY: 產品諮詢
        - SHIPPING_INFO: 運送資訊
        - COMPLAINT: 投訴
        - OTHER: 其他
        
        返回格式：
        {{
            "primary_intent": "...",
            "entities": {{...}},
            "confidence": 0.X
        }}
        """
        
        response = await llm.complete(prompt)
        return json.loads(response)
    
    async def execute_step(self, step):
        """執行單個步驟"""
        tool_name = step["tool"]
        params = step["params"]
        
        if tool_name not in self.tools:
            return {"error": f"Tool {tool_name} not found"}
        
        try:
            result = await self.tools[tool_name](**params)
            return {"success": True, "data": result}
        except Exception as e:
            return {"success": False, "error": str(e)}
```

### 🔬 Lab 實作：訂單查詢助理

```python
# Lab: 能處理混合語言和模糊輸入的訂單助理
class SmartOrderAssistant:
    def __init__(self):
        self.workflow = WorkflowChain()
        self.data_processor = DirtyDataProcessor()
        self.agent = SimpleAgent()
        
        # 設定工作流
        self.setup_workflow()
    
    def setup_workflow(self):
        """設定工作流程"""
        self.workflow \
            .add_step("clean_input", self.clean_input) \
            .add_step("extract_info", self.extract_order_info) \
            .add_step("search_order", self.search_order) \
            .add_step("check_status", self.check_order_status) \
            .add_step("generate_response", self.generate_response)
    
    async def clean_input(self, context):
        """步驟 1：清理輸入"""
        raw_input = context["input"]
        
        # 處理髒資料
        cleaned = self.data_processor.clean(raw_input)
        
        # 處理特殊情況
        if "mixed_language" in cleaned["issues_found"]:
            # 統一語言
            cleaned["cleaned"] = await self.translate_to_primary(cleaned["cleaned"])
        
        if "emotional" in cleaned["issues_found"]:
            # 記錄情緒狀態
            context["emotional_state"] = "high"
            context["response_tone"] = "empathetic"
        
        return cleaned
    
    async def extract_order_info(self, context):
        """步驟 2：提取訂單資訊"""
        cleaned_input = context["steps"]["clean_input"]["cleaned"]
        
        prompt = f"""
        從以下文字中提取訂單相關資訊：
        {cleaned_input}
        
        提取：
        - order_id: 訂單號（如果有）
        - product_name: 產品名稱
        - issue: 問題描述
        - date: 相關日期
        
        如果資訊不完整，標記 needs_clarification: true
        """
        
        extracted = await llm.complete(prompt, response_format={"type": "json"})
        
        # 驗證提取結果
        if not extracted.get("order_id"):
            # 嘗試模糊匹配
            extracted["possible_orders"] = await self.fuzzy_search_orders(cleaned_input)
        
        return extracted
    
    async def search_order(self, context):
        """步驟 3：搜尋訂單"""
        order_info = context["steps"]["extract_info"]
        
        if order_info.get("order_id"):
            # 精確搜尋
            order = await self.db.find_order(order_info["order_id"])
        elif order_info.get("possible_orders"):
            # 讓用戶確認
            return {
                "found_multiple": True,
                "orders": order_info["possible_orders"],
                "needs_confirmation": True
            }
        else:
            # 根據其他資訊搜尋
            orders = await self.db.search_orders(
                customer_id=context.get("customer_id"),
                product=order_info.get("product_name"),
                date_range=self.parse_date_range(order_info.get("date"))
            )
            
            if len(orders) == 1:
                order = orders[0]
            elif len(orders) > 1:
                return {"found_multiple": True, "orders": orders}
            else:
                return {"found": False}
        
        return {"found": True, "order": order}
    
    async def generate_response(self, context):
        """步驟 5：生成回應"""
        order_result = context["steps"]["search_order"]
        
        # 根據不同情況生成回應
        if not order_result.get("found"):
            response = "抱歉，我找不到相關訂單。請確認訂單號或提供更多資訊。"
        elif order_result.get("found_multiple"):
            response = self.format_multiple_orders(order_result["orders"])
        else:
            order = order_result["order"]
            status = context["steps"]["check_status"]
            response = self.format_order_status(order, status)
        
        # 根據情緒狀態調整語氣
        if context.get("emotional_state") == "high":
            response = self.add_empathy(response)
        
        return response
    
    async def handle_user_input(self, user_input):
        """主入口：處理用戶輸入"""
        
        # 測試各種髒輸入
        test_inputs = [
            "我的訂單（訂單號：ORD12345）到哪了？？？",  # 正常
            "Check my order status ORDER12345 謝謝",      # 混合語言
            "wtf 我的東西呢！！！都三天了！！！",         # 情緒化
            "訂單",                                        # 不完整
            "我上週買的藍牙耳機怎麼還沒到",                # 模糊
            "ORD1234... 不對是 ORD12346",                 # 矛盾
        ]
        
        results = []
        for test_input in test_inputs:
            print(f"\n處理輸入: {test_input}")
            
            try:
                result = await self.workflow.execute(test_input)
                response = result["steps"]["generate_response"]
                
                print(f"清理後: {result['steps']['clean_input']['cleaned']}")
                print(f"提取資訊: {result['steps']['extract_info']}")
                print(f"回應: {response}")
                
                results.append({
                    "input": test_input,
                    "success": True,
                    "response": response
                })
                
            except Exception as e:
                print(f"錯誤: {e}")
                results.append({
                    "input": test_input,
                    "success": False,
                    "error": str(e)
                })
        
        # 統計成功率
        success_rate = sum(1 for r in results if r["success"]) / len(results)
        print(f"\n成功率: {success_rate:.1%}")
        
        return results

# 執行測試
assistant = SmartOrderAssistant()
results = await assistant.handle_user_input("測試輸入")
```

### 💡 實戰心得
> 🔧 **髒資料是常態，不是例外**。一個產品級的 LLM 應用，50% 的程式碼都在處理各種邊界情況。

---

## 📘 模組 7：可靠性與可觀測性（第 7 週）

### 🎯 學習目標
建立監控體系，優化成本與性能

### 📚 核心內容

#### 7.1 成本工程實戰

```python
class CostEngineering:
    """成本工程系統"""
    
    def __init__(self):
        self.token_prices = {
            "gpt-4": {"input": 0.03, "output": 0.06},      # per 1K tokens
            "gpt-3.5-turbo": {"input": 0.001, "output": 0.002},
            "claude-3-opus": {"input": 0.015, "output": 0.075},
            "claude-3-sonnet": {"input": 0.003, "output": 0.015}
        }
        
        self.optimizers = {
            "batching": BatchingOptimizer(),
            "caching": CachingOptimizer(),
            "routing": ModelRouter(),
            "compression": PromptCompressor()
        }
    
    def optimize_request(self, request):
        """優化單個請求"""
        original_cost = self.estimate_cost(request)
        optimized = request.copy()
        
        # 1. 壓縮 Prompt
        optimized["prompt"] = self.optimizers["compression"].compress(
            request["prompt"]
        )
        
        # 2. 選擇最佳模型
        optimized["model"] = self.optimizers["routing"].select_model(
            task_type=request["task_type"],
            quality_requirement=request.get("quality", 0.8),
            budget=request.get("budget", float('inf'))
        )
        
        # 3. 檢查快取
        cached = self.optimizers["caching"].get(optimized["prompt"])
        if cached:
            return {
                "response": cached,
                "cost": 0,
                "source": "cache",
                "savings": original_cost
            }
        
        # 4. 批次處理
        if self.optimizers["batching"].should_batch(optimized):
            batch_id = self.optimizers["batching"].add_to_batch(optimized)
            return {
                "batch_id": batch_id,
                "estimated_wait": self.optimizers["batching"].estimate_wait(),
                "estimated_savings": original_cost * 0.3
            }
        
        final_cost = self.estimate_cost(optimized)
        
        return {
            "optimized_request": optimized,
            "original_cost": original_cost,
            "optimized_cost": final_cost,
            "savings": original_cost - final_cost,
            "savings_percentage": (original_cost - final_cost) / original_cost * 100
        }
    
    def estimate_cost(self, request):
        """估算成本"""
        model = request["model"]
        prompt_tokens = self.count_tokens(request["prompt"])
        
        # 估算輸出 tokens（經驗值）
        estimated_output = prompt_tokens * 0.8
        
        input_cost = (prompt_tokens / 1000) * self.token_prices[model]["input"]
        output_cost = (estimated_output / 1000) * self.token_prices[model]["output"]
        
        return input_cost + output_cost
```

#### 7.2 可觀測性架構

```python
class ObservabilitySystem:
    """可觀測性系統"""
    
    def __init__(self):
        self.metrics = MetricsCollector()
        self.tracer = DistributedTracer()
        self.logger = StructuredLogger()
        self.profiler = PerformanceProfiler()
        
        # 關鍵指標
        self.key_metrics = {
            "latency": {"threshold": 2000, "unit": "ms"},
            "error_rate": {"threshold": 0.01, "unit": "%"},
            "token_cost": {"threshold": 0.1, "unit": "$"},
            "user_satisfaction": {"threshold": 0.85, "unit": "score"}
        }
    
    def trace_request(self, request_id):
        """追蹤請求全流程"""
        
        @self.tracer.span("llm_request")
        async def traced_execution():
            span = self.tracer.current_span()
            
            # 記錄請求屬性
            span.set_attributes({
                "request.id": request_id,
                "request.model": request.get("model"),
                "request.prompt_length": len(request.get("prompt", "")),
                "request.timestamp": datetime.now().isoformat()
            })
            
            try:
                # Prompt 處理階段
                with self.tracer.span("prompt_processing"):
                    prompt = await self.process_prompt(request)
                    span.set_attribute("prompt.tokens", self.count_tokens(prompt))
                
                # LLM 呼叫階段
                with self.tracer.span("llm_call"):
                    start_time = time.time()
                    response = await self.call_llm(prompt)
                    latency = (time.time() - start_time) * 1000
                    
                    span.set_attributes({
                        "llm.latency_ms": latency,
                        "llm.response_tokens": self.count_tokens(response),
                        "llm.total_tokens": self.count_tokens(prompt + response)
                    })
                
                # 後處理階段
                with self.tracer.span("post_processing"):
                    final_response = await self.post_process(response)
                
                # 記錄成功metrics
                self.metrics.record("request_success", 1)
                self.metrics.record("request_latency", latency)
                
                return final_response
                
            except Exception as e:
                # 記錄錯誤
                span.set_status("ERROR")
                span.set_attribute("error.message", str(e))
                
                self.metrics.record("request_error", 1)
                self.logger.error(f"Request failed: {e}", extra={
                    "request_id": request_id,
                    "error_type": type(e).__name__
                })
                
                raise
        
        return await traced_execution()
```

#### 7.3 A/B 測試框架

```python
class ABTestingFramework:
    """A/B 測試框架"""
    
    def __init__(self):
        self.experiments = {}
        self.results = defaultdict(lambda: {
            "impressions": 0,
            "conversions": 0,
            "total_latency": 0,
            "total_cost": 0,
            "errors": 0
        })
    
    def create_experiment(self, name, variants):
        """創建實驗"""
        self.experiments[name] = {
            "variants": variants,
            "traffic_split": self.calculate_traffic_split(len(variants)),
            "created_at": datetime.now(),
            "status": "running"
        }
    
    async def run_variant(self, experiment_name, user_id):
        """執行變體"""
        experiment = self.experiments[experiment_name]
        
        # 分配變體
        variant = self.assign_variant(user_id, experiment)
        variant_config = experiment["variants"][variant]
        
        # 執行並追蹤
        start_time = time.time()
        try:
            # 根據變體配置執行
            result = await self.execute_variant(variant_config)
            
            # 記錄成功metrics
            self.results[f"{experiment_name}_{variant}"]["impressions"] += 1
            self.results[f"{experiment_name}_{variant}"]["total_latency"] += (time.time() - start_time)
            
            # 計算成本
            cost = self.calculate_cost(variant_config, result)
            self.results[f"{experiment_name}_{variant}"]["total_cost"] += cost
            
            return result
            
        except Exception as e:
            self.results[f"{experiment_name}_{variant}"]["errors"] += 1
            raise
    
    def analyze_experiment(self, experiment_name):
        """分析實驗結果"""
        experiment = self.experiments[experiment_name]
        analysis = {}
        
        for variant in experiment["variants"]:
            key = f"{experiment_name}_{variant}"
            data = self.results[key]
            
            if data["impressions"] > 0:
                analysis[variant] = {
                    "conversion_rate": data["conversions"] / data["impressions"],
                    "avg_latency": data["total_latency"] / data["impressions"],
                    "avg_cost": data["total_cost"] / data["impressions"],
                    "error_rate": data["errors"] / data["impressions"],
                    "sample_size": data["impressions"]
                }
                
                # 計算統計顯著性
                if len(analysis) > 1:
                    analysis[variant]["statistical_significance"] = \
                        self.calculate_significance(analysis)
        
        # 推薦獲勝者
        winner = self.recommend_winner(analysis)
        
        return {
            "analysis": analysis,
            "winner": winner,
            "confidence": self.calculate_confidence(analysis),
            "recommendation": self.generate_recommendation(analysis, winner)
        }
```

### 🔬 Lab 實作：成本優化實驗

```python
# Lab: Streaming vs Batch 實驗
class StreamingVsBatchExperiment:
    def __init__(self):
        self.ab_test = ABTestingFramework()
        self.cost_engine = CostEngineering()
        self.observability = ObservabilitySystem()
        
        # 定義實驗變體
        self.setup_experiment()
    
    def setup_experiment(self):
        """設定實驗"""
        self.ab_test.create_experiment(
            name="streaming_vs_batch",
            variants={
                "streaming": {
                    "mode": "streaming",
                    "model": "gpt-3.5-turbo",
                    "batch_size": 1,
                    "timeout": 30
                },
                "batch_small": {
                    "mode": "batch",
                    "model": "gpt-3.5-turbo",
                    "batch_size": 5,
                    "timeout": 10
                },
                "batch_large": {
                    "mode": "batch",
                    "model": "gpt-3.5-turbo",
                    "batch_size": 20,
                    "timeout": 5
                }
            }
        )
    
    async def run_test(self, num_requests=100):
        """執行測試"""
        tasks = []
        
        for i in range(num_requests):
            user_id = f"user_{i % 10}"  # 模擬 10 個用戶
            
            # 創建測試請求
            request = {
                "prompt": f"Test prompt {i}: Explain quantum computing",
                "user_id": user_id,
                "timestamp": datetime.now()
            }
            
            # 執行實驗
            task = self.process_with_monitoring(request, user_id)
            tasks.append(task)
            
            # 模擬真實流量
            await asyncio.sleep(random.uniform(0.1, 0.5))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 分析結果
        self.analyze_results(results)
    
    async def process_with_monitoring(self, request, user_id):
        """帶監控的處理"""
        
        # 開始追蹤
        with self.observability.tracer.span("experiment_request") as span:
            span.set_attribute("user_id", user_id)
            
            try:
                # 執行變體
                result = await self.ab_test.run_variant(
                    "streaming_vs_batch",
                    user_id
                )
                
                # 記錄詳細metrics
                self.observability.metrics.record("request_success", 1, {
                    "variant": result.get("variant"),
                    "user_id": user_id
                })
                
                # 模擬用戶行為（轉換）
                if self.simulate_user_satisfaction(result):
                    variant_key = f"streaming_vs_batch_{result['variant']}"
                    self.ab_test.results[variant_key]["conversions"] += 1
                
                return result
                
            except Exception as e:
                self.observability.logger.error(f"Experiment failed: {e}")
                raise
    
    def simulate_user_satisfaction(self, result):
        """模擬用戶滿意度"""
        # 基於延遲和品質計算滿意度
        latency_score = 1.0 if result.get("latency", 0) < 2000 else 0.5
        quality_score = result.get("quality", 0.8)
        
        satisfaction = (latency_score * 0.4 + quality_score * 0.6)
        
        # 隨機決定是否轉換
        return random.random() < satisfaction
    
    def analyze_results(self, results):
        """分析測試結果"""
        analysis = self.ab_test.analyze_experiment("streaming_vs_batch")
        
        print("\n" + "="*60)
        print("📊 A/B 測試結果分析")
        print("="*60)
        
        for variant, data in analysis["analysis"].items():
            print(f"\n🔹 變體: {variant}")
            print(f"   轉換率: {data['conversion_rate']:.2%}")
            print(f"   平均延遲: {data['avg_latency']:.2f}秒")
            print(f"   平均成本: ${data['avg_cost']:.4f}")
            print(f"   錯誤率: {data['error_rate']:.2%}")
            print(f"   樣本數: {data['sample_size']}")
        
        print(f"\n🏆 獲勝者: {analysis['winner']}")
        print(f"📈 信心度: {analysis['confidence']:.2%}")
        print(f"\n💡 建議: {analysis['recommendation']}")
        
        # 成本節省分析
        self.calculate_cost_savings(analysis)
    
    def calculate_cost_savings(self, analysis):
        """計算成本節省"""
        baseline = analysis["analysis"].get("streaming", {})
        
        print("\n💰 成本節省分析:")
        for variant, data in analysis["analysis"].items():
            if variant != "streaming":
                savings = baseline.get("avg_cost", 0) - data["avg_cost"]
                savings_pct = (savings / baseline.get("avg_cost", 1)) * 100
                
                print(f"   {variant}: 節省 ${savings:.4f}/request ({savings_pct:.1f}%)")
                
                # 月度預估
                monthly_requests = 100000
                monthly_savings = savings * monthly_requests
                print(f"      預估月節省: ${monthly_savings:,.2f}")

# 執行實驗
experiment = StreamingVsBatchExperiment()
await experiment.run_test(num_requests=100)
```

### 💡 實戰心得
> 📊 **數據驅動決策**：不要憑感覺優化，要用 A/B 測試證明。我們曾經以為 streaming 一定更好，結果發現批次處理在某些場景下成本降低 70%。

---

## 📘 模組 8：應用落地與 UX 強化（第 8 週）

### 🎯 學習目標
將應用推向生產環境，加強用戶體驗

### 📚 核心內容

#### 8.1 產品指標體系設計

```python
class ProductMetrics:
    """產品指標系統"""
    
    def __init__(self):
        # 技術指標
        self.technical_metrics = {
            "latency_p50": {"target": 1000, "unit": "ms", "weight": 0.2},
            "latency_p95": {"target": 3000, "unit": "ms", "weight": 0.1},
            "error_rate": {"target": 0.01, "unit": "%", "weight": 0.2},
            "token_cost_per_request": {"target": 0.05, "unit": "$", "weight": 0.2}
        }
        
        # 業務指標
        self.business_metrics = {
            "csat": {"target": 0.85, "unit": "score", "weight": 0.3},  # 客戶滿意度
            "resolution_rate": {"target": 0.80, "unit": "%", "weight": 0.3},  # 解決率
            "fallback_rate": {"target": 0.10, "unit": "%", "weight": 0.2},  # 降級率
            "escalation_rate": {"target": 0.05, "unit": "%", "weight": 0.2}  # 轉人工率
        }
        
        # 綜合健康分數
        self.health_score_calculator = HealthScoreCalculator()
    
    def calculate_health_score(self, current_metrics):
        """計算健康分數"""
        technical_score = 0
        business_score = 0
        
        # 計算技術分數
        for metric, config in self.technical_metrics.items():
            current = current_metrics.get(metric, 0)
            target = config["target"]
            
            # 反向指標（越低越好）
            if metric in ["latency_p50", "latency_p95", "error_rate", "token_cost_per_request"]:
                score = min(1.0, target / max(current, 0.001))
            else:
                score = min(1.0, current / target)
            
            technical_score += score * config["weight"]
        
        # 計算業務分數
        for metric, config in self.business_metrics.items():
            current = current_metrics.get(metric, 0)
            target = config["target"]
            
            # 反向指標
            if metric in ["fallback_rate", "escalation_rate"]:
                score = min(1.0, target / max(current, 0.001))
            else:
                score = min(1.0, current / target)
            
            business_score += score * config["weight"]
        
        # 綜合分數
        overall_score = technical_score * 0.4 + business_score * 0.6
        
        return {
            "overall": overall_score,
            "technical": technical_score,
            "business": business_score,
            "status": self.get_status(overall_score),
            "recommendations": self.generate_recommendations(current_metrics)
        }
    
    def get_status(self, score):
        """獲取狀態"""
        if score >= 0.9:
            return "🟢 Excellent"
        elif score >= 0.7:
            return "🟡 Good"
        elif score >= 0.5:
            return "🟠 Needs Improvement"
        else:
            return "🔴 Critical"
    
    def generate_recommendations(self, metrics):
        """生成優化建議"""
        recommendations = []
        
        # 延遲問題
        if metrics.get("latency_p95", 0) > 5000:
            recommendations.append("⚡ 考慮使用更快的模型或增加快取")
        
        # 成本問題
        if metrics.get("token_cost_per_request", 0) > 0.1:
            recommendations.append("💰 優化 Prompt 長度或使用更便宜的模型")
        
        # 滿意度問題
        if metrics.get("csat", 1) < 0.7:
            recommendations.append("😊 改善回應品質，考慮增加人工審核")
        
        # 降級率問題
        if metrics.get("fallback_rate", 0) > 0.2:
            recommendations.append("🔧 檢查主要服務穩定性，優化降級策略")
        
        return recommendations
```

#### 8.2 LLM 特有的 UX 模式

```python
class LLMSpecificUX:
    """LLM 特有的 UX 元件"""
    
    def __init__(self):
        self.components = {
            "thinking_indicator": ThinkingIndicator(),
            "confidence_display": ConfidenceDisplay(),
            "quick_fix": QuickFixComponent(),
            "streaming_renderer": StreamingRenderer()
        }
    
    def create_thinking_indicator(self):
        """思考過程可視化"""
        return {
            "type": "thinking_indicator",
            "stages": [
                {"id": "understanding", "label": "理解問題", "duration": 500},
                {"id": "searching", "label": "搜尋資料", "duration": 1000},
                {"id": "analyzing", "label": "分析中", "duration": 1500},
                {"id": "generating", "label": "生成回答", "duration": 800}
            ],
            "animations": {
                "dots": "...",
                "spinner": "⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏",
                "progress": "████░░░░░░"
            }
        }
    
    def create_confidence_display(self, response, confidence_score):
        """信心度顯示"""
        if confidence_score > 0.9:
            indicator = "✅ 高信心度"
            color = "green"
            disclaimer = None
        elif confidence_score > 0.7:
            indicator = "⚠️ 中等信心度"
            color = "yellow"
            disclaimer = "此回答可能不完全準確，建議進一步確認"
        else:
            indicator = "⚡ 低信心度"
            color = "red"
            disclaimer = "此回答僅供參考，強烈建議人工確認"
        
        return {
            "type": "confidence_display",
            "score": confidence_score,
            "indicator": indicator,
            "color": color,
            "disclaimer": disclaimer,
            "show_sources": confidence_score < 0.8  # 低信心時顯示來源
        }
    
    def create_quick_fix_component(self, response):
        """快速修正元件"""
        return {
            "type": "quick_fix",
            "actions": [
                {
                    "id": "regenerate",
                    "label": "🔄 重新生成",
                    "hotkey": "Ctrl+R",
                    "action": "regenerate_response"
                },
                {
                    "id": "report",
                    "label": "🚩 回報問題",
                    "hotkey": "Ctrl+F",
                    "action": "report_issue"
                },
                {
                    "id": "edit",
                    "label": "✏️ 編輯回答",
                    "hotkey": "Ctrl+E",
                    "action": "edit_response"
                }
            ],
            "feedback_options": [
                "不準確",
                "不完整",
                "不相關",
                "語氣不當"
            ]
        }
    
    def create_streaming_ux(self):
        """串流 UX 設計"""
        return {
            "type": "streaming",
            "features": {
                "typing_effect": {
                    "enabled": True,
                    "speed": 50,  # 字/秒
                    "variable_speed": True  # 模擬真人打字節奏
                },
                "partial_render": {
                    "enabled": True,
                    "chunk_size": 10,  # 每 10 個字渲染一次
                    "markdown_preview": True
                },
                "interrupt": {
                    "enabled": True,
                    "hotkey": "Esc",
                    "show_stop_button": True
                },
                "progress": {
                    "show_token_count": True,
                    "show_estimated_time": True,
                    "show_cost": False  # 生產環境不顯示成本
                }
            }
        }
```

#### 8.3 部署檢查清單

```python
class DeploymentChecklist:
    """部署檢查清單"""
    
    def __init__(self):
        self.checks = {
            "security": [
                ("prompt_injection_protection", self.check_prompt_injection),
                ("api_key_management", self.check_api_keys),
                ("rate_limiting", self.check_rate_limits),
                ("data_privacy", self.check_data_privacy)
            ],
            "reliability": [
                ("fallback_strategy", self.check_fallback),
                ("error_handling", self.check_error_handling),
                ("timeout_configuration", self.check_timeouts),
                ("retry_logic", self.check_retry_logic)
            ],
            "performance": [
                ("response_time", self.check_response_time),
                ("concurrent_requests", self.check_concurrency),
                ("cache_configuration", self.check_cache),
                ("model_optimization", self.check_model_optimization)
            ],
            "monitoring": [
                ("logging_setup", self.check_logging),
                ("metrics_collection", self.check_metrics),
                ("alerting_rules", self.check_alerts),
                ("dashboard_setup", self.check_dashboards)
            ],
            "cost": [
                ("budget_limits", self.check_budget_limits),
                ("cost_tracking", self.check_cost_tracking),
                ("optimization_rules", self.check_optimizations),
                ("billing_alerts", self.check_billing_alerts)
            ]
        }
    
    def run_all_checks(self):
        """執行所有檢查"""
        results = {}
        total_passed = 0
        total_checks = 0
        
        for category, checks in self.checks.items():
            results[category] = {}
            
            for check_name, check_func in checks:
                result = check_func()
                results[category][check_name] = result
                
                if result["passed"]:
                    total_passed += 1
                total_checks += 1
        
        # 生成報告
        return self.generate_report(results, total_passed, total_checks)
    
    def generate_report(self, results, passed, total):
        """生成部署報告"""
        score = passed / total * 100
        
        report = f"""
        ========================================
        📋 部署就緒檢查報告
        ========================================
        
        總分: {score:.1f}/100
        狀態: {'✅ 可以部署' if score > 80 else '❌ 需要改進'}
        
        詳細結果:
        """
        
        for category, checks in results.items():
            report += f"\n{category.upper()}:\n"
            for check, result in checks.items():
                status = "✅" if result["passed"] else "❌"
                report += f"  {status} {check}: {result['message']}\n"
        
        # 關鍵問題
        critical_issues = self.find_critical_issues(results)
        if critical_issues:
            report += "\n⚠️ 關鍵問題:\n"
            for issue in critical_issues:
                report += f"  - {issue}\n"
        
        return report
```

### 🔬 Lab 實作：完整客服 Bot 部署

```python
# Lab: 部署一個生產級客服 Bot
class ProductionCustomerBot:
    def __init__(self):
        self.metrics = ProductMetrics()
        self.ux = LLMSpecificUX()
        self.deployment = DeploymentChecklist()
        
        # 初始化各個組件
        self.setup_components()
    
    def setup_components(self):
        """設定所有組件"""
        # 核心功能
        self.llm_handler = LLMHandler()
        self.fallback_system = GracefulDegradation()
        self.cache = ResponseCache()
        
        # 監控
        self.monitoring = ObservabilitySystem()
        self.analytics = AnalyticsTracker()
        
        # UX 元件
        self.ui_components = {
            "thinking": self.ux.create_thinking_indicator(),
            "confidence": None,  # 動態生成
            "quick_fix": self.ux.create_quick_fix_component(None),
            "streaming": self.ux.create_streaming_ux()
        }
    
    async def handle_customer_query(self, query, session_id):
        """處理客戶查詢 - 完整流程"""
        
        # 1. 開始追蹤
        trace_id = self.monitoring.start_trace()
        
        try:
            # 2. 顯示思考指示器
            await self.show_thinking_process()
            
            # 3. 處理查詢（帶降級）
            response_data = await self.fallback_system.handle_request({
                "prompt": query,
                "session_id": session_id,
                "trace_id": trace_id
            })
            
            # 4. 計算信心度
            confidence = self.calculate_confidence(response_data)
            
            # 5. 準備 UX 元件
            ui_response = {
                "message": response_data["response"],
                "confidence": self.ux.create_confidence_display(
                    response_data["response"],
                    confidence
                ),
                "quick_actions": self.ux.create_quick_fix_component(
                    response_data["response"]
                ),
                "metadata": {
                    "strategy_used": response_data.get("strategy_used"),
                    "response_time": response_data.get("total_time"),
                    "trace_id": trace_id
                }
            }
            
            # 6. 記錄 metrics
            await self.record_metrics(response_data, confidence)
            
            # 7. 用戶反饋收集
            ui_response["feedback_widget"] = self.create_feedback_widget(trace_id)
            
            return ui_response
            
        except Exception as e:
            # 錯誤處理
            self.monitoring.record_error(e, trace_id)
            return self.create_error_response(e)
        
        finally:
            # 結束追蹤
            self.monitoring.end_trace(trace_id)
    
    async def show_thinking_process(self):
        """顯示思考過程"""
        stages = self.ui_components["thinking"]["stages"]
        
        for stage in stages:
            # 發送狀態更新到前端
            await self.send_status_update({
                "type": "thinking",
                "stage": stage["id"],
                "label": stage["label"]
            })
            
            # 模擬處理時間
            await asyncio.sleep(stage["duration"] / 1000)
    
    def calculate_confidence(self, response_data):
        """計算回應信心度"""
        factors = {
            "strategy_level": {
                "try_primary": 1.0,
                "try_cache": 0.9,
                "try_simple_model": 0.7,
                "try_template": 0.5,
                "try_human": 0.3
            },
            "response_time": 1.0 if response_data.get("total_time", 0) < 2 else 0.8,
            "cache_hit": 0.9 if response_data.get("cache_hit") else 1.0
        }
        
        strategy = response_data.get("strategy_used", "unknown")
        confidence = factors["strategy_level"].get(strategy, 0.5)
        confidence *= factors["response_time"]
        
        if response_data.get("cache_hit"):
            confidence *= factors["cache_hit"]
        
        return min(confidence, 1.0)
    
    async def record_metrics(self, response_data, confidence):
        """記錄各項指標"""
        metrics = {
            "latency_p50": response_data.get("total_time", 0) * 1000,
            "error_rate": 0 if response_data.get("success") else 1,
            "token_cost_per_request": response_data.get("cost", 0),
            "csat": confidence,  # 暫時用信心度代替
            "resolution_rate": 1 if confidence > 0.7 else 0,
            "fallback_rate": 1 if response_data.get("degradation_level", 0) > 0 else 0,
            "escalation_rate": 1 if response_data.get("strategy_used") == "try_human" else 0
        }
        
        # 記錄到監控系統
        for metric, value in metrics.items():
            self.monitoring.metrics.record(metric, value)
        
        # 計算健康分數
        health = self.metrics.calculate_health_score(metrics)
        
        # 如果健康分數低，發送警報
        if health["overall"] < 0.5:
            await self.send_alert(f"Health score critical: {health['overall']:.2f}")
    
    def create_feedback_widget(self, trace_id):
        """創建反饋小工具"""
        return {
            "type": "feedback",
            "trace_id": trace_id,
            "options": [
                {"emoji": "👍", "value": "helpful"},
                {"emoji": "👎", "value": "not_helpful"},
                {"emoji": "😕", "value": "confusing"},
                {"emoji": "🎯", "value": "accurate"},
                {"emoji": "❌", "value": "wrong"}
            ],
            "allow_text": True,
            "placeholder": "告訴我們如何改進..."
        }
    
    async def run_deployment_checks(self):
        """執行部署前檢查"""
        print("🚀 開始部署前檢查...\n")
        
        report = self.deployment.run_all_checks()
        print(report)
        
        # 模擬一些指標
        test_metrics = {
            "latency_p50": 800,
            "latency_p95": 2500,
            "error_rate": 0.005,
            "token_cost_per_request": 0.03,
            "csat": 0.88,
            "resolution_rate": 0.82,
            "fallback_rate": 0.08,
            "escalation_rate": 0.03
        }
        
        health = self.metrics.calculate_health_score(test_metrics)
        
        print("\n📊 系統健康報告:")
        print(f"  整體分數: {health['overall']:.2f} - {health['status']}")
        print(f"  技術分數: {health['technical']:.2f}")
        print(f"  業務分數: {health['business']:.2f}")
        
        if health["recommendations"]:
            print("\n💡 優化建議:")
            for rec in health["recommendations"]:
                print(f"  {rec}")
        
        return health["overall"] > 0.7

# 測試部署
bot = ProductionCustomerBot()

# 1. 執行部署檢查
ready = await bot.run_deployment_checks()

if ready:
    print("\n✅ 系統已準備就緒，可以部署！")
    
    # 2. 測試一些查詢
    test_queries = [
        "我的訂單什麼時候到？",
        "如何申請退款？",
        "你們的客服電話是多少？"
    ]
    
    for query in test_queries:
        print(f"\n測試查詢: {query}")
        response = await bot.handle_customer_query(query, "test_session")
        print(f"回應: {response['message'][:100]}...")
        print(f"信心度: {response['confidence']['indicator']}")
else:
    print("\n❌ 系統尚未準備好，請解決上述問題後再部署。")
```

### 💡 實戰心得
> 🚀 **UX 決定成敗**：技術再好，用戶體驗差就是失敗。花 50% 的時間在 UX 上不為過。

---

## 🎓 終極專題：Capstone Project

### 🎯 專題目標
整合所有模組知識，開發一個**真正可用的 LLM OS 應用**

### 📝 專題選項

#### Option 1: 智慧客服助手（推薦新手）
- **功能要求**：多輪對話、RAG、情緒管理、工單系統整合
- **技術挑戰**：處理情緒化客戶、多語言支援、降級策略
- **評分重點**：回應品質、處理效率、用戶滿意度

#### Option 2: 程式碼審查 Copilot
- **功能要求**：程式碼分析、bug 檢測、重構建議、最佳實踐檢查
- **技術挑戰**：理解程式碼上下文、提供可執行建議
- **評分重點**：建議準確性、實用性、整合便利性

#### Option 3: 智慧文件助理
- **功能要求**：文件上傳、智慧問答、摘要生成、引用追蹤
- **技術挑戰**：處理大文件、準確引用、多格式支援
- **評分重點**：檢索準確性、回答完整性、引用可靠性

### 📊 評分標準

| 面向 | 權重 | 評分要點 |
|------|------|---------|
| **技術實現** | 40% | API 整合完整性、錯誤處理完善度、效能優化程度、成本控制能力 |
| **產品完成度** | 40% | UX 流暢性、功能完整性、實際解決問題能力、部署就緒程度 |
| **創新性** | 20% | 場景創意、Prompt 設計巧思、UX 差異化、技術亮點 |

### 🏆 優秀專題範例

```python
class ExcellentCapstoneExample:
    """優秀專題範例：智慧 HR 助手"""
    
    def __init__(self):
        # 完整的模組整合
        self.modules = {
            "prompt_manager": PromptManager(),        # 模組 1
            "api_handler": LLMAPIPatterns(),         # 模組 2
            "context_engine": MemoryArchitecture(),  # 模組 3
            "rag_system": SimpleRAG(),               # 模組 4
            "product_logic": ProductDecisionFramework(), # 模組 5
            "workflow": WorkflowChain(),             # 模組 6
            "monitoring": ObservabilitySystem(),     # 模組 7
            "ux_system": LLMSpecificUX()            # 模組 8
        }
        
        # 創新點
        self.innovations = {
            "multi_persona": self.handle_multiple_personas,
            "proactive_suggestions": self.generate_proactive_suggestions,
            "sentiment_routing": self.route_by_sentiment
        }
    
    async def demo_flow(self):
        """展示完整流程"""
        
        # 場景：員工詢問請假政策
        query = "我想請病假，需要什麼手續？最近壓力很大..."
        
        # 1. 情緒檢測與路由（創新點）
        sentiment = await self.detect_sentiment(query)
        if sentiment["stress_level"] > 0.7:
            # 切換到關懷模式
            self.modules["prompt_manager"].switch_mode("empathetic")
        
        # 2. 多角色處理（創新點）
        response = await self.handle_with_persona(
            query,
            persona="hr_counselor"  # 不只是 HR，還有心理關懷
        )
        
        # 3. 主動建議（創新點）
        suggestions = await self.generate_proactive_suggestions(query)
        # 例如：建議 EAP 服務、推薦減壓資源
        
        # 4. 完整的產品化輸出
        return {
            "primary_response": response,
            "care_package": {
                "detected_stress": True,
                "eap_resources": self.get_eap_resources(),
                "anonymous_counseling": self.get_counseling_link()
            },
            "next_steps": suggestions,
            "follow_up_scheduled": self.schedule_follow_up(query)
        }
```

---

## 🚀 學習路徑總結

### 🎯 快速通道（4 週兼職學習）

**Week 1-2: 基礎速成**
- Day 1-3: Prompt Engineering + 版本管理
- Day 4-5: API 模式 + UX 基礎
- Day 6-7: 簡單 RAG + Context 管理
- **產出**: 能對話的 Bot Demo

**Week 3: 核心實戰**
- Day 1-2: 產品思維 + 成本優化
- Day 3-4: Workflow 設計
- Day 5-7: 可靠性基礎
- **產出**: 有 fallback 的穩定 Bot

**Week 4: 專題衝刺**
- Day 1-5: 開發完整專題
- Day 6-7: 部署與優化
- **產出**: 可部署的 MVP

### 🎓 完整通道（8 週深度學習）

按照完整 8 個模組循序漸進，每週一個模組，最後用 2 週完成專題。

---

## 💼 職涯發展建議

### 📈 技能成長路線圖

```
初級（0-6個月）
├── 掌握 Prompt Engineering
├── 熟悉主流 LLM API
└── 能開發簡單 Bot

中級（6-18個月）
├── 精通 RAG 和 Context 管理  
├── 設計複雜 Workflow
├── 優化成本和性能
└── 領導小型專案

高級（18個月+）
├── 架構大型 LLM 系統
├── 制定技術標準
├── 培訓團隊
└── 推動創新

專家（3年+）
├── 定義產品策略
├── 跨團隊協作
├── 開源貢獻
└── 行業影響力
```

## 🎯 立即行動計劃

### 今天就開始（Day 1）

```python
# Step 1: 設定環境
pip install openai langchain pinecone-client

# Step 2: 第一個 Prompt Manager
class MyFirstPromptManager:
    def __init__(self):
        self.prompts = {
            "v1": "You are a helpful assistant.",
            "v2": "You are a helpful and empathetic assistant."
        }
        self.current = "v1"
    
    def get_prompt(self):
        return self.prompts[self.current]

# Step 3: 測試版本差異
manager = MyFirstPromptManager()
for version in ["v1", "v2"]:
    manager.current = version
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": manager.get_prompt()},
            {"role": "user", "content": "I'm feeling stressed"}
        ]
    )
    print(f"{version}: {response.choices[0].message.content}")
```

### 本週目標（Week 1）

- [ ] 完成模組 1-2 的學習
- [ ] 實作 3 個不同的 Prompt 策略
- [ ] 測試 3 種 UX 模式
- [ ] 建立第一個帶驗證的 API 呼叫

### 本月目標（Month 1）

- [ ] 完成模組 1-6
- [ ] 開發一個完整的 FAQ Bot
- [ ] 實現成本優化，降低 50% 開銷
- [ ] 部署到測試環境

---

## 📚 學習資源推薦

### 📖 必讀資源
- [OpenAI Cookbook](https://cookbook.openai.com/) - 官方最佳實踐
- [LangChain Docs](https://docs.langchain.com/) - 應用開發框架
- [Pinecone Learning Center](https://www.pinecone.io/learn/) - 向量資料庫入門

### 🎓 進階課程
- [Building LLM Apps with LangChain.js](https://www.deeplearning.ai/short-courses/building-applications-vector-databases/) - DeepLearning.AI
- [LLM Application Development](https://www.coursera.org/learn/llm-applications) - Coursera
- [Full Stack LLM Bootcamp](https://fullstackdeeplearning.com/llm-bootcamp/) - FSDL

### 🛠 開發工具
- **Prompt 測試**: [Promptfoo](https://promptfoo.dev/), [Langfuse](https://langfuse.com/)
- **監控平台**: [Helicone](https://helicone.ai/), [Langsmith](https://smith.langchain.com/)
- **向量資料庫**: [Pinecone](https://pinecone.io/), [Weaviate](https://weaviate.io/)

### 👥 社群資源
- [r/LocalLLaMA](https://reddit.com/r/LocalLLaMA) - Reddit 社群
- [LLM Discord](https://discord.gg/llm) - Discord 討論群
- [AI Builder Club](https://aibuilder.club/) - 開發者社群

---

## 🏁 結語：成為市場需要的 LLM 應用工程師

還記得開頭提到的問題嗎？為什麼 90% 的 LLM 應用都只是「玩具」？

現在你有答案了：**因為缺乏應用工程的系統化思維。**

透過這 8 個模組的學習，你將掌握：
- ✅ 如何管理 Prompt 資產，而不只是寫 Prompt
- ✅ 如何設計降級策略，而不是祈禱 API 不會掛
- ✅ 如何優化成本效益，而不是燒錢做 Demo
- ✅ 如何打造用戶體驗，而不只是技術炫技

**市場現狀**：
- 每家企業都想導入 AI，但缺乏落地能力
- 大量職缺湧現，但合格人才稀缺
- 薪資持續上漲，機會窗口正在開啟

**你的機會**：
- 不需要 PhD，不需要懂模型原理
- 只要 2-3 個月，就能掌握核心技能
- 市場需求是系統工程師的 **5-10 倍**

### 🚀 最後的行動呼籲

**不要再等了。** 每天都有新的 LLM 應用上線，每天都有公司在找 LLM 應用工程師。

現在就開始：
1. **今天**：設定環境，寫第一個 Prompt Manager
2. **本週**：完成模組 1-2，做出 Demo
3. **本月**：開發第一個完整應用
4. **三個月後**：成為合格的 LLM 應用工程師

記住：**在 AI 時代，應用層才是主戰場。**

系統工程師建造引擎，但**應用工程師開車上路**。

問題是——**你準備好上路了嗎？**

---

**最後更新**：2025年8月  
**作者**：Ian Chou  
**聯絡方式**：i@wo94.com

---

### 🔗 相關文章推薦
- [🧭 建造你的 LLM OS：從 Prompt 到 Production 的完整建構指南](/blog/2025-08-llm-os-complete-guide) - LLM OS 系統架構深度指南
- [🚀 AI 編程助手比較：Claude vs ChatGPT vs Gemini 開發者實戰評測](/blog/2025-06-ai-coding-assistant-comparison-claude-chatgpt-gemini-developers) - AI 編程工具對比
- [📊 台灣軟體工程師就業市場分析：2025 年趨勢與機會](/blog/2025-06-taiwan-software-engineer-job-market-analysis) - 職涯發展參考
- [🔧 規格驅動開發：2025 年軟體開發的新典範](/blog/2025-07-specification-driven-development-2025-paradigm) - 新興開發模式